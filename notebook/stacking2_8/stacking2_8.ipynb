{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    exp_num = 8\n",
    "    n_folds = 5\n",
    "    folds = [0, 1, 2, 3, 4]\n",
    "    seed = 777\n",
    "    local = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/ventilator-pressure-prediction\")\n",
    "OUTPUT_DIR = Path('./output/')\n",
    "OOF_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_oofs_stacking\")\n",
    "SUB_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_subs_stacking\")\n",
    "PICKLE_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_stacking_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../src/')\n",
    "import utils as utils\n",
    "from utils import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 33)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_paths = sorted(list(OOF_DIR.rglob('*.npy'))+list(OOF_DIR.rglob('*.csv')))\n",
    "sub_paths = sorted(list(SUB_DIR.rglob('*.npy'))+list(SUB_DIR.rglob('*.csv')))\n",
    "\n",
    "len(oof_paths), len(sub_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLE_DIR / \"all_stacking1_oof.npy\", mode=\"rb\") as f:\n",
    "    oofs = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>pred_10</th>\n",
       "      <th>pred_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.051358</td>\n",
       "      <td>6.008679</td>\n",
       "      <td>5.839750</td>\n",
       "      <td>5.916682</td>\n",
       "      <td>5.907529</td>\n",
       "      <td>5.523668</td>\n",
       "      <td>5.810369</td>\n",
       "      <td>5.970937</td>\n",
       "      <td>5.683621</td>\n",
       "      <td>5.805068</td>\n",
       "      <td>5.900626</td>\n",
       "      <td>5.855789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.901721</td>\n",
       "      <td>5.824164</td>\n",
       "      <td>5.896797</td>\n",
       "      <td>5.886481</td>\n",
       "      <td>5.899961</td>\n",
       "      <td>5.929617</td>\n",
       "      <td>5.871547</td>\n",
       "      <td>5.902353</td>\n",
       "      <td>5.919608</td>\n",
       "      <td>5.846550</td>\n",
       "      <td>5.890169</td>\n",
       "      <td>5.898379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.389902</td>\n",
       "      <td>8.267651</td>\n",
       "      <td>8.516665</td>\n",
       "      <td>8.561444</td>\n",
       "      <td>8.385892</td>\n",
       "      <td>8.095352</td>\n",
       "      <td>8.126698</td>\n",
       "      <td>8.220336</td>\n",
       "      <td>8.197915</td>\n",
       "      <td>7.975787</td>\n",
       "      <td>8.125211</td>\n",
       "      <td>8.267651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.343451</td>\n",
       "      <td>12.020198</td>\n",
       "      <td>12.398529</td>\n",
       "      <td>12.385787</td>\n",
       "      <td>12.373862</td>\n",
       "      <td>12.134422</td>\n",
       "      <td>12.084424</td>\n",
       "      <td>12.261753</td>\n",
       "      <td>12.206296</td>\n",
       "      <td>12.002528</td>\n",
       "      <td>12.069723</td>\n",
       "      <td>12.261753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.681964</td>\n",
       "      <td>12.505707</td>\n",
       "      <td>12.786497</td>\n",
       "      <td>12.760039</td>\n",
       "      <td>12.763080</td>\n",
       "      <td>12.600920</td>\n",
       "      <td>12.546120</td>\n",
       "      <td>12.702161</td>\n",
       "      <td>12.597127</td>\n",
       "      <td>12.502975</td>\n",
       "      <td>12.482092</td>\n",
       "      <td>12.604898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290963</th>\n",
       "      <td>29.430931</td>\n",
       "      <td>29.476478</td>\n",
       "      <td>29.435886</td>\n",
       "      <td>29.438047</td>\n",
       "      <td>29.445435</td>\n",
       "      <td>29.459700</td>\n",
       "      <td>29.480509</td>\n",
       "      <td>29.465638</td>\n",
       "      <td>29.459790</td>\n",
       "      <td>29.423048</td>\n",
       "      <td>29.466577</td>\n",
       "      <td>29.445435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290964</th>\n",
       "      <td>29.093206</td>\n",
       "      <td>29.113724</td>\n",
       "      <td>29.106075</td>\n",
       "      <td>29.106499</td>\n",
       "      <td>29.109507</td>\n",
       "      <td>29.138840</td>\n",
       "      <td>29.120060</td>\n",
       "      <td>29.103670</td>\n",
       "      <td>29.111308</td>\n",
       "      <td>29.086384</td>\n",
       "      <td>29.113920</td>\n",
       "      <td>29.106499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290965</th>\n",
       "      <td>29.850384</td>\n",
       "      <td>29.908362</td>\n",
       "      <td>29.861372</td>\n",
       "      <td>29.865599</td>\n",
       "      <td>29.871944</td>\n",
       "      <td>29.883578</td>\n",
       "      <td>29.890086</td>\n",
       "      <td>29.886187</td>\n",
       "      <td>29.887238</td>\n",
       "      <td>29.874448</td>\n",
       "      <td>29.870653</td>\n",
       "      <td>29.874448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290966</th>\n",
       "      <td>29.370970</td>\n",
       "      <td>29.400613</td>\n",
       "      <td>29.380976</td>\n",
       "      <td>29.381800</td>\n",
       "      <td>29.382881</td>\n",
       "      <td>29.397045</td>\n",
       "      <td>29.373083</td>\n",
       "      <td>29.392937</td>\n",
       "      <td>29.371835</td>\n",
       "      <td>29.382864</td>\n",
       "      <td>29.392797</td>\n",
       "      <td>29.381800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290967</th>\n",
       "      <td>30.061115</td>\n",
       "      <td>30.085098</td>\n",
       "      <td>30.059231</td>\n",
       "      <td>30.062292</td>\n",
       "      <td>30.062634</td>\n",
       "      <td>30.056584</td>\n",
       "      <td>30.028496</td>\n",
       "      <td>30.051001</td>\n",
       "      <td>30.037753</td>\n",
       "      <td>30.072513</td>\n",
       "      <td>30.061198</td>\n",
       "      <td>30.057908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2290968 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred_0     pred_1     pred_2     pred_3     pred_4     pred_5  \\\n",
       "0         6.051358   6.008679   5.839750   5.916682   5.907529   5.523668   \n",
       "1         5.901721   5.824164   5.896797   5.886481   5.899961   5.929617   \n",
       "2         8.389902   8.267651   8.516665   8.561444   8.385892   8.095352   \n",
       "3        12.343451  12.020198  12.398529  12.385787  12.373862  12.134422   \n",
       "4        12.681964  12.505707  12.786497  12.760039  12.763080  12.600920   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "2290963  29.430931  29.476478  29.435886  29.438047  29.445435  29.459700   \n",
       "2290964  29.093206  29.113724  29.106075  29.106499  29.109507  29.138840   \n",
       "2290965  29.850384  29.908362  29.861372  29.865599  29.871944  29.883578   \n",
       "2290966  29.370970  29.400613  29.380976  29.381800  29.382881  29.397045   \n",
       "2290967  30.061115  30.085098  30.059231  30.062292  30.062634  30.056584   \n",
       "\n",
       "            pred_6     pred_7     pred_8     pred_9    pred_10    pred_11  \n",
       "0         5.810369   5.970937   5.683621   5.805068   5.900626   5.855789  \n",
       "1         5.871547   5.902353   5.919608   5.846550   5.890169   5.898379  \n",
       "2         8.126698   8.220336   8.197915   7.975787   8.125211   8.267651  \n",
       "3        12.084424  12.261753  12.206296  12.002528  12.069723  12.261753  \n",
       "4        12.546120  12.702161  12.597127  12.502975  12.482092  12.604898  \n",
       "...            ...        ...        ...        ...        ...        ...  \n",
       "2290963  29.480509  29.465638  29.459790  29.423048  29.466577  29.445435  \n",
       "2290964  29.120060  29.103670  29.111308  29.086384  29.113920  29.106499  \n",
       "2290965  29.890086  29.886187  29.887238  29.874448  29.870653  29.874448  \n",
       "2290966  29.373083  29.392937  29.371835  29.382864  29.392797  29.381800  \n",
       "2290967  30.028496  30.051001  30.037753  30.072513  30.061198  30.057908  \n",
       "\n",
       "[2290968 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oofs = pd.DataFrame(oofs)\n",
    "oofs.columns = [f\"pred_{i}\" for i in range(len(oofs.columns))]\n",
    "oofs['pred_10'] = np.load(OOF_DIR / \"rt4kaido_stacking_oof_6.npy\")\n",
    "oofs['pred_11'] = np.load(OOF_DIR / \"oof_lb0.1137.npy\")\n",
    "oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLE_DIR / \"all_stacking1_sub.npy\", mode=\"rb\") as f:\n",
    "    subs = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>pred_10</th>\n",
       "      <th>pred_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.122457</td>\n",
       "      <td>6.234838</td>\n",
       "      <td>6.228402</td>\n",
       "      <td>6.223941</td>\n",
       "      <td>6.215096</td>\n",
       "      <td>6.270192</td>\n",
       "      <td>6.259692</td>\n",
       "      <td>6.246551</td>\n",
       "      <td>6.232782</td>\n",
       "      <td>6.239510</td>\n",
       "      <td>6.228573</td>\n",
       "      <td>6.232782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.897243</td>\n",
       "      <td>5.966046</td>\n",
       "      <td>5.976529</td>\n",
       "      <td>5.962824</td>\n",
       "      <td>5.969975</td>\n",
       "      <td>5.970970</td>\n",
       "      <td>5.984572</td>\n",
       "      <td>5.972593</td>\n",
       "      <td>5.991468</td>\n",
       "      <td>5.973396</td>\n",
       "      <td>5.943083</td>\n",
       "      <td>5.972593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.116149</td>\n",
       "      <td>7.154629</td>\n",
       "      <td>7.155302</td>\n",
       "      <td>7.151405</td>\n",
       "      <td>7.149951</td>\n",
       "      <td>7.154575</td>\n",
       "      <td>7.120526</td>\n",
       "      <td>7.143456</td>\n",
       "      <td>7.191395</td>\n",
       "      <td>7.121976</td>\n",
       "      <td>7.134622</td>\n",
       "      <td>7.151405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.687282</td>\n",
       "      <td>7.767205</td>\n",
       "      <td>7.695719</td>\n",
       "      <td>7.696728</td>\n",
       "      <td>7.700007</td>\n",
       "      <td>7.730515</td>\n",
       "      <td>7.684567</td>\n",
       "      <td>7.731995</td>\n",
       "      <td>7.745194</td>\n",
       "      <td>7.688272</td>\n",
       "      <td>7.713250</td>\n",
       "      <td>7.715229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.229881</td>\n",
       "      <td>9.256029</td>\n",
       "      <td>9.214653</td>\n",
       "      <td>9.217604</td>\n",
       "      <td>9.215394</td>\n",
       "      <td>9.231619</td>\n",
       "      <td>9.252678</td>\n",
       "      <td>9.217831</td>\n",
       "      <td>9.240966</td>\n",
       "      <td>9.231130</td>\n",
       "      <td>9.224500</td>\n",
       "      <td>9.226733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.720507</td>\n",
       "      <td>11.235307</td>\n",
       "      <td>13.147164</td>\n",
       "      <td>13.164266</td>\n",
       "      <td>15.354063</td>\n",
       "      <td>14.852493</td>\n",
       "      <td>13.631219</td>\n",
       "      <td>13.676671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.164266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.166886</td>\n",
       "      <td>11.625679</td>\n",
       "      <td>13.939608</td>\n",
       "      <td>13.322442</td>\n",
       "      <td>15.355318</td>\n",
       "      <td>14.720789</td>\n",
       "      <td>13.892657</td>\n",
       "      <td>14.014549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.607549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.206486</td>\n",
       "      <td>11.646933</td>\n",
       "      <td>14.122984</td>\n",
       "      <td>13.530339</td>\n",
       "      <td>15.515092</td>\n",
       "      <td>15.015911</td>\n",
       "      <td>14.041680</td>\n",
       "      <td>14.213983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.786009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.823473</td>\n",
       "      <td>12.016227</td>\n",
       "      <td>13.867440</td>\n",
       "      <td>13.157774</td>\n",
       "      <td>16.102294</td>\n",
       "      <td>15.561432</td>\n",
       "      <td>14.433167</td>\n",
       "      <td>14.409499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.512607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.857474</td>\n",
       "      <td>8.502496</td>\n",
       "      <td>10.085802</td>\n",
       "      <td>12.981979</td>\n",
       "      <td>15.284306</td>\n",
       "      <td>14.650837</td>\n",
       "      <td>14.830043</td>\n",
       "      <td>14.567464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.981979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4024000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred_0    pred_1     pred_2     pred_3     pred_4     pred_5  \\\n",
       "0        6.122457  6.234838   6.228402   6.223941   6.215096   6.270192   \n",
       "1        5.897243  5.966046   5.976529   5.962824   5.969975   5.970970   \n",
       "2        7.116149  7.154629   7.155302   7.151405   7.149951   7.154575   \n",
       "3        7.687282  7.767205   7.695719   7.696728   7.700007   7.730515   \n",
       "4        9.229881  9.256029   9.214653   9.217604   9.215394   9.231619   \n",
       "...           ...       ...        ...        ...        ...        ...   \n",
       "4023995  0.000000  0.000000  10.720507  11.235307  13.147164  13.164266   \n",
       "4023996  0.000000  0.000000  11.166886  11.625679  13.939608  13.322442   \n",
       "4023997  0.000000  0.000000  11.206486  11.646933  14.122984  13.530339   \n",
       "4023998  0.000000  0.000000  10.823473  12.016227  13.867440  13.157774   \n",
       "4023999  0.000000  0.000000   5.857474   8.502496  10.085802  12.981979   \n",
       "\n",
       "            pred_6     pred_7     pred_8     pred_9   pred_10    pred_11  \n",
       "0         6.259692   6.246551   6.232782   6.239510  6.228573   6.232782  \n",
       "1         5.984572   5.972593   5.991468   5.973396  5.943083   5.972593  \n",
       "2         7.120526   7.143456   7.191395   7.121976  7.134622   7.151405  \n",
       "3         7.684567   7.731995   7.745194   7.688272  7.713250   7.715229  \n",
       "4         9.252678   9.217831   9.240966   9.231130  9.224500   9.226733  \n",
       "...            ...        ...        ...        ...       ...        ...  \n",
       "4023995  15.354063  14.852493  13.631219  13.676671  0.000000  13.164266  \n",
       "4023996  15.355318  14.720789  13.892657  14.014549  0.000000  13.607549  \n",
       "4023997  15.515092  15.015911  14.041680  14.213983  0.000000  13.786009  \n",
       "4023998  16.102294  15.561432  14.433167  14.409499  0.000000  13.512607  \n",
       "4023999  15.284306  14.650837  14.830043  14.567464  0.000000  12.981979  \n",
       "\n",
       "[4024000 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = pd.DataFrame(subs)\n",
    "subs.columns = [f\"pred_{i}\" for i in range(len(subs.columns))]\n",
    "subs['pred_10'] = pd.read_csv(SUB_DIR / \"rt4kaido_stacking_submission_median_6.csv\")['pressure'].values\n",
    "subs['pred_11'] = np.load(SUB_DIR / \"pred_lb0.1137.npy\")\n",
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_features(input_df, dataType = 'train'):\n",
    "    colum = ['time_step', 'u_in', 'R', 'C']\n",
    "\n",
    "    return input_df[colum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_features(input_df, dataType = 'train'):\n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    colum = ['R_C']\n",
    "    rc_map = {'5_10': 0, '5_20': 1, '5_50': 2, '20_10': 3, '20_20': 4, '20_50': 5, '50_10': 6, '50_20': 7, '50_50': 8}\n",
    "    \n",
    "    output_df['R_C'] = [f'{r}_{c}' for r, c in zip(output_df['R'], output_df['C'])]\n",
    "    output_df['R_C'] = output_df['R_C'].map(rc_map)\n",
    "\n",
    "    return output_df[colum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_calc_features(input_df, dataType = 'train'):\n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    output_df['time_delta'] = output_df.groupby('breath_id')['time_step'].diff().fillna(0)\n",
    "    output_df['delta'] = output_df['time_delta'] * output_df['u_in']\n",
    "    output_df['area'] = output_df.groupby('breath_id')['delta'].cumsum()\n",
    "\n",
    "    output_df['cross']= output_df['u_in']*output_df['u_out']\n",
    "    output_df['cross2']= output_df['time_step']*output_df['u_out']\n",
    "    \n",
    "    output_df['u_in_cumsum'] = (output_df['u_in']).groupby(output_df['breath_id']).cumsum()\n",
    "    output_df['one'] = 1\n",
    "    output_df['count'] = (output_df['one']).groupby(output_df['breath_id']).cumsum()\n",
    "    output_df['u_in_cummean'] =output_df['u_in_cumsum'] / output_df['count']\n",
    "    \n",
    "    output_df['u_in_sqrt'] = output_df['u_in'].apply(lambda x: np.sqrt(x))\n",
    "    output_df['u_in_sqrt_cumsum'] = output_df.groupby('breath_id')['u_in_sqrt'].cumsum()\n",
    "    \n",
    "    output_df = output_df.drop(['count','one'], axis=1)\n",
    "    \n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'u_in': [np.max, np.mean],\n",
    "    }\n",
    "    \n",
    "    def get_agg_window(start_time=0, end_time=3.0, add_suffix = False):\n",
    "        \n",
    "        df_tgt = output_df[(output_df['time_step'] >= start_time) & (output_df['time_step'] <= end_time)]\n",
    "        df_feature = df_tgt.groupby(['breath_id']).agg(create_feature_dict)\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        \n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(start_time) + '_' + str(end_time))\n",
    "            \n",
    "        return df_feature\n",
    "    \n",
    "    df_agg_feature = get_agg_window().reset_index()\n",
    "    \n",
    "#     df_tmp = get_agg_window(start_time = 2, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(start_time = 1, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(end_time = 1, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(end_time = 2, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "\n",
    "    output_df = pd.merge(output_df, df_agg_feature, how='left', on='breath_id')\n",
    "    \n",
    "    output_df['u_in_diffmax'] = output_df['u_in_amax'] - output_df['u_in']\n",
    "    output_df['u_in_diffmean'] = output_df['u_in_mean'] - output_df['u_in']\n",
    "    \n",
    "#     output_df = output_df.drop(['u_in_amax','u_in_mean'], axis=1)\n",
    "    \n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_half_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    output_df['tmp'] = output_df['u_out']*(-1)+1 # inversion of u_out\n",
    "    output_df['u_in_half'] = output_df['tmp'] * output_df['u_in']\n",
    "    \n",
    "#     u_in_half_max_dict = train.groupby('breath_id')['u_in_half'].max().to_dict()\n",
    "#     train['u_in_half_max'] = train['breath_id'].map(u_in_half_max_dict)\n",
    "#     u_in_half_min_dict = train.groupby('breath_id')['u_in_half'].min().to_dict()\n",
    "#     train['u_in_half_min'] = train['breath_id'].map(u_in_half_min_dict)\n",
    "    u_in_half_mean_dict = output_df.groupby('breath_id')['u_in_half'].mean().to_dict()\n",
    "    output_df['u_in_half_mean'] = output_df['breath_id'].map(u_in_half_mean_dict)\n",
    "#     u_in_half_std_dict = train.groupby('breath_id')['u_in_half'].std().to_dict()\n",
    "#     train['u_in_half_std'] = train['breath_id'].map(u_in_half_std_dict)\n",
    "\n",
    "    del output_df['u_in_half'], output_df['tmp']\n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass_filter(series, b, a):\n",
    "    return signal.filtfilt(b, a, series)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    fp = 5 # 通過域端周波数[Hz]\n",
    "    fs = 10 # 阻止域端周波数[Hz]\n",
    "    gpass = 3 # 通過域端最大損失[dB]\n",
    "    gstop = 40 # 阻止域端最小損失[dB]\n",
    "    samplerate = 100\n",
    "\n",
    "    fn = samplerate / 2   #ナイキスト周波数\n",
    "    wp = fp / fn  #ナイキスト周波数で通過域端周波数を正規化\n",
    "    ws = fs / fn  #ナイキスト周波数で阻止域端周波数を正規化\n",
    "    N, Wn = signal.buttord(wp, ws, gpass, gstop)  #オーダーとバターワースの正規化周波数を計算\n",
    "    b, a = signal.butter(N, Wn, \"low\")            #フィルタ伝達関数の分子と分母を計算\n",
    "    \n",
    "    def get_agg_window(start_time=0, end_time=3.0, add_suffix = False):\n",
    "        \n",
    "        df_tgt = output_df[(output_df['time_step'] >= start_time) & (output_df['time_step'] <= end_time)]\n",
    "        df_feature = df_tgt.groupby(['breath_id'])['u_in'].apply(lowpass_filter, b=b, a=a)\n",
    "        df_feature.name = 'u_in_filter'\n",
    "                    \n",
    "        return df_feature\n",
    "    \n",
    "    df_agg_feature = get_agg_window().reset_index()\n",
    "    df_agg_feature = df_agg_feature.explode(\"u_in_filter\").reset_index(drop=True)\n",
    "    df_agg_feature['u_in_filter'] = df_agg_feature['u_in_filter'].astype(float)\n",
    "        \n",
    "    df_agg_feature['u_in_filter_cumsum'] = df_agg_feature.groupby('breath_id')['u_in_filter'].cumsum()\n",
    "\n",
    "    return df_agg_feature.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vib_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    output_df['u_out_diff'] = output_df['u_out'].diff()\n",
    "    output_df['u_out_diff'].fillna(0, inplace=True)\n",
    "    output_df['u_out_diff'].replace(-1, 0, inplace=True)\n",
    "    uout1_df = output_df[output_df['u_out_diff']==1]\n",
    "    \n",
    "    first_df = output_df.loc[0::80,:]\n",
    "    first_0_dict = dict(zip(first_df['id'], [0]*len(uout1_df)))\n",
    "\n",
    "    output_df['u_in_diff'] = output_df['u_in'].diff()\n",
    "    output_df['diff_sign'] = np.sign(output_df['u_in_diff'])\n",
    "    output_df['sign_diff'] = output_df['diff_sign'].diff()\n",
    "    output_df['tmp'] = output_df['id'].map(first_0_dict) # put 0, the 80row cycle\n",
    "    output_df.iloc[0::80, output_df.columns.get_loc('sign_diff')] = output_df.iloc[0::80, output_df.columns.get_loc('tmp')]\n",
    "\n",
    "    # Count the number of inversions, so take the absolute value and sum\n",
    "    output_df['sign_diff'] = abs(output_df['sign_diff']) \n",
    "    sign_diff_dict = output_df.groupby('breath_id')['sign_diff'].sum().to_dict()\n",
    "    output_df['diff_vib'] = output_df['breath_id'].map(sign_diff_dict)\n",
    "    \n",
    "    return output_df['sign_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(out_df, input_df, dataType = 'train'):\n",
    "\n",
    "    USE_LAG = [-2, -1, 1, 2, 3, 4]\n",
    "    lag_map = {-2: 1, -1: 2, 1: 3, 2: 4, 3: 5, 4: 6}\n",
    "\n",
    "    out_df['breath_id'] = input_df['breath_id']\n",
    "    \n",
    "    for lag in USE_LAG:\n",
    "        out_df[f'breath_id_lag{lag_map[lag]}']=out_df['breath_id'].shift(lag).fillna(0)\n",
    "        out_df[f'breath_id_lag{lag_map[lag]}same']=np.select([out_df[f'breath_id_lag{lag_map[lag]}']==out_df['breath_id']], [1], 0)\n",
    "\n",
    "        # u_in_filter\n",
    "        out_df[f'u_in_filter_lag_{lag_map[lag]}'] = out_df['u_in_filter'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "        out_df[f'u_in_filter_diff_{lag_map[lag]}'] = out_df['u_in_filter'] - out_df[f'u_in_filter_lag_{lag_map[lag]}']\n",
    "        # u_in_sqrt\n",
    "        out_df[f'u_in_sqrt_lag_{lag_map[lag]}'] = out_df['u_in_sqrt'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "        out_df[f'u_in_sqrt_diff_{lag_map[lag]}'] = out_df['u_in_sqrt'] - out_df[f'u_in_sqrt_lag_{lag_map[lag]}']\n",
    "\n",
    "        # u_in \n",
    "        out_df[f'u_in_lag_{lag_map[lag]}'] = out_df['u_in'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "        out_df[f'u_in_diff_{lag_map[lag]}'] = out_df['u_in'] - out_df[f'u_in_lag_{lag_map[lag]}']\n",
    "        # u_out\n",
    "        out_df[f'u_out_lag_{lag_map[lag]}'] = out_df['u_out'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "\n",
    "        # breath_time\n",
    "    out_df[f'time_step_lag_{1}'] = out_df['time_step'].shift(1).fillna(0) * out_df[f'breath_id_lag{1}same']\n",
    "    out_df[f'time_step_diff_{1}'] = out_df['time_step'] - out_df[f'time_step_lag_{1}']\n",
    "        \n",
    "    drop_columns = ['breath_id', 'time_step_lag_1']\n",
    "    drop_columns += [f'breath_id_lag{lag_map[i]}' for i in USE_LAG]\n",
    "    drop_columns += [f'breath_id_lag{lag_map[i]}same' for i in USE_LAG]\n",
    "    out_df = out_df.drop(drop_columns, axis=1)\n",
    "    out_df = out_df.fillna(0)\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    for i in range(len(pred_cols)):\n",
    "        output_df[f\"pred_{i}\"] = 0.\n",
    "        output_df.loc[oof[\"u_out\"] == 0, f\"pred_{i}\"] = _oof[f\"oof{i}\"].values\n",
    "    \n",
    "\n",
    "    \n",
    "    return output_df['sign_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_feature(input_df, dataType = 'train'):\n",
    "    \"\"\"input_df を特徴量行列に変換した新しいデータフレームを返す.\n",
    "    \"\"\"\n",
    "\n",
    "    processors = [\n",
    "        get_raw_features,\n",
    "#         get_simple_calc_features,\n",
    "#         get_agg_features,\n",
    "#         get_vib_features,\n",
    "#         get_half_features,\n",
    "        get_category_features,\n",
    "#         get_filter_features,\n",
    "    ]\n",
    "\n",
    "    out_df = pd.DataFrame()\n",
    "\n",
    "    for func in tqdm(processors, total=len(processors)):\n",
    "        with Timer(prefix='' + func.__name__ + ' '):\n",
    "            _df = func(input_df, dataType)\n",
    "\n",
    "        # 長さが等しいことをチェック (ずれている場合, func の実装がおかしい)\n",
    "        assert len(_df) == len(input_df), func.__name__\n",
    "        out_df = pd.concat([out_df, _df], axis=1)\n",
    "#     out_df = utils.reduce_mem_usage(out_df)\n",
    "#     out_df = add_time_features(out_df, input_df)\n",
    "    out_df_cols = sorted(list(out_df))\n",
    "    out_df = out_df[out_df_cols]\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_raw_features  0.030[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_category_features  2.380[s]\n",
      "get_raw_features  0.019[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_category_features  1.623[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = to_feature(train, dataType = 'train')\n",
    "test_df = to_feature(test, dataType = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = [f\"pred_{i}\" for i in range(len(oofs.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_oof_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    if dataType == 'train':\n",
    "        for i in range(len(pred_cols)):\n",
    "            input_df[f\"pred_{i}\"] = 0.\n",
    "            input_df.loc[train[\"u_out\"] == 0, f\"pred_{i}\"] = oofs[f\"pred_{i}\"].values\n",
    "        input_df['breath_id'] = train['breath_id']\n",
    "        input_df = train_df.loc[train[\"u_out\"] == 0].reset_index(drop=True)\n",
    "    else:\n",
    "        for i in range(len(pred_cols)):\n",
    "            input_df[f\"pred_{i}\"] = 0.\n",
    "            input_df.loc[:, f\"pred_{i}\"] = subs[f\"pred_{i}\"].values\n",
    "        input_df['breath_id'] = test['breath_id']\n",
    "        input_df = input_df.loc[test[\"u_out\"] == 0].reset_index(drop=True)\n",
    "      \n",
    "    # v2\n",
    "    input_df[\"pred_mean\"] = np.mean(input_df[pred_cols].values, axis=1)\n",
    "    input_df[\"pred_median\"] = np.median(input_df[pred_cols].values, axis=1)\n",
    "\n",
    "    input_df[\"pred_std\"] = input_df[pred_cols].std(axis=1)\n",
    "    input_df[\"pred_max\"] = input_df[pred_cols].values.max(axis=1)\n",
    "    input_df[\"pred_min\"] = input_df[pred_cols].values.min(axis=1)\n",
    "    input_df[\"pred_max-min\"] = input_df[\"pred_max\"] - input_df[\"pred_min\"]\n",
    "    input_df[\"pred_max-median\"] = input_df[\"pred_max\"] - input_df[\"pred_median\"]\n",
    "    input_df[\"pred_max-mean\"] = input_df[\"pred_max\"] - input_df[\"pred_mean\"]\n",
    "    input_df[\"pred_median-min\"] = input_df[\"pred_median\"] - input_df[\"pred_min\"]\n",
    "    input_df[\"pred_mean-min\"] = input_df[\"pred_mean\"] - input_df[\"pred_min\"]\n",
    "    input_df[\"pred_mean-median\"] = input_df[\"pred_mean\"] - input_df[\"pred_median\"]\n",
    "    input_df[\"pred_kurt\"] = input_df[pred_cols].kurt(axis=1)\n",
    "    for col_ in pred_cols:\n",
    "        input_df[f\"{col_}_past_1\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(1)\n",
    "        input_df[f\"{col_}_past_2\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(2)\n",
    "        input_df[f\"{col_}_past_3\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(3)\n",
    "        input_df[f\"{col_}_past_4\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(4)\n",
    "\n",
    "        input_df[f\"{col_}_diff_1\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_1\"]\n",
    "        input_df[f\"{col_}_diff_2\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_2\"]\n",
    "        input_df[f\"{col_}_diff_3\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_3\"]\n",
    "        input_df[f\"{col_}_diff_4\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_4\"]\n",
    "\n",
    "    input_df[\"u_in_past_1\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(1)\n",
    "    input_df[\"u_in_past_2\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(2)\n",
    "    input_df[\"u_in_past_3\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(3)\n",
    "    input_df[\"u_in_past_4\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(4)\n",
    "\n",
    "    input_df[\"u_in_diff_1\"] = input_df[\"u_in\"] - input_df[\"u_in_past_1\"]\n",
    "    input_df[\"u_in_diff_2\"] = input_df[\"u_in\"] - input_df[\"u_in_past_2\"]\n",
    "    input_df[\"u_in_diff_3\"] = input_df[\"u_in\"] - input_df[\"u_in_past_3\"]\n",
    "    input_df[\"u_in_diff_4\"] = input_df[\"u_in\"] - input_df[\"u_in_past_4\"]\n",
    "\n",
    "    input_df[\"u_in_cumsum\"] = input_df.groupby(\"breath_id\")[\"u_in\"].cumsum()\n",
    "\n",
    "    del input_df['breath_id']\n",
    "    \n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_oof_features(train_df, dataType = 'train')\n",
    "test_df = add_oof_features(test_df, dataType = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>R</th>\n",
       "      <th>R_C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_11_diff_4</th>\n",
       "      <th>u_in_past_1</th>\n",
       "      <th>u_in_past_2</th>\n",
       "      <th>u_in_past_3</th>\n",
       "      <th>u_in_past_4</th>\n",
       "      <th>u_in_diff_1</th>\n",
       "      <th>u_in_diff_2</th>\n",
       "      <th>u_in_diff_3</th>\n",
       "      <th>u_in_diff_4</th>\n",
       "      <th>u_in_cumsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>6.051358</td>\n",
       "      <td>6.008679</td>\n",
       "      <td>5.839750</td>\n",
       "      <td>5.916682</td>\n",
       "      <td>5.907529</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>5.901721</td>\n",
       "      <td>5.824164</td>\n",
       "      <td>5.896797</td>\n",
       "      <td>5.886481</td>\n",
       "      <td>5.899961</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.299707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.466375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>8.389902</td>\n",
       "      <td>8.267651</td>\n",
       "      <td>8.516665</td>\n",
       "      <td>8.561444</td>\n",
       "      <td>8.385892</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.126236</td>\n",
       "      <td>22.425944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.975653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>12.343451</td>\n",
       "      <td>12.020198</td>\n",
       "      <td>12.398529</td>\n",
       "      <td>12.385787</td>\n",
       "      <td>12.373862</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.299544</td>\n",
       "      <td>4.425781</td>\n",
       "      <td>22.725488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.784476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>12.681964</td>\n",
       "      <td>12.505707</td>\n",
       "      <td>12.786497</td>\n",
       "      <td>12.760039</td>\n",
       "      <td>12.763080</td>\n",
       "      <td>...</td>\n",
       "      <td>6.749109</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>2.547028</td>\n",
       "      <td>2.846573</td>\n",
       "      <td>6.972809</td>\n",
       "      <td>25.272516</td>\n",
       "      <td>89.140326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290963</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.834147</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>29.430931</td>\n",
       "      <td>29.476478</td>\n",
       "      <td>29.435886</td>\n",
       "      <td>29.438047</td>\n",
       "      <td>29.445435</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046318</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>2.438287</td>\n",
       "      <td>3.783043</td>\n",
       "      <td>3.209590</td>\n",
       "      <td>-0.780965</td>\n",
       "      <td>-0.568920</td>\n",
       "      <td>-1.913676</td>\n",
       "      <td>-1.340223</td>\n",
       "      <td>238.890288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290964</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.867574</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>29.093206</td>\n",
       "      <td>29.113724</td>\n",
       "      <td>29.106075</td>\n",
       "      <td>29.106499</td>\n",
       "      <td>29.109507</td>\n",
       "      <td>...</td>\n",
       "      <td>1.318443</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>2.438287</td>\n",
       "      <td>3.783043</td>\n",
       "      <td>0.285047</td>\n",
       "      <td>-0.495918</td>\n",
       "      <td>-0.283873</td>\n",
       "      <td>-1.628629</td>\n",
       "      <td>241.044703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290965</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.900917</td>\n",
       "      <td>1.304434</td>\n",
       "      <td>29.850384</td>\n",
       "      <td>29.908362</td>\n",
       "      <td>29.861372</td>\n",
       "      <td>29.865599</td>\n",
       "      <td>29.871944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840777</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>2.438287</td>\n",
       "      <td>-0.849980</td>\n",
       "      <td>-0.564933</td>\n",
       "      <td>-1.345899</td>\n",
       "      <td>-1.133853</td>\n",
       "      <td>242.349137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290966</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.934309</td>\n",
       "      <td>1.733830</td>\n",
       "      <td>29.370970</td>\n",
       "      <td>29.400613</td>\n",
       "      <td>29.380976</td>\n",
       "      <td>29.381800</td>\n",
       "      <td>29.382881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617472</td>\n",
       "      <td>1.304434</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>0.429396</td>\n",
       "      <td>-0.420585</td>\n",
       "      <td>-0.135538</td>\n",
       "      <td>-0.916503</td>\n",
       "      <td>244.082966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290967</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.967743</td>\n",
       "      <td>0.958726</td>\n",
       "      <td>30.061115</td>\n",
       "      <td>30.085098</td>\n",
       "      <td>30.059231</td>\n",
       "      <td>30.062292</td>\n",
       "      <td>30.062634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612473</td>\n",
       "      <td>1.733830</td>\n",
       "      <td>1.304434</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>-0.775103</td>\n",
       "      <td>-0.345708</td>\n",
       "      <td>-1.195688</td>\n",
       "      <td>-0.910641</td>\n",
       "      <td>245.041693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2290968 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C   R  R_C  time_step       u_in     pred_0     pred_1     pred_2  \\\n",
       "0        50  20    5   0.000000   0.083334   6.051358   6.008679   5.839750   \n",
       "1        50  20    5   0.033652  18.383041   5.901721   5.824164   5.896797   \n",
       "2        50  20    5   0.067514  22.509278   8.389902   8.267651   8.516665   \n",
       "3        50  20    5   0.101542  22.808822  12.343451  12.020198  12.398529   \n",
       "4        50  20    5   0.135756  25.355850  12.681964  12.505707  12.786497   \n",
       "...      ..  ..  ...        ...        ...        ...        ...        ...   \n",
       "2290963  10  50    6   0.834147   1.869367  29.430931  29.476478  29.435886   \n",
       "2290964  10  50    6   0.867574   2.154414  29.093206  29.113724  29.106075   \n",
       "2290965  10  50    6   0.900917   1.304434  29.850384  29.908362  29.861372   \n",
       "2290966  10  50    6   0.934309   1.733830  29.370970  29.400613  29.380976   \n",
       "2290967  10  50    6   0.967743   0.958726  30.061115  30.085098  30.059231   \n",
       "\n",
       "            pred_3     pred_4  ...  pred_11_diff_4  u_in_past_1  u_in_past_2  \\\n",
       "0         5.916682   5.907529  ...             NaN          NaN          NaN   \n",
       "1         5.886481   5.899961  ...             NaN     0.083334          NaN   \n",
       "2         8.561444   8.385892  ...             NaN    18.383041     0.083334   \n",
       "3        12.385787  12.373862  ...             NaN    22.509278    18.383041   \n",
       "4        12.760039  12.763080  ...        6.749109    22.808822    22.509278   \n",
       "...            ...        ...  ...             ...          ...          ...   \n",
       "2290963  29.438047  29.445435  ...        1.046318     2.650333     2.438287   \n",
       "2290964  29.106499  29.109507  ...        1.318443     1.869367     2.650333   \n",
       "2290965  29.865599  29.871944  ...        0.840777     2.154414     1.869367   \n",
       "2290966  29.381800  29.382881  ...        0.617472     1.304434     2.154414   \n",
       "2290967  30.062292  30.062634  ...        0.612473     1.733830     1.304434   \n",
       "\n",
       "         u_in_past_3  u_in_past_4  u_in_diff_1  u_in_diff_2  u_in_diff_3  \\\n",
       "0                NaN          NaN          NaN          NaN          NaN   \n",
       "1                NaN          NaN    18.299707          NaN          NaN   \n",
       "2                NaN          NaN     4.126236    22.425944          NaN   \n",
       "3           0.083334          NaN     0.299544     4.425781    22.725488   \n",
       "4          18.383041     0.083334     2.547028     2.846573     6.972809   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "2290963     3.783043     3.209590    -0.780965    -0.568920    -1.913676   \n",
       "2290964     2.438287     3.783043     0.285047    -0.495918    -0.283873   \n",
       "2290965     2.650333     2.438287    -0.849980    -0.564933    -1.345899   \n",
       "2290966     1.869367     2.650333     0.429396    -0.420585    -0.135538   \n",
       "2290967     2.154414     1.869367    -0.775103    -0.345708    -1.195688   \n",
       "\n",
       "         u_in_diff_4  u_in_cumsum  \n",
       "0                NaN     0.083334  \n",
       "1                NaN    18.466375  \n",
       "2                NaN    40.975653  \n",
       "3                NaN    63.784476  \n",
       "4          25.272516    89.140326  \n",
       "...              ...          ...  \n",
       "2290963    -1.340223   238.890288  \n",
       "2290964    -1.628629   241.044703  \n",
       "2290965    -1.133853   242.349137  \n",
       "2290966    -0.916503   244.082966  \n",
       "2290967    -0.910641   245.041693  \n",
       "\n",
       "[2290968 rows x 134 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>R</th>\n",
       "      <th>R_C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_11_diff_4</th>\n",
       "      <th>u_in_past_1</th>\n",
       "      <th>u_in_past_2</th>\n",
       "      <th>u_in_past_3</th>\n",
       "      <th>u_in_past_4</th>\n",
       "      <th>u_in_diff_1</th>\n",
       "      <th>u_in_diff_2</th>\n",
       "      <th>u_in_diff_3</th>\n",
       "      <th>u_in_diff_4</th>\n",
       "      <th>u_in_cumsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.122457</td>\n",
       "      <td>6.234838</td>\n",
       "      <td>6.228402</td>\n",
       "      <td>6.223941</td>\n",
       "      <td>6.215096</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>5.897243</td>\n",
       "      <td>5.966046</td>\n",
       "      <td>5.976529</td>\n",
       "      <td>5.962824</td>\n",
       "      <td>5.969975</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.515046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.116149</td>\n",
       "      <td>7.154629</td>\n",
       "      <td>7.155302</td>\n",
       "      <td>7.151405</td>\n",
       "      <td>7.149951</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.136630</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.166721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>7.687282</td>\n",
       "      <td>7.767205</td>\n",
       "      <td>7.695719</td>\n",
       "      <td>7.696728</td>\n",
       "      <td>7.700007</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.578935</td>\n",
       "      <td>13.715564</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.397331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>9.229881</td>\n",
       "      <td>9.256029</td>\n",
       "      <td>9.214653</td>\n",
       "      <td>9.217604</td>\n",
       "      <td>9.215394</td>\n",
       "      <td>...</td>\n",
       "      <td>2.993951</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.090346</td>\n",
       "      <td>11.669281</td>\n",
       "      <td>18.805911</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>69.718287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527560</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.842145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.105703</td>\n",
       "      <td>10.115388</td>\n",
       "      <td>10.103384</td>\n",
       "      <td>10.102245</td>\n",
       "      <td>10.104448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.839645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527561</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.094866</td>\n",
       "      <td>10.101979</td>\n",
       "      <td>10.089975</td>\n",
       "      <td>10.088987</td>\n",
       "      <td>10.092776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.839645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527562</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.909185</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>9.985191</td>\n",
       "      <td>9.985294</td>\n",
       "      <td>9.983527</td>\n",
       "      <td>9.980724</td>\n",
       "      <td>9.980343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>68.961019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527563</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.943148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.079302</td>\n",
       "      <td>10.056884</td>\n",
       "      <td>10.080218</td>\n",
       "      <td>10.079402</td>\n",
       "      <td>10.080560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059823</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.961019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527564</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.976815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.078142</td>\n",
       "      <td>10.069474</td>\n",
       "      <td>10.073240</td>\n",
       "      <td>10.072607</td>\n",
       "      <td>10.075235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.961019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527565 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C   R  R_C  time_step       u_in     pred_0     pred_1     pred_2  \\\n",
       "0        20   5    1   0.000000   0.000000   6.122457   6.234838   6.228402   \n",
       "1        20   5    1   0.031904   7.515046   5.897243   5.966046   5.976529   \n",
       "2        20   5    1   0.063827  14.651675   7.116149   7.154629   7.155302   \n",
       "3        20   5    1   0.095751  21.230610   7.687282   7.767205   7.695719   \n",
       "4        20   5    1   0.127644  26.320956   9.229881   9.256029   9.214653   \n",
       "...      ..  ..  ...        ...        ...        ...        ...        ...   \n",
       "1527560  10  20    3   0.842145   0.000000  10.105703  10.115388  10.103384   \n",
       "1527561  10  20    3   0.875648   0.000000  10.094866  10.101979  10.089975   \n",
       "1527562  10  20    3   0.909185   0.121375   9.985191   9.985294   9.983527   \n",
       "1527563  10  20    3   0.943148   0.000000  10.079302  10.056884  10.080218   \n",
       "1527564  10  20    3   0.976815   0.000000  10.078142  10.069474  10.073240   \n",
       "\n",
       "            pred_3     pred_4  ...  pred_11_diff_4  u_in_past_1  u_in_past_2  \\\n",
       "0         6.223941   6.215096  ...             NaN          NaN          NaN   \n",
       "1         5.962824   5.969975  ...             NaN     0.000000          NaN   \n",
       "2         7.151405   7.149951  ...             NaN     7.515046     0.000000   \n",
       "3         7.696728   7.700007  ...             NaN    14.651675     7.515046   \n",
       "4         9.217604   9.215394  ...        2.993951    21.230610    14.651675   \n",
       "...            ...        ...  ...             ...          ...          ...   \n",
       "1527560  10.102245  10.104448  ...        0.021388     0.000000     0.000000   \n",
       "1527561  10.088987  10.092776  ...       -0.038626     0.000000     0.000000   \n",
       "1527562   9.980724   9.980343  ...       -0.145053     0.000000     0.000000   \n",
       "1527563  10.079402  10.080560  ...       -0.059823     0.121375     0.000000   \n",
       "1527564  10.072607  10.075235  ...       -0.043812     0.000000     0.121375   \n",
       "\n",
       "         u_in_past_3  u_in_past_4  u_in_diff_1  u_in_diff_2  u_in_diff_3  \\\n",
       "0                NaN          NaN          NaN          NaN          NaN   \n",
       "1                NaN          NaN     7.515046          NaN          NaN   \n",
       "2                NaN          NaN     7.136630    14.651675          NaN   \n",
       "3           0.000000          NaN     6.578935    13.715564    21.230610   \n",
       "4           7.515046          0.0     5.090346    11.669281    18.805911   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "1527560     0.000000          0.0     0.000000     0.000000     0.000000   \n",
       "1527561     0.000000          0.0     0.000000     0.000000     0.000000   \n",
       "1527562     0.000000          0.0     0.121375     0.121375     0.121375   \n",
       "1527563     0.000000          0.0    -0.121375     0.000000     0.000000   \n",
       "1527564     0.000000          0.0     0.000000    -0.121375     0.000000   \n",
       "\n",
       "         u_in_diff_4  u_in_cumsum  \n",
       "0                NaN     0.000000  \n",
       "1                NaN     7.515046  \n",
       "2                NaN    22.166721  \n",
       "3                NaN    43.397331  \n",
       "4          26.320956    69.718287  \n",
       "...              ...          ...  \n",
       "1527560     0.000000    68.839645  \n",
       "1527561     0.000000    68.839645  \n",
       "1527562     0.121375    68.961019  \n",
       "1527563     0.000000    68.961019  \n",
       "1527564     0.000000    68.961019  \n",
       "\n",
       "[1527565 rows x 134 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train_df), display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_category_col = ['R_C']\n",
    "train_value_col = [i for i in train_df.columns.to_list() if i not in train_category_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_features = train_value_col\n",
    "# train_df = train_df.fillna(0)\n",
    "# test_df = test_df.fillna(0)\n",
    "# scaler = RobustScaler()\n",
    "# scaler.fit(train_df[norm_features])\n",
    "# train_df[norm_features] = scaler.transform(train_df[norm_features].values)\n",
    "# test_df[norm_features] = scaler.transform(test_df[norm_features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.loc[train[\"u_out\"] == 0]['pressure'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train.loc[train[\"u_out\"] == 0, ['id', 'breath_id', 'pressure']].reset_index(drop=True)], axis=1)\n",
    "test_df = pd.concat([test_df, test.loc[test[\"u_out\"] == 0,['id', 'breath_id']].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.428567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 508288\n",
      "[LightGBM] [Info] Number of data points in the train set: 1832919, number of used features: 133\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.129923\tvalid_1's l1: 0.129789\n",
      "[200]\ttraining's l1: 0.123677\tvalid_1's l1: 0.123848\n",
      "[300]\ttraining's l1: 0.121276\tvalid_1's l1: 0.121532\n",
      "[400]\ttraining's l1: 0.120021\tvalid_1's l1: 0.12037\n",
      "[500]\ttraining's l1: 0.119213\tvalid_1's l1: 0.119716\n",
      "[600]\ttraining's l1: 0.118689\tvalid_1's l1: 0.119341\n",
      "[700]\ttraining's l1: 0.118147\tvalid_1's l1: 0.118963\n",
      "[800]\ttraining's l1: 0.117868\tvalid_1's l1: 0.118852\n",
      "[900]\ttraining's l1: 0.117616\tvalid_1's l1: 0.118731\n",
      "[1000]\ttraining's l1: 0.117377\tvalid_1's l1: 0.118598\n",
      "[1100]\ttraining's l1: 0.11718\tvalid_1's l1: 0.118475\n",
      "[1200]\ttraining's l1: 0.116971\tvalid_1's l1: 0.118372\n",
      "[1300]\ttraining's l1: 0.116735\tvalid_1's l1: 0.118288\n",
      "[1400]\ttraining's l1: 0.116546\tvalid_1's l1: 0.118198\n",
      "[1500]\ttraining's l1: 0.116388\tvalid_1's l1: 0.118161\n",
      "[1600]\ttraining's l1: 0.116247\tvalid_1's l1: 0.118134\n",
      "[1700]\ttraining's l1: 0.116074\tvalid_1's l1: 0.118057\n",
      "[1800]\ttraining's l1: 0.115975\tvalid_1's l1: 0.118022\n",
      "[1900]\ttraining's l1: 0.115855\tvalid_1's l1: 0.117975\n",
      "[2000]\ttraining's l1: 0.115753\tvalid_1's l1: 0.117928\n",
      "[2100]\ttraining's l1: 0.115633\tvalid_1's l1: 0.117905\n",
      "[2200]\ttraining's l1: 0.115528\tvalid_1's l1: 0.1179\n",
      "[2300]\ttraining's l1: 0.115431\tvalid_1's l1: 0.117898\n",
      "[2400]\ttraining's l1: 0.115344\tvalid_1's l1: 0.117895\n",
      "[2500]\ttraining's l1: 0.115227\tvalid_1's l1: 0.117877\n",
      "[2600]\ttraining's l1: 0.115122\tvalid_1's l1: 0.117859\n",
      "[2700]\ttraining's l1: 0.115046\tvalid_1's l1: 0.117818\n",
      "[2800]\ttraining's l1: 0.11497\tvalid_1's l1: 0.117792\n",
      "[2900]\ttraining's l1: 0.114893\tvalid_1's l1: 0.117753\n",
      "[3000]\ttraining's l1: 0.114789\tvalid_1's l1: 0.117737\n",
      "[3100]\ttraining's l1: 0.114693\tvalid_1's l1: 0.11773\n",
      "[3200]\ttraining's l1: 0.114583\tvalid_1's l1: 0.117725\n",
      "[3300]\ttraining's l1: 0.114505\tvalid_1's l1: 0.117718\n",
      "[3400]\ttraining's l1: 0.114422\tvalid_1's l1: 0.117711\n",
      "[3500]\ttraining's l1: 0.11432\tvalid_1's l1: 0.117716\n",
      "[3600]\ttraining's l1: 0.114242\tvalid_1's l1: 0.117714\n",
      "Early stopping, best iteration is:\n",
      "[3402]\ttraining's l1: 0.114414\tvalid_1's l1: 0.117707\n",
      "fold = 0, score = 0.11770670684333409\n",
      "Fold-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.428470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 508288\n",
      "[LightGBM] [Info] Number of data points in the train set: 1832894, number of used features: 133\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.129394\tvalid_1's l1: 0.128448\n",
      "[200]\ttraining's l1: 0.124529\tvalid_1's l1: 0.124173\n",
      "[300]\ttraining's l1: 0.121252\tvalid_1's l1: 0.121049\n",
      "[400]\ttraining's l1: 0.119746\tvalid_1's l1: 0.119696\n",
      "[500]\ttraining's l1: 0.119028\tvalid_1's l1: 0.119084\n",
      "[600]\ttraining's l1: 0.118418\tvalid_1's l1: 0.118624\n",
      "[700]\ttraining's l1: 0.11803\tvalid_1's l1: 0.118373\n",
      "[800]\ttraining's l1: 0.117686\tvalid_1's l1: 0.118194\n",
      "[900]\ttraining's l1: 0.117454\tvalid_1's l1: 0.118069\n",
      "[1000]\ttraining's l1: 0.11727\tvalid_1's l1: 0.117969\n",
      "[1100]\ttraining's l1: 0.11708\tvalid_1's l1: 0.117862\n",
      "[1200]\ttraining's l1: 0.116859\tvalid_1's l1: 0.11776\n",
      "[1300]\ttraining's l1: 0.116724\tvalid_1's l1: 0.117698\n",
      "[1400]\ttraining's l1: 0.116599\tvalid_1's l1: 0.117666\n",
      "[1500]\ttraining's l1: 0.116438\tvalid_1's l1: 0.11762\n",
      "[1600]\ttraining's l1: 0.116303\tvalid_1's l1: 0.117583\n",
      "[1700]\ttraining's l1: 0.116163\tvalid_1's l1: 0.117554\n",
      "[1800]\ttraining's l1: 0.116038\tvalid_1's l1: 0.11753\n",
      "[1900]\ttraining's l1: 0.115921\tvalid_1's l1: 0.117485\n",
      "[2000]\ttraining's l1: 0.115814\tvalid_1's l1: 0.117456\n",
      "[2100]\ttraining's l1: 0.115714\tvalid_1's l1: 0.117443\n",
      "[2200]\ttraining's l1: 0.115596\tvalid_1's l1: 0.117436\n",
      "[2300]\ttraining's l1: 0.1155\tvalid_1's l1: 0.117426\n",
      "[2400]\ttraining's l1: 0.115404\tvalid_1's l1: 0.117419\n",
      "[2500]\ttraining's l1: 0.115312\tvalid_1's l1: 0.117407\n",
      "[2600]\ttraining's l1: 0.115203\tvalid_1's l1: 0.117398\n",
      "[2700]\ttraining's l1: 0.11512\tvalid_1's l1: 0.117393\n",
      "[2800]\ttraining's l1: 0.115015\tvalid_1's l1: 0.117381\n",
      "[2900]\ttraining's l1: 0.114919\tvalid_1's l1: 0.117381\n",
      "[3000]\ttraining's l1: 0.114845\tvalid_1's l1: 0.117372\n",
      "[3100]\ttraining's l1: 0.11476\tvalid_1's l1: 0.117351\n",
      "[3200]\ttraining's l1: 0.114679\tvalid_1's l1: 0.117335\n",
      "[3300]\ttraining's l1: 0.114618\tvalid_1's l1: 0.117333\n",
      "[3400]\ttraining's l1: 0.114539\tvalid_1's l1: 0.117328\n",
      "[3500]\ttraining's l1: 0.114465\tvalid_1's l1: 0.117318\n",
      "[3600]\ttraining's l1: 0.11439\tvalid_1's l1: 0.117311\n",
      "[3700]\ttraining's l1: 0.114315\tvalid_1's l1: 0.117284\n",
      "[3800]\ttraining's l1: 0.114231\tvalid_1's l1: 0.117281\n",
      "[3900]\ttraining's l1: 0.114163\tvalid_1's l1: 0.117271\n",
      "[4000]\ttraining's l1: 0.114085\tvalid_1's l1: 0.117253\n",
      "[4100]\ttraining's l1: 0.114028\tvalid_1's l1: 0.117237\n",
      "[4200]\ttraining's l1: 0.113964\tvalid_1's l1: 0.117217\n",
      "[4300]\ttraining's l1: 0.113911\tvalid_1's l1: 0.117212\n",
      "[4400]\ttraining's l1: 0.113852\tvalid_1's l1: 0.117205\n",
      "[4500]\ttraining's l1: 0.113803\tvalid_1's l1: 0.117198\n",
      "[4600]\ttraining's l1: 0.113752\tvalid_1's l1: 0.117194\n",
      "[4700]\ttraining's l1: 0.113694\tvalid_1's l1: 0.11719\n",
      "[4800]\ttraining's l1: 0.113643\tvalid_1's l1: 0.117185\n",
      "[4900]\ttraining's l1: 0.113589\tvalid_1's l1: 0.117181\n",
      "[5000]\ttraining's l1: 0.113532\tvalid_1's l1: 0.11718\n",
      "[5100]\ttraining's l1: 0.113478\tvalid_1's l1: 0.117169\n",
      "[5200]\ttraining's l1: 0.11343\tvalid_1's l1: 0.117169\n",
      "Early stopping, best iteration is:\n",
      "[5083]\ttraining's l1: 0.113491\tvalid_1's l1: 0.117166\n",
      "fold = 1, score = 0.11716621529578906\n",
      "Fold-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.448774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 508288\n",
      "[LightGBM] [Info] Number of data points in the train set: 1832667, number of used features: 133\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.129952\tvalid_1's l1: 0.131147\n",
      "[200]\ttraining's l1: 0.123561\tvalid_1's l1: 0.124569\n",
      "[300]\ttraining's l1: 0.121184\tvalid_1's l1: 0.122198\n",
      "[400]\ttraining's l1: 0.119842\tvalid_1's l1: 0.120898\n",
      "[500]\ttraining's l1: 0.119005\tvalid_1's l1: 0.120177\n",
      "[600]\ttraining's l1: 0.118466\tvalid_1's l1: 0.119745\n",
      "[700]\ttraining's l1: 0.118102\tvalid_1's l1: 0.119512\n",
      "[800]\ttraining's l1: 0.11776\tvalid_1's l1: 0.119295\n",
      "[900]\ttraining's l1: 0.117468\tvalid_1's l1: 0.119127\n",
      "[1000]\ttraining's l1: 0.117232\tvalid_1's l1: 0.118997\n",
      "[1100]\ttraining's l1: 0.117048\tvalid_1's l1: 0.118906\n",
      "[1200]\ttraining's l1: 0.116841\tvalid_1's l1: 0.118838\n",
      "[1300]\ttraining's l1: 0.116687\tvalid_1's l1: 0.118771\n",
      "[1400]\ttraining's l1: 0.116434\tvalid_1's l1: 0.118609\n",
      "[1500]\ttraining's l1: 0.116295\tvalid_1's l1: 0.118538\n",
      "[1600]\ttraining's l1: 0.116161\tvalid_1's l1: 0.11848\n",
      "[1700]\ttraining's l1: 0.116055\tvalid_1's l1: 0.118426\n",
      "[1800]\ttraining's l1: 0.11591\tvalid_1's l1: 0.118358\n",
      "[1900]\ttraining's l1: 0.11577\tvalid_1's l1: 0.118326\n",
      "[2000]\ttraining's l1: 0.11563\tvalid_1's l1: 0.118289\n",
      "[2100]\ttraining's l1: 0.11551\tvalid_1's l1: 0.11825\n",
      "[2200]\ttraining's l1: 0.115396\tvalid_1's l1: 0.11822\n",
      "[2300]\ttraining's l1: 0.115304\tvalid_1's l1: 0.118191\n",
      "[2400]\ttraining's l1: 0.115192\tvalid_1's l1: 0.118161\n",
      "[2500]\ttraining's l1: 0.115064\tvalid_1's l1: 0.118138\n",
      "[2600]\ttraining's l1: 0.11496\tvalid_1's l1: 0.118116\n",
      "[2700]\ttraining's l1: 0.114852\tvalid_1's l1: 0.118098\n",
      "[2800]\ttraining's l1: 0.114769\tvalid_1's l1: 0.118081\n",
      "[2900]\ttraining's l1: 0.11468\tvalid_1's l1: 0.118077\n",
      "[3000]\ttraining's l1: 0.114595\tvalid_1's l1: 0.118073\n",
      "[3100]\ttraining's l1: 0.114513\tvalid_1's l1: 0.118079\n",
      "Early stopping, best iteration is:\n",
      "[2909]\ttraining's l1: 0.114669\tvalid_1's l1: 0.118071\n",
      "fold = 2, score = 0.11807093471439675\n",
      "Fold-3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.450713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 508288\n",
      "[LightGBM] [Info] Number of data points in the train set: 1832640, number of used features: 133\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.129146\tvalid_1's l1: 0.129972\n",
      "[200]\ttraining's l1: 0.122787\tvalid_1's l1: 0.12412\n",
      "[300]\ttraining's l1: 0.120641\tvalid_1's l1: 0.122149\n",
      "[400]\ttraining's l1: 0.119436\tvalid_1's l1: 0.121035\n",
      "[500]\ttraining's l1: 0.118737\tvalid_1's l1: 0.12048\n",
      "[600]\ttraining's l1: 0.118264\tvalid_1's l1: 0.120143\n",
      "[700]\ttraining's l1: 0.117816\tvalid_1's l1: 0.1199\n",
      "[800]\ttraining's l1: 0.117545\tvalid_1's l1: 0.119741\n",
      "[900]\ttraining's l1: 0.117304\tvalid_1's l1: 0.119611\n",
      "[1000]\ttraining's l1: 0.117073\tvalid_1's l1: 0.119517\n",
      "[1100]\ttraining's l1: 0.116881\tvalid_1's l1: 0.119447\n",
      "[1200]\ttraining's l1: 0.116723\tvalid_1's l1: 0.119365\n",
      "[1300]\ttraining's l1: 0.116554\tvalid_1's l1: 0.119291\n",
      "[1400]\ttraining's l1: 0.116414\tvalid_1's l1: 0.119218\n",
      "[1500]\ttraining's l1: 0.116304\tvalid_1's l1: 0.119182\n",
      "[1600]\ttraining's l1: 0.116184\tvalid_1's l1: 0.11913\n",
      "[1700]\ttraining's l1: 0.116053\tvalid_1's l1: 0.119104\n",
      "[1800]\ttraining's l1: 0.115926\tvalid_1's l1: 0.119092\n",
      "[1900]\ttraining's l1: 0.115804\tvalid_1's l1: 0.119066\n",
      "[2000]\ttraining's l1: 0.115735\tvalid_1's l1: 0.11903\n",
      "[2100]\ttraining's l1: 0.115665\tvalid_1's l1: 0.119002\n",
      "[2200]\ttraining's l1: 0.11551\tvalid_1's l1: 0.118959\n",
      "[2300]\ttraining's l1: 0.115351\tvalid_1's l1: 0.118941\n",
      "[2400]\ttraining's l1: 0.115253\tvalid_1's l1: 0.118939\n",
      "[2500]\ttraining's l1: 0.115131\tvalid_1's l1: 0.118934\n",
      "[2600]\ttraining's l1: 0.115044\tvalid_1's l1: 0.118936\n",
      "[2700]\ttraining's l1: 0.114941\tvalid_1's l1: 0.118921\n",
      "[2800]\ttraining's l1: 0.114862\tvalid_1's l1: 0.118914\n",
      "[2900]\ttraining's l1: 0.114766\tvalid_1's l1: 0.118903\n",
      "[3000]\ttraining's l1: 0.114682\tvalid_1's l1: 0.118883\n",
      "[3100]\ttraining's l1: 0.114605\tvalid_1's l1: 0.118864\n",
      "[3200]\ttraining's l1: 0.11453\tvalid_1's l1: 0.118865\n",
      "[3300]\ttraining's l1: 0.114455\tvalid_1's l1: 0.118849\n",
      "[3400]\ttraining's l1: 0.114391\tvalid_1's l1: 0.118847\n",
      "[3500]\ttraining's l1: 0.114309\tvalid_1's l1: 0.118833\n",
      "[3600]\ttraining's l1: 0.114243\tvalid_1's l1: 0.11883\n",
      "[3700]\ttraining's l1: 0.114172\tvalid_1's l1: 0.118826\n",
      "[3800]\ttraining's l1: 0.114103\tvalid_1's l1: 0.11881\n",
      "[3900]\ttraining's l1: 0.114049\tvalid_1's l1: 0.118805\n",
      "[4000]\ttraining's l1: 0.113971\tvalid_1's l1: 0.118802\n",
      "[4100]\ttraining's l1: 0.113893\tvalid_1's l1: 0.118797\n",
      "[4200]\ttraining's l1: 0.113826\tvalid_1's l1: 0.118797\n",
      "[4300]\ttraining's l1: 0.113749\tvalid_1's l1: 0.118804\n",
      "Early stopping, best iteration is:\n",
      "[4198]\ttraining's l1: 0.113829\tvalid_1's l1: 0.118796\n",
      "fold = 3, score = 0.11879644225691492\n",
      "Fold-4\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.429216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 508288\n",
      "[LightGBM] [Info] Number of data points in the train set: 1832752, number of used features: 133\n",
      "[LightGBM] [Info] Start training from score 15.890698\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.129727\tvalid_1's l1: 0.13134\n",
      "[200]\ttraining's l1: 0.12357\tvalid_1's l1: 0.124623\n",
      "[300]\ttraining's l1: 0.121073\tvalid_1's l1: 0.122035\n",
      "[400]\ttraining's l1: 0.119667\tvalid_1's l1: 0.120691\n",
      "[500]\ttraining's l1: 0.118904\tvalid_1's l1: 0.120047\n",
      "[600]\ttraining's l1: 0.118485\tvalid_1's l1: 0.11974\n",
      "[700]\ttraining's l1: 0.118058\tvalid_1's l1: 0.119397\n",
      "[800]\ttraining's l1: 0.117729\tvalid_1's l1: 0.119185\n",
      "[900]\ttraining's l1: 0.117387\tvalid_1's l1: 0.119031\n",
      "[1000]\ttraining's l1: 0.117157\tvalid_1's l1: 0.118913\n",
      "[1100]\ttraining's l1: 0.116958\tvalid_1's l1: 0.118815\n",
      "[1200]\ttraining's l1: 0.116745\tvalid_1's l1: 0.118718\n",
      "[1300]\ttraining's l1: 0.116584\tvalid_1's l1: 0.118663\n",
      "[1400]\ttraining's l1: 0.116418\tvalid_1's l1: 0.118608\n",
      "[1500]\ttraining's l1: 0.116287\tvalid_1's l1: 0.118563\n",
      "[1600]\ttraining's l1: 0.116192\tvalid_1's l1: 0.118495\n",
      "[1700]\ttraining's l1: 0.116042\tvalid_1's l1: 0.118448\n",
      "[1800]\ttraining's l1: 0.115913\tvalid_1's l1: 0.11842\n",
      "[1900]\ttraining's l1: 0.115792\tvalid_1's l1: 0.118403\n",
      "[2000]\ttraining's l1: 0.115665\tvalid_1's l1: 0.118381\n",
      "[2100]\ttraining's l1: 0.115546\tvalid_1's l1: 0.118336\n",
      "[2200]\ttraining's l1: 0.115434\tvalid_1's l1: 0.118298\n",
      "[2300]\ttraining's l1: 0.115335\tvalid_1's l1: 0.11827\n",
      "[2400]\ttraining's l1: 0.115243\tvalid_1's l1: 0.118253\n",
      "[2500]\ttraining's l1: 0.115158\tvalid_1's l1: 0.118229\n",
      "[2600]\ttraining's l1: 0.115067\tvalid_1's l1: 0.118213\n",
      "[2700]\ttraining's l1: 0.114983\tvalid_1's l1: 0.11818\n",
      "[2800]\ttraining's l1: 0.11486\tvalid_1's l1: 0.11817\n",
      "[2900]\ttraining's l1: 0.114751\tvalid_1's l1: 0.118153\n",
      "[3000]\ttraining's l1: 0.114686\tvalid_1's l1: 0.118145\n",
      "[3100]\ttraining's l1: 0.1146\tvalid_1's l1: 0.118146\n",
      "[3200]\ttraining's l1: 0.114536\tvalid_1's l1: 0.11814\n",
      "[3300]\ttraining's l1: 0.114477\tvalid_1's l1: 0.118128\n",
      "[3400]\ttraining's l1: 0.114405\tvalid_1's l1: 0.118126\n",
      "[3500]\ttraining's l1: 0.114337\tvalid_1's l1: 0.118112\n",
      "[3600]\ttraining's l1: 0.114263\tvalid_1's l1: 0.118097\n",
      "[3700]\ttraining's l1: 0.114194\tvalid_1's l1: 0.118093\n",
      "[3800]\ttraining's l1: 0.114114\tvalid_1's l1: 0.118077\n",
      "[3900]\ttraining's l1: 0.114035\tvalid_1's l1: 0.118063\n",
      "[4000]\ttraining's l1: 0.113948\tvalid_1's l1: 0.118057\n",
      "[4100]\ttraining's l1: 0.113885\tvalid_1's l1: 0.118057\n",
      "Early stopping, best iteration is:\n",
      "[3952]\ttraining's l1: 0.113984\tvalid_1's l1: 0.118049\n",
      "fold = 4, score = 0.11804922689995294\n"
     ]
    }
   ],
   "source": [
    "oof_prediction = np.zeros(len(train_df))\n",
    "test_preds_lst = []\n",
    "input_dim = len(train_value_col)\n",
    "train_df['pred'] = 0\n",
    "train_gby = train_df.groupby('breath_id')['R_C'].agg('first').reset_index()\n",
    "skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "models = []\n",
    "\n",
    "\n",
    "fold_df = pd.DataFrame()\n",
    "fold_df[\"id\"] = train[\"id\"]\n",
    "fold_df[\"fold\"] = -1\n",
    "\n",
    "for fold, (_, valid_idx) in enumerate(skf.split(train_gby, train_gby['R_C'])):        \n",
    "    valid_b_ids = train_gby.iloc[valid_idx]['breath_id'].values\n",
    "    valid_df_idx = train_df[train_df['breath_id'].isin(valid_b_ids)].index.to_list()\n",
    "    fold_df.loc[valid_df_idx, 'fold'] = fold\n",
    "\n",
    "for i, fold in enumerate(range(CFG.n_folds)):\n",
    "    if i not in CFG.folds:\n",
    "        continue\n",
    "    print(f'Fold-{fold}')\n",
    "    \n",
    "    train_idx = fold_df[fold_df[\"fold\"] != fold].index\n",
    "    valid_idx = fold_df[fold_df[\"fold\"] == fold].index\n",
    "    \n",
    "    trn_df = train_df.loc[fold_df[\"fold\"] != fold, train_value_col].reset_index(drop=True)\n",
    "    val_df = train_df.loc[fold_df[\"fold\"] == fold, train_value_col].reset_index(drop=True)\n",
    "    trn_y = train_df.loc[fold_df[\"fold\"] != fold, 'pressure'].reset_index(drop=True)\n",
    "    val_y = train_df.loc[fold_df[\"fold\"] == fold, 'pressure'].reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    lgb_train = lgb.Dataset(trn_df, trn_y)\n",
    "    lgb_valid = lgb.Dataset(val_df, val_y, reference=lgb_train)\n",
    "\n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "             'objective': 'l1',\n",
    "            'metric': 'l1',\n",
    "            'seed': CFG.seed,\n",
    "            'max_bin': 3880, \n",
    "            'min_data_in_leaf': 1217, \n",
    "            'num_leaves': 36,\n",
    "            'num_boost_round': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'lambda_l1': 0.1,\n",
    "            'lambda_l2': 0.1,\n",
    "            'n_jobs': -1\n",
    "    }\n",
    "\n",
    "\n",
    "    model = lgb.train(params, \n",
    "                      train_set=lgb_train, \n",
    "                      valid_sets=[lgb_train, lgb_valid], early_stopping_rounds=200, verbose_eval=100)\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "    oof_prediction[valid_idx] = model.predict(val_df[train_value_col])\n",
    "    test_pred = model.predict(test_df[train_value_col])\n",
    "    test_preds_lst.append(test_pred)\n",
    "    score = np.abs(val_y.values - oof_prediction[valid_idx]).mean()\n",
    "    print(f'fold = {fold}, score = {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11795801777185215"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV = np.abs(y.values - oof_prediction).mean()\n",
    "CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(OUTPUT_DIR / f\"stacking2_oof_{CFG.exp_num}\", oof_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pressures = train[\"pressure\"].unique()\n",
    "sorted_pressures = np.sort(unique_pressures)\n",
    "total_pressures_len = len(sorted_pressures)\n",
    "\n",
    "def find_nearest(prediction):\n",
    "    insert_idx = np.searchsorted(sorted_pressures, prediction)\n",
    "    if insert_idx == total_pressures_len:\n",
    "        # If the predicted value is bigger than the highest pressure in the train dataset,\n",
    "        # return the max value.\n",
    "        return sorted_pressures[-1]\n",
    "    elif insert_idx == 0:\n",
    "        # Same control but for the lower bound.\n",
    "        return sorted_pressures[0]\n",
    "    lower_val = sorted_pressures[insert_idx - 1]\n",
    "    upper_val = sorted_pressures[insert_idx]\n",
    "    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11645248154988011\n"
     ]
    }
   ],
   "source": [
    "oof = pd.DataFrame({'pred': oof_prediction})\n",
    "oof_pp = oof['pred'].map(lambda x: unique_pressures[np.abs(unique_pressures-x).argmin()])\n",
    "score = np.abs(y.values - oof_pp).mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(DATA_DIR / \"sample_submission.csv\")\n",
    "\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = np.stack(test_preds_lst).mean(0)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking2_submission_mean_{CFG.exp_num}.csv\", index=None)\n",
    "\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = np.median(np.stack(test_preds_lst), axis=0)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking2_submission_median_{CFG.exp_num}.csv\", index=None)\n",
    "\n",
    "# Post Processing: https://www.kaggle.com/snnclsr/a-dummy-approach-to-improve-your-score-postprocess\n",
    "\n",
    "\n",
    "sub_df = pd.read_csv(OUTPUT_DIR / f\"stacking2_submission_mean_{CFG.exp_num}.csv\")\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = sub_df[\"pressure\"].apply(find_nearest)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking2_submission_mean_pp_{CFG.exp_num}.csv\", index=None)\n",
    "\n",
    "sub_df = pd.read_csv(OUTPUT_DIR / f\"stacking2_submission_median_{CFG.exp_num}.csv\")\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = sub_df[\"pressure\"].apply(find_nearest)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking2_submission_median_pp_{CFG.exp_num}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5cb25c469b873a0e0eec115bfbbdb6f77ff8970c2724434dd7f3f7fbd6e0533"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
