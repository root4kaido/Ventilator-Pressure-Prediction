{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most sharing code train this dataset as a regression task.\n",
    "\n",
    "But in this code, I train as a classification task.\n",
    "\n",
    "I encode the target value pressure to 950 classes and calculate CrossEntropy Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# secret_label = \"wandb\"\n",
    "# secret_value = UserSecretsClient().get_secret(secret_label)\n",
    "# # !wandb login $secret_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import random\n",
    "# import wandb\n",
    "import math\n",
    "from pathlib import Path\n",
    "import scipy.signal\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../src/')\n",
    "import utils as utils\n",
    "from utils import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    exp_num = 53\n",
    "    n_folds = 5\n",
    "    folds = [0, 1, 2, 3, 4]\n",
    "    seed = 777\n",
    "    local = True\n",
    "    \n",
    "    lr = 0.0015\n",
    "    epochs = 100\n",
    "    emb_dim = 64\n",
    "    hidden_dim = 256\n",
    "    weight_decay = 0.1    \n",
    "    \n",
    "    ######################\n",
    "    # Loaders #\n",
    "    ######################\n",
    "    loader_params = {\n",
    "        \"train\": {\n",
    "            'batch_size': 128,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 8,\n",
    "            'pin_memory': True,\n",
    "            'drop_last': True,\n",
    "        },\n",
    "        \"valid\": {\n",
    "            'batch_size': 32,\n",
    "            'shuffle': False,\n",
    "            'num_workers': 8,\n",
    "            'pin_memory': True,\n",
    "            'drop_last': False,\n",
    "        },\n",
    "        \"test\": {\n",
    "            'batch_size': 32,\n",
    "            'shuffle': False,\n",
    "            'num_workers': 8,\n",
    "            'pin_memory': True,\n",
    "            'drop_last': False,\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.set_seed(CFG.seed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.local:\n",
    "    DATA_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/ventilator-pressure-prediction\")\n",
    "    OUTPUT_DIR = Path('./output/')\n",
    "else:\n",
    "    DATA_DIR = Path(\"../input/ventilator-pressure-prediction\")\n",
    "    OUTPUT_DIR = Path('')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_pred, y_true, u_outs):\n",
    "#     loss = nn.L1Loss()(y_pred.reshape(-1), y_true.reshape(-1))\n",
    "    w = 1 - u_outs.reshape(-1)\n",
    "    loss = nn.CrossEntropyLoss(reduction = 'none')(y_pred.reshape(-1, 950), y_true.reshape(-1)).reshape(-1)\n",
    "    loss = loss * w\n",
    "    loss = loss.sum() / w.sum()\n",
    "    return loss\n",
    "\n",
    "def compute_metric(preds, trues, u_outs):\n",
    "    \"\"\"\n",
    "    Metric for the problem, as I understood it.\n",
    "    \"\"\"\n",
    "    \n",
    "    y = trues\n",
    "    w = 1 - u_outs\n",
    "    \n",
    "    assert y.shape == preds.shape and w.shape == y.shape, (y.shape, preds.shape, w.shape)\n",
    "    \n",
    "    mae = w * np.abs(y - preds)\n",
    "    mae = mae.sum() / w.sum()\n",
    "    \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VentilatorDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, train_value_col, train_category_col, label_dic=None):\n",
    "        self.dfs = [_df for _, _df in df.groupby(\"breath_id\")]\n",
    "        self.label_dic = label_dic\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dfs)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        df = self.dfs[item]\n",
    "        X = df[train_category_col + train_value_col].values\n",
    "        u_out = df['u_out'].values\n",
    "        y = df['pressure'].values\n",
    "        if self.label_dic is None:\n",
    "            label = [-1]\n",
    "        else:\n",
    "            label = [self.label_dic[i] for i in y]\n",
    "\n",
    "        d = {\n",
    "            \"X\": torch.tensor(X).float(),\n",
    "            \"u_out\": torch.tensor(u_out).long(),\n",
    "            \"y\" : torch.tensor(label).long(),\n",
    "        }\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VentilatorModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        super(VentilatorModel, self).__init__()\n",
    "        self.rc_emb = nn.Embedding(9, 4, padding_idx=0)\n",
    "\n",
    "        self.seq_emb = nn.Sequential(\n",
    "            nn.Linear(4+input_dim, CFG.emb_dim),\n",
    "            nn.LayerNorm(CFG.emb_dim)\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(CFG.emb_dim, CFG.hidden_dim, batch_first=True, bidirectional=True, dropout=0.1, num_layers=4)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(CFG.hidden_dim * 2, CFG.hidden_dim * 2),\n",
    "            nn.LayerNorm(CFG.hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(CFG.hidden_dim * 2, 950),\n",
    "        )\n",
    "        \n",
    "        # Encoder\n",
    "        initrange = 0.1\n",
    "        self.rc_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        # LSTM\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.LSTM):\n",
    "                print(f'init {m}')\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        nn.init.normal_(param.data)\n",
    "\n",
    "    def forward(self, X, y=None):\n",
    "        # embed\n",
    "        bs = X.shape[0]\n",
    "        rc_emb = self.rc_emb(X[:,:,0].long()).view(bs, 80, -1)\n",
    "\n",
    "        seq_x = torch.cat((rc_emb, X[:, :, 1:]), 2)\n",
    "        emb_x = self.seq_emb(seq_x)\n",
    "        \n",
    "        out, _ = self.lstm(emb_x, None) \n",
    "        logits = self.head(out)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, scheduler, loader):\n",
    "    losses, lrs = [], []\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for d in loader:\n",
    "        out = model(d['X'].to(device))\n",
    "        loss = loss_fn(out, d['y'].to(device), d['u_out'].to(device))\n",
    "        losses.append(loss.item())\n",
    "        step_lr = np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean()\n",
    "        lrs.append(step_lr)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "    return np.array(losses).mean(), np.array(lrs).mean()\n",
    "\n",
    "\n",
    "def valid_loop(model, loader, target_dic_inv):\n",
    "    losses, predicts = [], []\n",
    "    model.eval()\n",
    "    for d in loader:\n",
    "        with torch.no_grad():\n",
    "            out = model(d['X'].to(device))\n",
    "            loss = loss_fn(out, d['y'].to(device), d['u_out'].to(device))\n",
    "        pred = out.reshape(-1, 950).softmax(1)\n",
    "        pred = torch.sum(torch.tensor(unique_targets).to(device) *  pred, axis=1)\n",
    "        losses.append(loss.item())\n",
    "        predicts.append(pred.cpu().numpy())\n",
    "\n",
    "    return np.array(losses).mean(), np.concatenate(predicts)\n",
    "\n",
    "def test_loop(model, loader, target_dic_inv):\n",
    "    predicts = []\n",
    "    model.eval()\n",
    "    for d in loader:\n",
    "        with torch.no_grad():\n",
    "            out = model(d['X'].to(device))\n",
    "        pred = out.reshape(-1, 950).softmax(1)\n",
    "        pred = torch.sum(torch.tensor(unique_targets).to(device) *  pred, axis=1)\n",
    "        predicts.append(pred.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_features(input_df, dataType = 'train'):\n",
    "    colum = ['time_step', 'u_in', 'u_out']\n",
    "\n",
    "    return input_df[colum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_features(input_df, dataType = 'train'):\n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    colum = ['R_C']\n",
    "    rc_map = {'5_10': 0, '5_20': 1, '5_50': 2, '20_10': 3, '20_20': 4, '20_50': 5, '50_10': 6, '50_20': 7, '50_50': 8}\n",
    "    \n",
    "    output_df['R_C'] = [f'{r}_{c}' for r, c in zip(output_df['R'], output_df['C'])]\n",
    "    output_df['R_C'] = output_df['R_C'].map(rc_map)\n",
    "\n",
    "    return output_df[colum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_calc_features(input_df, dataType = 'train'):\n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    output_df['time_delta'] = output_df.groupby('breath_id')['time_step'].diff().fillna(0)\n",
    "    output_df['delta'] = output_df['time_delta'] * output_df['u_in']\n",
    "    output_df['area'] = output_df.groupby('breath_id')['delta'].cumsum()\n",
    "\n",
    "    output_df['cross']= output_df['u_in']*output_df['u_out']\n",
    "    output_df['cross2']= output_df['time_step']*output_df['u_out']\n",
    "    \n",
    "    output_df['u_in_cumsum'] = (output_df['u_in']).groupby(output_df['breath_id']).cumsum()\n",
    "    output_df['one'] = 1\n",
    "    output_df['count'] = (output_df['one']).groupby(output_df['breath_id']).cumsum()\n",
    "    output_df['u_in_cummean'] =output_df['u_in_cumsum'] / output_df['count']\n",
    "    \n",
    "    output_df = output_df.drop(['count','one'], axis=1)\n",
    "    \n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_shift_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    USE_LAG = [-2, -1, 1, 2, 3, 4]\n",
    "    \n",
    "    for lag in USE_LAG:\n",
    "        output_df[f'breath_id_lag{lag}']=output_df['breath_id'].shift(lag).fillna(0)\n",
    "        output_df[f'breath_id_lag{lag}same']=np.select([output_df[f'breath_id_lag{lag}']==output_df['breath_id']], [1], 0)\n",
    "\n",
    "        # u_in \n",
    "        output_df[f'u_in_lag_{lag}'] = output_df['u_in'].shift(lag).fillna(0) * output_df[f'breath_id_lag{lag}same']\n",
    "        output_df[f'u_in_diff_{lag}'] = output_df['u_in'] - output_df[f'u_in_lag_{lag}']\n",
    "        output_df[f'u_out_lag_{lag}'] = output_df['u_out'].shift(lag).fillna(0) * output_df[f'breath_id_lag{lag}same']\n",
    "\n",
    "        # breath_time\n",
    "    output_df[f'time_step_lag_{1}'] = output_df['time_step'].shift(1).fillna(0) * output_df[f'breath_id_lag{1}same']\n",
    "    output_df[f'time_step_diff_{1}'] = output_df['time_step'] - output_df[f'time_step_lag_{1}']\n",
    "\n",
    "    drop_columns = ['time_step_lag_1']\n",
    "    drop_columns += [f'breath_id_lag{i}' for i in USE_LAG]\n",
    "    drop_columns += [f'breath_id_lag{i}same' for i in USE_LAG]\n",
    "    output_df = output_df.drop(drop_columns, axis=1)\n",
    "\n",
    "    # fill na by zero\n",
    "    output_df = output_df.fillna(0)\n",
    "    \n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'u_in': [np.max, np.mean],\n",
    "    }\n",
    "    \n",
    "    def get_agg_window(start_time=0, end_time=3.0, add_suffix = False):\n",
    "        \n",
    "        df_tgt = output_df[(output_df['time_step'] >= start_time) & (output_df['time_step'] <= end_time)]\n",
    "        df_feature = df_tgt.groupby(['breath_id']).agg(create_feature_dict)\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        \n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(start_time) + '_' + str(end_time))\n",
    "            \n",
    "        return df_feature\n",
    "    \n",
    "    df_agg_feature = get_agg_window().reset_index()\n",
    "    \n",
    "#     df_tmp = get_agg_window(start_time = 2, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(start_time = 1, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(end_time = 1, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(end_time = 2, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "\n",
    "    output_df = pd.merge(output_df, df_agg_feature, how='left', on='breath_id')\n",
    "    \n",
    "    output_df['u_in_diffmax'] = output_df['u_in_amax'] - output_df['u_in']\n",
    "    output_df['u_in_diffmean'] = output_df['u_in_mean'] - output_df['u_in']\n",
    "    \n",
    "#     output_df = output_df.drop(['u_in_amax','u_in_mean'], axis=1)\n",
    "    \n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass(x, samplerate, fp, fs, gpass, gstop):\n",
    "    fn = samplerate / 2   #ナイキスト周波数\n",
    "    wp = fp / fn  #ナイキスト周波数で通過域端周波数を正規化\n",
    "    ws = fs / fn  #ナイキスト周波数で阻止域端周波数を正規化\n",
    "    N, Wn = signal.buttord(wp, ws, gpass, gstop)  #オーダーとバターワースの正規化周波数を計算\n",
    "    b, a = signal.butter(N, Wn, \"low\")            #フィルタ伝達関数の分子と分母を計算\n",
    "    y = signal.filtfilt(b, a, x)                  #信号に対してフィルタをかける\n",
    "    return y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 5 # 通過域端周波数[Hz]\n",
    "fs = 10 # 阻止域端周波数[Hz]\n",
    "gpass = 3 # 通過域端最大損失[dB]\n",
    "gstop = 40 # 阻止域端最小損失[dB]\n",
    "samplerate = 100\n",
    "def lowpass_filter(series):\n",
    "    return lowpass(series, samplerate, fp, fs, gpass, gstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    def get_agg_window(start_time=0, end_time=3.0, add_suffix = False):\n",
    "        \n",
    "        df_tgt = output_df[(output_df['time_step'] >= start_time) & (output_df['time_step'] <= end_time)]\n",
    "        df_feature = df_tgt.groupby(['breath_id'])['u_in'].apply(lowpass_filter)\n",
    "        df_feature.name = 'u_in_filter'\n",
    "                    \n",
    "        return df_feature\n",
    "    \n",
    "    df_agg_feature = get_agg_window().reset_index()\n",
    "    df_agg_feature = df_agg_feature.explode(\"u_in_filter\").reset_index(drop=True)\n",
    "    \n",
    "    USE_LAG = [-2, -1, 1, 2, 3, 4]\n",
    "    \n",
    "    for lag in USE_LAG:\n",
    "        df_agg_feature[f'breath_id_lag{lag}']=df_agg_feature['breath_id'].shift(lag).fillna(0)\n",
    "        df_agg_feature[f'breath_id_lag{lag}same']=np.select([df_agg_feature[f'breath_id_lag{lag}']==df_agg_feature['breath_id']], [1], 0)\n",
    "\n",
    "        # u_in \n",
    "        df_agg_feature[f'u_in_filter_lag_{lag}'] = df_agg_feature['u_in_filter'].shift(lag).fillna(0) * df_agg_feature[f'breath_id_lag{lag}same']\n",
    "        df_agg_feature[f'u_in_filter_diff_{lag}'] = df_agg_feature['u_in_filter'] - df_agg_feature[f'u_in_filter_lag_{lag}']\n",
    "\n",
    "    drop_columns = [f'breath_id_lag{i}' for i in USE_LAG]\n",
    "    drop_columns += [f'breath_id_lag{i}same' for i in USE_LAG]\n",
    "    df_agg_feature = df_agg_feature.drop(drop_columns, axis=1)\n",
    "    df_agg_feature = df_agg_feature.fillna(0)\n",
    "    \n",
    "    return df_agg_feature.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_feature(input_df, dataType = 'train'):\n",
    "    \"\"\"input_df を特徴量行列に変換した新しいデータフレームを返す.\n",
    "    \"\"\"\n",
    "\n",
    "    processors = [\n",
    "        get_raw_features,\n",
    "        get_simple_calc_features,\n",
    "        get_diff_shift_features,\n",
    "        get_agg_features,\n",
    "        get_category_features,\n",
    "        get_filter_features\n",
    "    ]\n",
    "\n",
    "    out_df = pd.DataFrame()\n",
    "\n",
    "    for func in tqdm(processors, total=len(processors)):\n",
    "        with Timer(prefix='' + func.__name__ + ' '):\n",
    "            _df = func(input_df, dataType)\n",
    "\n",
    "        # 長さが等しいことをチェック (ずれている場合, func の実装がおかしい)\n",
    "        assert len(_df) == len(input_df), func.__name__\n",
    "        out_df = pd.concat([out_df, _df], axis=1)\n",
    "#     out_df = utils.reduce_mem_usage(out_df)\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR / 'train.csv')\n",
    "test = pd.read_csv(DATA_DIR / 'test.csv')\n",
    "sub_df = pd.read_csv(DATA_DIR / \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035995</th>\n",
       "      <td>6035996</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.504603</td>\n",
       "      <td>1.489714</td>\n",
       "      <td>1</td>\n",
       "      <td>3.869032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035996</th>\n",
       "      <td>6035997</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.537961</td>\n",
       "      <td>1.488497</td>\n",
       "      <td>1</td>\n",
       "      <td>3.869032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035997</th>\n",
       "      <td>6035998</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.571408</td>\n",
       "      <td>1.558978</td>\n",
       "      <td>1</td>\n",
       "      <td>3.798729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035998</th>\n",
       "      <td>6035999</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.604744</td>\n",
       "      <td>1.272663</td>\n",
       "      <td>1</td>\n",
       "      <td>4.079938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035999</th>\n",
       "      <td>6036000</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.638017</td>\n",
       "      <td>1.482739</td>\n",
       "      <td>1</td>\n",
       "      <td>3.869032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6036000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  breath_id   R   C  time_step       u_in  u_out   pressure\n",
       "0              1          1  20  50   0.000000   0.083334      0   5.837492\n",
       "1              2          1  20  50   0.033652  18.383041      0   5.907794\n",
       "2              3          1  20  50   0.067514  22.509278      0   7.876254\n",
       "3              4          1  20  50   0.101542  22.808822      0  11.742872\n",
       "4              5          1  20  50   0.135756  25.355850      0  12.234987\n",
       "...          ...        ...  ..  ..        ...        ...    ...        ...\n",
       "6035995  6035996     125749  50  10   2.504603   1.489714      1   3.869032\n",
       "6035996  6035997     125749  50  10   2.537961   1.488497      1   3.869032\n",
       "6035997  6035998     125749  50  10   2.571408   1.558978      1   3.798729\n",
       "6035998  6035999     125749  50  10   2.604744   1.272663      1   4.079938\n",
       "6035999  6036000     125749  50  10   2.638017   1.482739      1   3.869032\n",
       "\n",
       "[6036000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023995</th>\n",
       "      <td>4023996</td>\n",
       "      <td>125748</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2.530117</td>\n",
       "      <td>4.971245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023996</th>\n",
       "      <td>4023997</td>\n",
       "      <td>125748</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2.563853</td>\n",
       "      <td>4.975709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023997</th>\n",
       "      <td>4023998</td>\n",
       "      <td>125748</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2.597475</td>\n",
       "      <td>4.979468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023998</th>\n",
       "      <td>4023999</td>\n",
       "      <td>125748</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2.631134</td>\n",
       "      <td>4.982648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023999</th>\n",
       "      <td>4024000</td>\n",
       "      <td>125748</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2.665301</td>\n",
       "      <td>4.985373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4024000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  breath_id   R   C  time_step       u_in  u_out\n",
       "0              1          0   5  20   0.000000   0.000000      0\n",
       "1              2          0   5  20   0.031904   7.515046      0\n",
       "2              3          0   5  20   0.063827  14.651675      0\n",
       "3              4          0   5  20   0.095751  21.230610      0\n",
       "4              5          0   5  20   0.127644  26.320956      0\n",
       "...          ...        ...  ..  ..        ...        ...    ...\n",
       "4023995  4023996     125748  20  10   2.530117   4.971245      1\n",
       "4023996  4023997     125748  20  10   2.563853   4.975709      1\n",
       "4023997  4023998     125748  20  10   2.597475   4.979468      1\n",
       "4023998  4023999     125748  20  10   2.631134   4.982648      1\n",
       "4023999  4024000     125748  20  10   2.665301   4.985373      1\n",
       "\n",
       "[4024000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train), display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f1a5892bec4eadbf3068ef100529ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_raw_features  0.023[s]\n",
      "get_simple_calc_features  12.133[s]\n",
      "get_diff_shift_features  2.150[s]\n",
      "get_agg_features  1.039[s]\n",
      "get_category_features  2.391[s]\n",
      "get_filter_features  41.357[s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef15bc5d7e74e92b1d90370435fe5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_raw_features  0.013[s]\n",
      "get_simple_calc_features  7.864[s]\n",
      "get_diff_shift_features  1.234[s]\n",
      "get_agg_features  0.615[s]\n",
      "get_category_features  1.503[s]\n",
      "get_filter_features  27.127[s]\n"
     ]
    }
   ],
   "source": [
    "train_df = to_feature(train, dataType = 'train')\n",
    "test_df = to_feature(test, dataType = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_category_col = ['R_C']\n",
    "train_value_col = [i for i in train_df.columns.to_list() if i not in train_category_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_features = train_value_col\n",
    "norm_features = sorted(list(set(train_value_col) - set(['u_out'])), key=norm_features.index)\n",
    "def norm_scale(train_df, test_df):\n",
    "    scaler = RobustScaler()\n",
    "    all_u_in = np.vstack([train_df[norm_features].values, test_df[norm_features].values])\n",
    "    scaler.fit(all_u_in)\n",
    "    train_df[norm_features] = scaler.transform(train_df[norm_features].values)\n",
    "    test_df[norm_features] = scaler.transform(test_df[norm_features].values)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = norm_scale(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = utils.reduce_mem_usage(train_df)\n",
    "test_df = utils.reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train[['id', 'breath_id', 'pressure']]], axis=1)\n",
    "test_df = pd.concat([test_df, test[['id', 'breath_id']]], axis=1)\n",
    "test_df['pressure'] = train_df['pressure'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_targets = sorted(train_df['pressure'].unique().tolist())\n",
    "target_dic = {v:i for i, v in enumerate(sorted(train_df['pressure'].unique().tolist()))}\n",
    "target_dic_inv = {v: k for k, v in target_dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df), display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = np.zeros(len(train_df))\n",
    "test_preds_lst = []\n",
    "input_dim = len(train_value_col)\n",
    "train_df['pred'] = 0\n",
    "\n",
    "gkf = GroupKFold(n_splits=CFG.n_folds).split(train_df, train_df.pressure, groups=train_df.breath_id)\n",
    "for fold, (_, valid_idx) in enumerate(gkf):\n",
    "    train_df.loc[valid_idx, 'fold'] = fold\n",
    "    \n",
    "for i, fold in enumerate(range(CFG.n_folds)):\n",
    "    if i not in CFG.folds:\n",
    "        continue\n",
    "    print(f'Fold-{fold}')\n",
    "    \n",
    "    trn_df = train_df.query(f\"fold!={fold}\").reset_index(drop=True)\n",
    "    val_df = train_df.query(f\"fold=={fold}\").reset_index(drop=True)\n",
    "    \n",
    "    loaders = {\n",
    "        phase: DataLoader(\n",
    "            VentilatorDataset(\n",
    "                df_, train_value_col, train_category_col, target_dic\n",
    "            ),\n",
    "            **CFG.loader_params[phase])  # type: ignore\n",
    "        for phase, df_ in zip([\"train\", \"valid\", \"test\"], [trn_df, val_df, test_df])\n",
    "    }\n",
    "    \n",
    "\n",
    "    model = VentilatorModel(input_dim)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    num_train_steps = int(len(loaders['train']) * CFG.epochs)\n",
    "    num_warmup_steps = int(num_train_steps / 10)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n",
    "\n",
    "    model_path = OUTPUT_DIR / f\"ventilator_f{fold}_best_model.bin\"\n",
    "\n",
    "    valid_best_score = float('inf')\n",
    "    valid_best_score_mask = float('inf')\n",
    "    for epoch in tqdm(range(CFG.epochs)):\n",
    "        train_loss, lrs = train_loop(model, optimizer, scheduler, loaders['train'])\n",
    "        valid_loss, valid_predict = valid_loop(model, loaders['valid'], target_dic_inv)\n",
    "       \n",
    "        valid_score_mask = compute_metric(valid_predict, val_df['pressure'].values, val_df['u_out'].values)\n",
    "\n",
    "        print(f\"epoch = {epoch}, valid mask score = {valid_score_mask}:\")\n",
    "\n",
    "        if valid_score_mask < valid_best_score_mask:\n",
    "            valid_best_score_mask = valid_score_mask\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            oof[train_df.query(f\"fold=={fold}\").index.values] = valid_predict\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    test_preds = test_loop(model, loaders['test'], target_dic_inv)\n",
    "    test_preds_lst.append(test_preds)\n",
    "    \n",
    "    sub_df['pressure'] = test_preds\n",
    "    sub_df.to_csv(OUTPUT_DIR / f\"sub_f{fold}.csv\", index=None)\n",
    "    \n",
    "    valid_loss, valid_predict = valid_loop(model, loaders['valid'], target_dic_inv)\n",
    "    valid_score_mask = compute_metric(valid_predict, val_df['pressure'].values, val_df['u_out'].values)\n",
    "    print(f\"fold = {epoch}, valid mask score = {valid_score_mask}:\")\n",
    "    train_df.loc[train_df['fold'] == fold, 'pred'] = valid_predict\n",
    "    train_df.loc[train_df['fold'] == fold, ['id', 'pred']].to_csv(OUTPUT_DIR / f\"oof_{fold}.csv\", index=None)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: 0.1640938902946353\n"
     ]
    }
   ],
   "source": [
    "valid_score_mask = compute_metric(train_df['pred'].values, train_df['pressure'].values, train_df['u_out'].values)\n",
    "print(\"CV:\", valid_score_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df = train_df.loc[:, ['id', 'pred']]\n",
    "oof_df.to_csv(OUTPUT_DIR / \"oof_total.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df['pressure'] = np.mean(np.stack(test_preds_lst), axis=0)\n",
    "sub_df.to_csv(OUTPUT_DIR / \"submission_mean.csv\", index=None)\n",
    "\n",
    "sub_df['pressure'] = np.median(np.stack(test_preds_lst), axis=0)\n",
    "sub_df.to_csv(OUTPUT_DIR / \"submission_median.csv\", index=None)\n",
    "\n",
    "# Post Processing: https://www.kaggle.com/snnclsr/a-dummy-approach-to-improve-your-score-postprocess\n",
    "unique_pressures = train_df[\"pressure\"].unique()\n",
    "sorted_pressures = np.sort(unique_pressures)\n",
    "total_pressures_len = len(sorted_pressures)\n",
    "\n",
    "def find_nearest(prediction):\n",
    "    insert_idx = np.searchsorted(sorted_pressures, prediction)\n",
    "    if insert_idx == total_pressures_len:\n",
    "        # If the predicted value is bigger than the highest pressure in the train dataset,\n",
    "        # return the max value.\n",
    "        return sorted_pressures[-1]\n",
    "    elif insert_idx == 0:\n",
    "        # Same control but for the lower bound.\n",
    "        return sorted_pressures[0]\n",
    "    lower_val = sorted_pressures[insert_idx - 1]\n",
    "    upper_val = sorted_pressures[insert_idx]\n",
    "    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val\n",
    "\n",
    "sub_df = pd.read_csv(OUTPUT_DIR / \"submission_mean.csv\")\n",
    "sub_df[\"pressure\"] = sub_df[\"pressure\"].apply(find_nearest)\n",
    "sub_df.to_csv(OUTPUT_DIR / \"submission_mean_pp.csv\", index=None)\n",
    "\n",
    "sub_df = pd.read_csv(OUTPUT_DIR / \"submission_median.csv\")\n",
    "sub_df[\"pressure\"] = sub_df[\"pressure\"].apply(find_nearest)\n",
    "sub_df.to_csv(OUTPUT_DIR / \"submission_median_pp.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
