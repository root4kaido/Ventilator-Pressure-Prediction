{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    exp_num = 1\n",
    "    n_folds = 10\n",
    "    folds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    seed = 777\n",
    "    local = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/ventilator-pressure-prediction\")\n",
    "OUTPUT_DIR = Path('./output/')\n",
    "OOF_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_oofs_stacking2\")\n",
    "SUB_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_subs_stacking2\")\n",
    "PICKLE_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_stacking_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../src/')\n",
    "import utils as utils\n",
    "from utils import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_paths = sorted(list(OOF_DIR.rglob('*.npy'))+list(OOF_DIR.rglob('*.csv')))\n",
    "sub_paths = sorted(list(SUB_DIR.rglob('*.npy'))+list(SUB_DIR.rglob('*.csv')))\n",
    "oof_paths = oof_paths[2:-1]\n",
    "sub_paths = sub_paths[2:-1]\n",
    "\n",
    "len(oof_paths), len(sub_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_team_preds(paths):\n",
    "    oofs = []\n",
    "    for path in paths:\n",
    "        path = str(path)\n",
    "        if '.csv' in path:\n",
    "            try:\n",
    "                oof_ = pd.read_csv(path, usecols=['pressure']).values.reshape(-1)\n",
    "\n",
    "            except:\n",
    "                oof_ = pd.read_csv(path, usecols=['pred']).values.reshape(-1)\n",
    "                print(type(oof_))\n",
    "        else:\n",
    "            try:\n",
    "                oof_ = np.load(path)\n",
    "            except:\n",
    "                oof_ = np.load(path).reshape(-1)\n",
    "#         print(f'loaded {path}')\n",
    "\n",
    "        oofs.append(oof_)\n",
    "    print('preparation done!')\n",
    "    oofs = np.array(oofs)\n",
    "    return oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparation done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.758537</td>\n",
       "      <td>5.854986</td>\n",
       "      <td>5.856609</td>\n",
       "      <td>5.826442</td>\n",
       "      <td>5.943061</td>\n",
       "      <td>5.881441</td>\n",
       "      <td>5.824871</td>\n",
       "      <td>5.845200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.867762</td>\n",
       "      <td>5.892190</td>\n",
       "      <td>5.874876</td>\n",
       "      <td>5.880338</td>\n",
       "      <td>5.897416</td>\n",
       "      <td>5.886806</td>\n",
       "      <td>5.876463</td>\n",
       "      <td>5.874144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.108805</td>\n",
       "      <td>8.105467</td>\n",
       "      <td>8.076283</td>\n",
       "      <td>8.064300</td>\n",
       "      <td>8.365878</td>\n",
       "      <td>8.031968</td>\n",
       "      <td>8.080507</td>\n",
       "      <td>8.083008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.083139</td>\n",
       "      <td>12.041125</td>\n",
       "      <td>12.103209</td>\n",
       "      <td>12.104465</td>\n",
       "      <td>11.933189</td>\n",
       "      <td>11.987523</td>\n",
       "      <td>12.094296</td>\n",
       "      <td>12.080077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.538487</td>\n",
       "      <td>12.465114</td>\n",
       "      <td>12.541359</td>\n",
       "      <td>12.562005</td>\n",
       "      <td>12.564201</td>\n",
       "      <td>12.490109</td>\n",
       "      <td>12.564713</td>\n",
       "      <td>12.544497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290963</th>\n",
       "      <td>29.461864</td>\n",
       "      <td>29.486289</td>\n",
       "      <td>29.467976</td>\n",
       "      <td>29.465347</td>\n",
       "      <td>29.469614</td>\n",
       "      <td>29.478833</td>\n",
       "      <td>29.466465</td>\n",
       "      <td>29.468664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290964</th>\n",
       "      <td>29.111432</td>\n",
       "      <td>29.130841</td>\n",
       "      <td>29.119736</td>\n",
       "      <td>29.117697</td>\n",
       "      <td>29.120155</td>\n",
       "      <td>29.113462</td>\n",
       "      <td>29.118502</td>\n",
       "      <td>29.116732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290965</th>\n",
       "      <td>29.877898</td>\n",
       "      <td>29.902215</td>\n",
       "      <td>29.879477</td>\n",
       "      <td>29.877914</td>\n",
       "      <td>29.882709</td>\n",
       "      <td>29.879132</td>\n",
       "      <td>29.880800</td>\n",
       "      <td>29.881449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290966</th>\n",
       "      <td>29.376818</td>\n",
       "      <td>29.390198</td>\n",
       "      <td>29.392828</td>\n",
       "      <td>29.391165</td>\n",
       "      <td>29.395009</td>\n",
       "      <td>29.390338</td>\n",
       "      <td>29.392717</td>\n",
       "      <td>29.388803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290967</th>\n",
       "      <td>30.048231</td>\n",
       "      <td>30.036477</td>\n",
       "      <td>30.077049</td>\n",
       "      <td>30.071825</td>\n",
       "      <td>30.079829</td>\n",
       "      <td>30.076969</td>\n",
       "      <td>30.076103</td>\n",
       "      <td>30.076145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2290968 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred_0     pred_1     pred_2     pred_3     pred_4     pred_5  \\\n",
       "0         5.758537   5.854986   5.856609   5.826442   5.943061   5.881441   \n",
       "1         5.867762   5.892190   5.874876   5.880338   5.897416   5.886806   \n",
       "2         8.108805   8.105467   8.076283   8.064300   8.365878   8.031968   \n",
       "3        12.083139  12.041125  12.103209  12.104465  11.933189  11.987523   \n",
       "4        12.538487  12.465114  12.541359  12.562005  12.564201  12.490109   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "2290963  29.461864  29.486289  29.467976  29.465347  29.469614  29.478833   \n",
       "2290964  29.111432  29.130841  29.119736  29.117697  29.120155  29.113462   \n",
       "2290965  29.877898  29.902215  29.879477  29.877914  29.882709  29.879132   \n",
       "2290966  29.376818  29.390198  29.392828  29.391165  29.395009  29.390338   \n",
       "2290967  30.048231  30.036477  30.077049  30.071825  30.079829  30.076969   \n",
       "\n",
       "            pred_6     pred_7  \n",
       "0         5.824871   5.845200  \n",
       "1         5.876463   5.874144  \n",
       "2         8.080507   8.083008  \n",
       "3        12.094296  12.080077  \n",
       "4        12.564713  12.544497  \n",
       "...            ...        ...  \n",
       "2290963  29.466465  29.468664  \n",
       "2290964  29.118502  29.116732  \n",
       "2290965  29.880800  29.881449  \n",
       "2290966  29.392717  29.388803  \n",
       "2290967  30.076103  30.076145  \n",
       "\n",
       "[2290968 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oofs = read_team_preds(oof_paths)\n",
    "oofs = pd.DataFrame(oofs.T, columns=[f'pred_{str(i)}' for i in range(oofs.shape[0])])\n",
    "oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparation done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.248648</td>\n",
       "      <td>6.254544</td>\n",
       "      <td>6.245866</td>\n",
       "      <td>6.244731</td>\n",
       "      <td>6.246731</td>\n",
       "      <td>6.256721</td>\n",
       "      <td>6.242466</td>\n",
       "      <td>6.243778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.974712</td>\n",
       "      <td>5.977849</td>\n",
       "      <td>5.974751</td>\n",
       "      <td>5.974328</td>\n",
       "      <td>5.977858</td>\n",
       "      <td>5.980080</td>\n",
       "      <td>5.974653</td>\n",
       "      <td>5.974627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.131713</td>\n",
       "      <td>7.148278</td>\n",
       "      <td>7.151010</td>\n",
       "      <td>7.144810</td>\n",
       "      <td>7.161030</td>\n",
       "      <td>7.163383</td>\n",
       "      <td>7.144706</td>\n",
       "      <td>7.144170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.705030</td>\n",
       "      <td>7.737832</td>\n",
       "      <td>7.742320</td>\n",
       "      <td>7.738994</td>\n",
       "      <td>7.749309</td>\n",
       "      <td>7.751696</td>\n",
       "      <td>7.738368</td>\n",
       "      <td>7.741155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.208021</td>\n",
       "      <td>9.217887</td>\n",
       "      <td>9.226716</td>\n",
       "      <td>9.225796</td>\n",
       "      <td>9.227802</td>\n",
       "      <td>9.239198</td>\n",
       "      <td>9.221495</td>\n",
       "      <td>9.222582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.743916</td>\n",
       "      <td>11.336866</td>\n",
       "      <td>16.854198</td>\n",
       "      <td>16.437588</td>\n",
       "      <td>11.403436</td>\n",
       "      <td>12.127083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000211</td>\n",
       "      <td>12.349588</td>\n",
       "      <td>16.840629</td>\n",
       "      <td>16.595287</td>\n",
       "      <td>12.660023</td>\n",
       "      <td>13.018024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.225691</td>\n",
       "      <td>12.570841</td>\n",
       "      <td>16.950960</td>\n",
       "      <td>16.841328</td>\n",
       "      <td>12.903463</td>\n",
       "      <td>13.207505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.856085</td>\n",
       "      <td>12.321102</td>\n",
       "      <td>16.888656</td>\n",
       "      <td>16.189855</td>\n",
       "      <td>12.654148</td>\n",
       "      <td>13.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.825203</td>\n",
       "      <td>8.373598</td>\n",
       "      <td>13.162028</td>\n",
       "      <td>13.018593</td>\n",
       "      <td>9.814577</td>\n",
       "      <td>11.360532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4024000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred_0    pred_1     pred_2     pred_3     pred_4     pred_5  \\\n",
       "0        6.248648  6.254544   6.245866   6.244731   6.246731   6.256721   \n",
       "1        5.974712  5.977849   5.974751   5.974328   5.977858   5.980080   \n",
       "2        7.131713  7.148278   7.151010   7.144810   7.161030   7.163383   \n",
       "3        7.705030  7.737832   7.742320   7.738994   7.749309   7.751696   \n",
       "4        9.208021  9.217887   9.226716   9.225796   9.227802   9.239198   \n",
       "...           ...       ...        ...        ...        ...        ...   \n",
       "4023995  0.000000  0.000000  12.743916  11.336866  16.854198  16.437588   \n",
       "4023996  0.000000  0.000000  14.000211  12.349588  16.840629  16.595287   \n",
       "4023997  0.000000  0.000000  14.225691  12.570841  16.950960  16.841328   \n",
       "4023998  0.000000  0.000000  13.856085  12.321102  16.888656  16.189855   \n",
       "4023999  0.000000  0.000000  16.825203   8.373598  13.162028  13.018593   \n",
       "\n",
       "            pred_6     pred_7  \n",
       "0         6.242466   6.243778  \n",
       "1         5.974653   5.974627  \n",
       "2         7.144706   7.144170  \n",
       "3         7.738368   7.741155  \n",
       "4         9.221495   9.222582  \n",
       "...            ...        ...  \n",
       "4023995  11.403436  12.127083  \n",
       "4023996  12.660023  13.018024  \n",
       "4023997  12.903463  13.207505  \n",
       "4023998  12.654148  13.001330  \n",
       "4023999   9.814577  11.360532  \n",
       "\n",
       "[4024000 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = read_team_preds(sub_paths)\n",
    "subs = pd.DataFrame(subs.T, columns=[f'pred_{str(i)}' for i in range(subs.shape[0])])\n",
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_features(input_df, dataType = 'train'):\n",
    "    colum = ['time_step', 'u_in', 'R', 'C']\n",
    "\n",
    "    return input_df[colum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_features(input_df, dataType = 'train'):\n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    colum = ['R_C']\n",
    "    rc_map = {'5_10': 0, '5_20': 1, '5_50': 2, '20_10': 3, '20_20': 4, '20_50': 5, '50_10': 6, '50_20': 7, '50_50': 8}\n",
    "    \n",
    "    output_df['R_C'] = [f'{r}_{c}' for r, c in zip(output_df['R'], output_df['C'])]\n",
    "    output_df['R_C'] = output_df['R_C'].map(rc_map)\n",
    "\n",
    "    return output_df[colum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_calc_features(input_df, dataType = 'train'):\n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    output_df['time_delta'] = output_df.groupby('breath_id')['time_step'].diff().fillna(0)\n",
    "    output_df['delta'] = output_df['time_delta'] * output_df['u_in']\n",
    "    output_df['area'] = output_df.groupby('breath_id')['delta'].cumsum()\n",
    "\n",
    "    output_df['cross']= output_df['u_in']*output_df['u_out']\n",
    "    output_df['cross2']= output_df['time_step']*output_df['u_out']\n",
    "    \n",
    "    output_df['u_in_cumsum'] = (output_df['u_in']).groupby(output_df['breath_id']).cumsum()\n",
    "    output_df['one'] = 1\n",
    "    output_df['count'] = (output_df['one']).groupby(output_df['breath_id']).cumsum()\n",
    "    output_df['u_in_cummean'] =output_df['u_in_cumsum'] / output_df['count']\n",
    "    \n",
    "    output_df['u_in_sqrt'] = output_df['u_in'].apply(lambda x: np.sqrt(x))\n",
    "    output_df['u_in_sqrt_cumsum'] = output_df.groupby('breath_id')['u_in_sqrt'].cumsum()\n",
    "    \n",
    "    output_df = output_df.drop(['count','one'], axis=1)\n",
    "    \n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'u_in': [np.max, np.mean],\n",
    "    }\n",
    "    \n",
    "    def get_agg_window(start_time=0, end_time=3.0, add_suffix = False):\n",
    "        \n",
    "        df_tgt = output_df[(output_df['time_step'] >= start_time) & (output_df['time_step'] <= end_time)]\n",
    "        df_feature = df_tgt.groupby(['breath_id']).agg(create_feature_dict)\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        \n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(start_time) + '_' + str(end_time))\n",
    "            \n",
    "        return df_feature\n",
    "    \n",
    "    df_agg_feature = get_agg_window().reset_index()\n",
    "    \n",
    "#     df_tmp = get_agg_window(start_time = 2, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(start_time = 1, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(end_time = 1, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(end_time = 2, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "\n",
    "    output_df = pd.merge(output_df, df_agg_feature, how='left', on='breath_id')\n",
    "    \n",
    "    output_df['u_in_diffmax'] = output_df['u_in_amax'] - output_df['u_in']\n",
    "    output_df['u_in_diffmean'] = output_df['u_in_mean'] - output_df['u_in']\n",
    "    \n",
    "#     output_df = output_df.drop(['u_in_amax','u_in_mean'], axis=1)\n",
    "    \n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_half_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    output_df['tmp'] = output_df['u_out']*(-1)+1 # inversion of u_out\n",
    "    output_df['u_in_half'] = output_df['tmp'] * output_df['u_in']\n",
    "    \n",
    "#     u_in_half_max_dict = train.groupby('breath_id')['u_in_half'].max().to_dict()\n",
    "#     train['u_in_half_max'] = train['breath_id'].map(u_in_half_max_dict)\n",
    "#     u_in_half_min_dict = train.groupby('breath_id')['u_in_half'].min().to_dict()\n",
    "#     train['u_in_half_min'] = train['breath_id'].map(u_in_half_min_dict)\n",
    "    u_in_half_mean_dict = output_df.groupby('breath_id')['u_in_half'].mean().to_dict()\n",
    "    output_df['u_in_half_mean'] = output_df['breath_id'].map(u_in_half_mean_dict)\n",
    "#     u_in_half_std_dict = train.groupby('breath_id')['u_in_half'].std().to_dict()\n",
    "#     train['u_in_half_std'] = train['breath_id'].map(u_in_half_std_dict)\n",
    "\n",
    "    del output_df['u_in_half'], output_df['tmp']\n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass_filter(series, b, a):\n",
    "    return signal.filtfilt(b, a, series)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    fp = 5 # 通過域端周波数[Hz]\n",
    "    fs = 10 # 阻止域端周波数[Hz]\n",
    "    gpass = 3 # 通過域端最大損失[dB]\n",
    "    gstop = 40 # 阻止域端最小損失[dB]\n",
    "    samplerate = 100\n",
    "\n",
    "    fn = samplerate / 2   #ナイキスト周波数\n",
    "    wp = fp / fn  #ナイキスト周波数で通過域端周波数を正規化\n",
    "    ws = fs / fn  #ナイキスト周波数で阻止域端周波数を正規化\n",
    "    N, Wn = signal.buttord(wp, ws, gpass, gstop)  #オーダーとバターワースの正規化周波数を計算\n",
    "    b, a = signal.butter(N, Wn, \"low\")            #フィルタ伝達関数の分子と分母を計算\n",
    "    \n",
    "    def get_agg_window(start_time=0, end_time=3.0, add_suffix = False):\n",
    "        \n",
    "        df_tgt = output_df[(output_df['time_step'] >= start_time) & (output_df['time_step'] <= end_time)]\n",
    "        df_feature = df_tgt.groupby(['breath_id'])['u_in'].apply(lowpass_filter, b=b, a=a)\n",
    "        df_feature.name = 'u_in_filter'\n",
    "                    \n",
    "        return df_feature\n",
    "    \n",
    "    df_agg_feature = get_agg_window().reset_index()\n",
    "    df_agg_feature = df_agg_feature.explode(\"u_in_filter\").reset_index(drop=True)\n",
    "    df_agg_feature['u_in_filter'] = df_agg_feature['u_in_filter'].astype(float)\n",
    "        \n",
    "    df_agg_feature['u_in_filter_cumsum'] = df_agg_feature.groupby('breath_id')['u_in_filter'].cumsum()\n",
    "\n",
    "    return df_agg_feature.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vib_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    output_df['u_out_diff'] = output_df['u_out'].diff()\n",
    "    output_df['u_out_diff'].fillna(0, inplace=True)\n",
    "    output_df['u_out_diff'].replace(-1, 0, inplace=True)\n",
    "    uout1_df = output_df[output_df['u_out_diff']==1]\n",
    "    \n",
    "    first_df = output_df.loc[0::80,:]\n",
    "    first_0_dict = dict(zip(first_df['id'], [0]*len(uout1_df)))\n",
    "\n",
    "    output_df['u_in_diff'] = output_df['u_in'].diff()\n",
    "    output_df['diff_sign'] = np.sign(output_df['u_in_diff'])\n",
    "    output_df['sign_diff'] = output_df['diff_sign'].diff()\n",
    "    output_df['tmp'] = output_df['id'].map(first_0_dict) # put 0, the 80row cycle\n",
    "    output_df.iloc[0::80, output_df.columns.get_loc('sign_diff')] = output_df.iloc[0::80, output_df.columns.get_loc('tmp')]\n",
    "\n",
    "    # Count the number of inversions, so take the absolute value and sum\n",
    "    output_df['sign_diff'] = abs(output_df['sign_diff']) \n",
    "    sign_diff_dict = output_df.groupby('breath_id')['sign_diff'].sum().to_dict()\n",
    "    output_df['diff_vib'] = output_df['breath_id'].map(sign_diff_dict)\n",
    "    \n",
    "    return output_df['sign_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(out_df, input_df, dataType = 'train'):\n",
    "\n",
    "    USE_LAG = [-2, -1, 1, 2, 3, 4]\n",
    "    lag_map = {-2: 1, -1: 2, 1: 3, 2: 4, 3: 5, 4: 6}\n",
    "\n",
    "    out_df['breath_id'] = input_df['breath_id']\n",
    "    \n",
    "    for lag in USE_LAG:\n",
    "        out_df[f'breath_id_lag{lag_map[lag]}']=out_df['breath_id'].shift(lag).fillna(0)\n",
    "        out_df[f'breath_id_lag{lag_map[lag]}same']=np.select([out_df[f'breath_id_lag{lag_map[lag]}']==out_df['breath_id']], [1], 0)\n",
    "\n",
    "        # u_in_filter\n",
    "        out_df[f'u_in_filter_lag_{lag_map[lag]}'] = out_df['u_in_filter'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "        out_df[f'u_in_filter_diff_{lag_map[lag]}'] = out_df['u_in_filter'] - out_df[f'u_in_filter_lag_{lag_map[lag]}']\n",
    "        # u_in_sqrt\n",
    "        out_df[f'u_in_sqrt_lag_{lag_map[lag]}'] = out_df['u_in_sqrt'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "        out_df[f'u_in_sqrt_diff_{lag_map[lag]}'] = out_df['u_in_sqrt'] - out_df[f'u_in_sqrt_lag_{lag_map[lag]}']\n",
    "\n",
    "        # u_in \n",
    "        out_df[f'u_in_lag_{lag_map[lag]}'] = out_df['u_in'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "        out_df[f'u_in_diff_{lag_map[lag]}'] = out_df['u_in'] - out_df[f'u_in_lag_{lag_map[lag]}']\n",
    "        # u_out\n",
    "        out_df[f'u_out_lag_{lag_map[lag]}'] = out_df['u_out'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "\n",
    "        # breath_time\n",
    "    out_df[f'time_step_lag_{1}'] = out_df['time_step'].shift(1).fillna(0) * out_df[f'breath_id_lag{1}same']\n",
    "    out_df[f'time_step_diff_{1}'] = out_df['time_step'] - out_df[f'time_step_lag_{1}']\n",
    "        \n",
    "    drop_columns = ['breath_id', 'time_step_lag_1']\n",
    "    drop_columns += [f'breath_id_lag{lag_map[i]}' for i in USE_LAG]\n",
    "    drop_columns += [f'breath_id_lag{lag_map[i]}same' for i in USE_LAG]\n",
    "    out_df = out_df.drop(drop_columns, axis=1)\n",
    "    out_df = out_df.fillna(0)\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    for i in range(len(pred_cols)):\n",
    "        output_df[f\"pred_{i}\"] = 0.\n",
    "        output_df.loc[oof[\"u_out\"] == 0, f\"pred_{i}\"] = _oof[f\"oof{i}\"].values\n",
    "    \n",
    "\n",
    "    \n",
    "    return output_df['sign_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_feature(input_df, dataType = 'train'):\n",
    "    \"\"\"input_df を特徴量行列に変換した新しいデータフレームを返す.\n",
    "    \"\"\"\n",
    "\n",
    "    processors = [\n",
    "        get_raw_features,\n",
    "#         get_simple_calc_features,\n",
    "#         get_agg_features,\n",
    "#         get_vib_features,\n",
    "#         get_half_features,\n",
    "        get_category_features,\n",
    "#         get_filter_features,\n",
    "    ]\n",
    "\n",
    "    out_df = pd.DataFrame()\n",
    "\n",
    "    for func in tqdm(processors, total=len(processors)):\n",
    "        with Timer(prefix='' + func.__name__ + ' '):\n",
    "            _df = func(input_df, dataType)\n",
    "\n",
    "        # 長さが等しいことをチェック (ずれている場合, func の実装がおかしい)\n",
    "        assert len(_df) == len(input_df), func.__name__\n",
    "        out_df = pd.concat([out_df, _df], axis=1)\n",
    "#     out_df = utils.reduce_mem_usage(out_df)\n",
    "#     out_df = add_time_features(out_df, input_df)\n",
    "    out_df_cols = sorted(list(out_df))\n",
    "    out_df = out_df[out_df_cols]\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_raw_features  0.024[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.23s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_category_features  2.374[s]\n",
      "get_raw_features  0.016[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_category_features  1.566[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = to_feature(train, dataType = 'train')\n",
    "test_df = to_feature(test, dataType = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = [f\"pred_{i}\" for i in range(len(oofs.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_oof_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    if dataType == 'train':\n",
    "        for i in range(len(pred_cols)):\n",
    "            input_df[f\"pred_{i}\"] = 0.\n",
    "            input_df.loc[train[\"u_out\"] == 0, f\"pred_{i}\"] = oofs[f\"pred_{i}\"].values\n",
    "        input_df['breath_id'] = train['breath_id']\n",
    "        input_df = train_df.loc[train[\"u_out\"] == 0].reset_index(drop=True)\n",
    "    else:\n",
    "        for i in range(len(pred_cols)):\n",
    "            input_df[f\"pred_{i}\"] = 0.\n",
    "            input_df.loc[:, f\"pred_{i}\"] = subs[f\"pred_{i}\"].values\n",
    "        input_df['breath_id'] = test['breath_id']\n",
    "        input_df = input_df.loc[test[\"u_out\"] == 0].reset_index(drop=True)\n",
    "      \n",
    "    # v2\n",
    "    input_df[\"pred_mean\"] = np.mean(input_df[pred_cols].values, axis=1)\n",
    "    input_df[\"pred_median\"] = np.median(input_df[pred_cols].values, axis=1)\n",
    "\n",
    "    input_df[\"pred_std\"] = input_df[pred_cols].std(axis=1)\n",
    "    input_df[\"pred_max\"] = input_df[pred_cols].values.max(axis=1)\n",
    "    input_df[\"pred_min\"] = input_df[pred_cols].values.min(axis=1)\n",
    "    input_df[\"pred_max-min\"] = input_df[\"pred_max\"] - input_df[\"pred_min\"]\n",
    "    input_df[\"pred_max-median\"] = input_df[\"pred_max\"] - input_df[\"pred_median\"]\n",
    "    input_df[\"pred_max-mean\"] = input_df[\"pred_max\"] - input_df[\"pred_mean\"]\n",
    "    input_df[\"pred_median-min\"] = input_df[\"pred_median\"] - input_df[\"pred_min\"]\n",
    "    input_df[\"pred_mean-min\"] = input_df[\"pred_mean\"] - input_df[\"pred_min\"]\n",
    "    input_df[\"pred_mean-median\"] = input_df[\"pred_mean\"] - input_df[\"pred_median\"]\n",
    "    input_df[\"pred_kurt\"] = input_df[pred_cols].kurt(axis=1)\n",
    "    for col_ in pred_cols:\n",
    "        input_df[f\"{col_}_past_1\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(1)\n",
    "        input_df[f\"{col_}_past_2\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(2)\n",
    "        input_df[f\"{col_}_past_3\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(3)\n",
    "        input_df[f\"{col_}_past_4\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(4)\n",
    "\n",
    "        input_df[f\"{col_}_diff_1\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_1\"]\n",
    "        input_df[f\"{col_}_diff_2\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_2\"]\n",
    "        input_df[f\"{col_}_diff_3\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_3\"]\n",
    "        input_df[f\"{col_}_diff_4\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_4\"]\n",
    "\n",
    "    input_df[\"u_in_past_1\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(1)\n",
    "    input_df[\"u_in_past_2\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(2)\n",
    "    input_df[\"u_in_past_3\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(3)\n",
    "    input_df[\"u_in_past_4\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(4)\n",
    "\n",
    "    input_df[\"u_in_diff_1\"] = input_df[\"u_in\"] - input_df[\"u_in_past_1\"]\n",
    "    input_df[\"u_in_diff_2\"] = input_df[\"u_in\"] - input_df[\"u_in_past_2\"]\n",
    "    input_df[\"u_in_diff_3\"] = input_df[\"u_in\"] - input_df[\"u_in_past_3\"]\n",
    "    input_df[\"u_in_diff_4\"] = input_df[\"u_in\"] - input_df[\"u_in_past_4\"]\n",
    "\n",
    "    input_df[\"u_in_cumsum\"] = input_df.groupby(\"breath_id\")[\"u_in\"].cumsum()\n",
    "\n",
    "    del input_df['breath_id']\n",
    "    \n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_oof_features(train_df, dataType = 'train')\n",
    "test_df = add_oof_features(test_df, dataType = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>R</th>\n",
       "      <th>R_C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_7_diff_4</th>\n",
       "      <th>u_in_past_1</th>\n",
       "      <th>u_in_past_2</th>\n",
       "      <th>u_in_past_3</th>\n",
       "      <th>u_in_past_4</th>\n",
       "      <th>u_in_diff_1</th>\n",
       "      <th>u_in_diff_2</th>\n",
       "      <th>u_in_diff_3</th>\n",
       "      <th>u_in_diff_4</th>\n",
       "      <th>u_in_cumsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>5.758537</td>\n",
       "      <td>5.854986</td>\n",
       "      <td>5.856609</td>\n",
       "      <td>5.826442</td>\n",
       "      <td>5.943061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>5.867762</td>\n",
       "      <td>5.892190</td>\n",
       "      <td>5.874876</td>\n",
       "      <td>5.880338</td>\n",
       "      <td>5.897416</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.299707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.466375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>8.108805</td>\n",
       "      <td>8.105467</td>\n",
       "      <td>8.076283</td>\n",
       "      <td>8.064300</td>\n",
       "      <td>8.365878</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.126236</td>\n",
       "      <td>22.425944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.975653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>12.083139</td>\n",
       "      <td>12.041125</td>\n",
       "      <td>12.103209</td>\n",
       "      <td>12.104465</td>\n",
       "      <td>11.933189</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.299544</td>\n",
       "      <td>4.425781</td>\n",
       "      <td>22.725488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.784476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>12.538487</td>\n",
       "      <td>12.465114</td>\n",
       "      <td>12.541359</td>\n",
       "      <td>12.562005</td>\n",
       "      <td>12.564201</td>\n",
       "      <td>...</td>\n",
       "      <td>6.699297</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>2.547028</td>\n",
       "      <td>2.846573</td>\n",
       "      <td>6.972809</td>\n",
       "      <td>25.272516</td>\n",
       "      <td>89.140326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290963</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.834147</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>29.461864</td>\n",
       "      <td>29.486289</td>\n",
       "      <td>29.467976</td>\n",
       "      <td>29.465347</td>\n",
       "      <td>29.469614</td>\n",
       "      <td>...</td>\n",
       "      <td>1.056164</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>2.438287</td>\n",
       "      <td>3.783043</td>\n",
       "      <td>3.209590</td>\n",
       "      <td>-0.780965</td>\n",
       "      <td>-0.568920</td>\n",
       "      <td>-1.913676</td>\n",
       "      <td>-1.340223</td>\n",
       "      <td>238.890288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290964</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.867574</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>29.111432</td>\n",
       "      <td>29.130841</td>\n",
       "      <td>29.119736</td>\n",
       "      <td>29.117697</td>\n",
       "      <td>29.120155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.339222</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>2.438287</td>\n",
       "      <td>3.783043</td>\n",
       "      <td>0.285047</td>\n",
       "      <td>-0.495918</td>\n",
       "      <td>-0.283873</td>\n",
       "      <td>-1.628629</td>\n",
       "      <td>241.044703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290965</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.900917</td>\n",
       "      <td>1.304434</td>\n",
       "      <td>29.877898</td>\n",
       "      <td>29.902215</td>\n",
       "      <td>29.879477</td>\n",
       "      <td>29.877914</td>\n",
       "      <td>29.882709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850908</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>2.438287</td>\n",
       "      <td>-0.849980</td>\n",
       "      <td>-0.564933</td>\n",
       "      <td>-1.345899</td>\n",
       "      <td>-1.133853</td>\n",
       "      <td>242.349137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290966</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.934309</td>\n",
       "      <td>1.733830</td>\n",
       "      <td>29.376818</td>\n",
       "      <td>29.390198</td>\n",
       "      <td>29.392828</td>\n",
       "      <td>29.391165</td>\n",
       "      <td>29.395009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629501</td>\n",
       "      <td>1.304434</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>0.429396</td>\n",
       "      <td>-0.420585</td>\n",
       "      <td>-0.135538</td>\n",
       "      <td>-0.916503</td>\n",
       "      <td>244.082966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290967</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.967743</td>\n",
       "      <td>0.958726</td>\n",
       "      <td>30.048231</td>\n",
       "      <td>30.036477</td>\n",
       "      <td>30.077049</td>\n",
       "      <td>30.071825</td>\n",
       "      <td>30.079829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607481</td>\n",
       "      <td>1.733830</td>\n",
       "      <td>1.304434</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>-0.775103</td>\n",
       "      <td>-0.345708</td>\n",
       "      <td>-1.195688</td>\n",
       "      <td>-0.910641</td>\n",
       "      <td>245.041693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2290968 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C   R  R_C  time_step       u_in     pred_0     pred_1     pred_2  \\\n",
       "0        50  20    5   0.000000   0.083334   5.758537   5.854986   5.856609   \n",
       "1        50  20    5   0.033652  18.383041   5.867762   5.892190   5.874876   \n",
       "2        50  20    5   0.067514  22.509278   8.108805   8.105467   8.076283   \n",
       "3        50  20    5   0.101542  22.808822  12.083139  12.041125  12.103209   \n",
       "4        50  20    5   0.135756  25.355850  12.538487  12.465114  12.541359   \n",
       "...      ..  ..  ...        ...        ...        ...        ...        ...   \n",
       "2290963  10  50    6   0.834147   1.869367  29.461864  29.486289  29.467976   \n",
       "2290964  10  50    6   0.867574   2.154414  29.111432  29.130841  29.119736   \n",
       "2290965  10  50    6   0.900917   1.304434  29.877898  29.902215  29.879477   \n",
       "2290966  10  50    6   0.934309   1.733830  29.376818  29.390198  29.392828   \n",
       "2290967  10  50    6   0.967743   0.958726  30.048231  30.036477  30.077049   \n",
       "\n",
       "            pred_3     pred_4  ...  pred_7_diff_4  u_in_past_1  u_in_past_2  \\\n",
       "0         5.826442   5.943061  ...            NaN          NaN          NaN   \n",
       "1         5.880338   5.897416  ...            NaN     0.083334          NaN   \n",
       "2         8.064300   8.365878  ...            NaN    18.383041     0.083334   \n",
       "3        12.104465  11.933189  ...            NaN    22.509278    18.383041   \n",
       "4        12.562005  12.564201  ...       6.699297    22.808822    22.509278   \n",
       "...            ...        ...  ...            ...          ...          ...   \n",
       "2290963  29.465347  29.469614  ...       1.056164     2.650333     2.438287   \n",
       "2290964  29.117697  29.120155  ...       1.339222     1.869367     2.650333   \n",
       "2290965  29.877914  29.882709  ...       0.850908     2.154414     1.869367   \n",
       "2290966  29.391165  29.395009  ...       0.629501     1.304434     2.154414   \n",
       "2290967  30.071825  30.079829  ...       0.607481     1.733830     1.304434   \n",
       "\n",
       "         u_in_past_3  u_in_past_4  u_in_diff_1  u_in_diff_2  u_in_diff_3  \\\n",
       "0                NaN          NaN          NaN          NaN          NaN   \n",
       "1                NaN          NaN    18.299707          NaN          NaN   \n",
       "2                NaN          NaN     4.126236    22.425944          NaN   \n",
       "3           0.083334          NaN     0.299544     4.425781    22.725488   \n",
       "4          18.383041     0.083334     2.547028     2.846573     6.972809   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "2290963     3.783043     3.209590    -0.780965    -0.568920    -1.913676   \n",
       "2290964     2.438287     3.783043     0.285047    -0.495918    -0.283873   \n",
       "2290965     2.650333     2.438287    -0.849980    -0.564933    -1.345899   \n",
       "2290966     1.869367     2.650333     0.429396    -0.420585    -0.135538   \n",
       "2290967     2.154414     1.869367    -0.775103    -0.345708    -1.195688   \n",
       "\n",
       "         u_in_diff_4  u_in_cumsum  \n",
       "0                NaN     0.083334  \n",
       "1                NaN    18.466375  \n",
       "2                NaN    40.975653  \n",
       "3                NaN    63.784476  \n",
       "4          25.272516    89.140326  \n",
       "...              ...          ...  \n",
       "2290963    -1.340223   238.890288  \n",
       "2290964    -1.628629   241.044703  \n",
       "2290965    -1.133853   242.349137  \n",
       "2290966    -0.916503   244.082966  \n",
       "2290967    -0.910641   245.041693  \n",
       "\n",
       "[2290968 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>R</th>\n",
       "      <th>R_C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_7_diff_4</th>\n",
       "      <th>u_in_past_1</th>\n",
       "      <th>u_in_past_2</th>\n",
       "      <th>u_in_past_3</th>\n",
       "      <th>u_in_past_4</th>\n",
       "      <th>u_in_diff_1</th>\n",
       "      <th>u_in_diff_2</th>\n",
       "      <th>u_in_diff_3</th>\n",
       "      <th>u_in_diff_4</th>\n",
       "      <th>u_in_cumsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.248648</td>\n",
       "      <td>6.254544</td>\n",
       "      <td>6.245866</td>\n",
       "      <td>6.244731</td>\n",
       "      <td>6.246731</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>5.974712</td>\n",
       "      <td>5.977849</td>\n",
       "      <td>5.974751</td>\n",
       "      <td>5.974328</td>\n",
       "      <td>5.977858</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.515046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.131713</td>\n",
       "      <td>7.148278</td>\n",
       "      <td>7.151010</td>\n",
       "      <td>7.144810</td>\n",
       "      <td>7.161030</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.136630</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.166721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>7.705030</td>\n",
       "      <td>7.737832</td>\n",
       "      <td>7.742320</td>\n",
       "      <td>7.738994</td>\n",
       "      <td>7.749309</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.578935</td>\n",
       "      <td>13.715564</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.397331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>9.208021</td>\n",
       "      <td>9.217887</td>\n",
       "      <td>9.226716</td>\n",
       "      <td>9.225796</td>\n",
       "      <td>9.227802</td>\n",
       "      <td>...</td>\n",
       "      <td>2.978804</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.090346</td>\n",
       "      <td>11.669281</td>\n",
       "      <td>18.805911</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>69.718287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527560</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.842145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.110286</td>\n",
       "      <td>10.121597</td>\n",
       "      <td>10.112878</td>\n",
       "      <td>10.112398</td>\n",
       "      <td>10.104356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.839645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527561</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.088546</td>\n",
       "      <td>10.088032</td>\n",
       "      <td>10.072209</td>\n",
       "      <td>10.070274</td>\n",
       "      <td>10.067932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.839645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527562</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.909185</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>9.987632</td>\n",
       "      <td>9.985331</td>\n",
       "      <td>9.983278</td>\n",
       "      <td>9.982208</td>\n",
       "      <td>9.984392</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>68.961019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527563</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.943148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.058333</td>\n",
       "      <td>10.056895</td>\n",
       "      <td>10.056179</td>\n",
       "      <td>10.055809</td>\n",
       "      <td>10.062260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063477</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.961019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527564</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.976815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.060080</td>\n",
       "      <td>10.056259</td>\n",
       "      <td>10.057204</td>\n",
       "      <td>10.057153</td>\n",
       "      <td>10.062133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.961019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527565 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C   R  R_C  time_step       u_in     pred_0     pred_1     pred_2  \\\n",
       "0        20   5    1   0.000000   0.000000   6.248648   6.254544   6.245866   \n",
       "1        20   5    1   0.031904   7.515046   5.974712   5.977849   5.974751   \n",
       "2        20   5    1   0.063827  14.651675   7.131713   7.148278   7.151010   \n",
       "3        20   5    1   0.095751  21.230610   7.705030   7.737832   7.742320   \n",
       "4        20   5    1   0.127644  26.320956   9.208021   9.217887   9.226716   \n",
       "...      ..  ..  ...        ...        ...        ...        ...        ...   \n",
       "1527560  10  20    3   0.842145   0.000000  10.110286  10.121597  10.112878   \n",
       "1527561  10  20    3   0.875648   0.000000  10.088546  10.088032  10.072209   \n",
       "1527562  10  20    3   0.909185   0.121375   9.987632   9.985331   9.983278   \n",
       "1527563  10  20    3   0.943148   0.000000  10.058333  10.056895  10.056179   \n",
       "1527564  10  20    3   0.976815   0.000000  10.060080  10.056259  10.057204   \n",
       "\n",
       "            pred_3     pred_4  ...  pred_7_diff_4  u_in_past_1  u_in_past_2  \\\n",
       "0         6.244731   6.246731  ...            NaN          NaN          NaN   \n",
       "1         5.974328   5.977858  ...            NaN     0.000000          NaN   \n",
       "2         7.144810   7.161030  ...            NaN     7.515046     0.000000   \n",
       "3         7.738994   7.749309  ...            NaN    14.651675     7.515046   \n",
       "4         9.225796   9.227802  ...       2.978804    21.230610    14.651675   \n",
       "...            ...        ...  ...            ...          ...          ...   \n",
       "1527560  10.112398  10.104356  ...       0.039103     0.000000     0.000000   \n",
       "1527561  10.070274  10.067932  ...      -0.056803     0.000000     0.000000   \n",
       "1527562   9.982208   9.984392  ...      -0.143902     0.000000     0.000000   \n",
       "1527563  10.055809  10.062260  ...      -0.063477     0.121375     0.000000   \n",
       "1527564  10.057153  10.062133  ...      -0.058408     0.000000     0.121375   \n",
       "\n",
       "         u_in_past_3  u_in_past_4  u_in_diff_1  u_in_diff_2  u_in_diff_3  \\\n",
       "0                NaN          NaN          NaN          NaN          NaN   \n",
       "1                NaN          NaN     7.515046          NaN          NaN   \n",
       "2                NaN          NaN     7.136630    14.651675          NaN   \n",
       "3           0.000000          NaN     6.578935    13.715564    21.230610   \n",
       "4           7.515046          0.0     5.090346    11.669281    18.805911   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "1527560     0.000000          0.0     0.000000     0.000000     0.000000   \n",
       "1527561     0.000000          0.0     0.000000     0.000000     0.000000   \n",
       "1527562     0.000000          0.0     0.121375     0.121375     0.121375   \n",
       "1527563     0.000000          0.0    -0.121375     0.000000     0.000000   \n",
       "1527564     0.000000          0.0     0.000000    -0.121375     0.000000   \n",
       "\n",
       "         u_in_diff_4  u_in_cumsum  \n",
       "0                NaN     0.000000  \n",
       "1                NaN     7.515046  \n",
       "2                NaN    22.166721  \n",
       "3                NaN    43.397331  \n",
       "4          26.320956    69.718287  \n",
       "...              ...          ...  \n",
       "1527560     0.000000    68.839645  \n",
       "1527561     0.000000    68.839645  \n",
       "1527562     0.121375    68.961019  \n",
       "1527563     0.000000    68.961019  \n",
       "1527564     0.000000    68.961019  \n",
       "\n",
       "[1527565 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train_df), display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_category_col = ['R_C']\n",
    "train_value_col = [i for i in train_df.columns.to_list() if i not in train_category_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_features = train_value_col\n",
    "# train_df = train_df.fillna(0)\n",
    "# test_df = test_df.fillna(0)\n",
    "# scaler = RobustScaler()\n",
    "# scaler.fit(train_df[norm_features])\n",
    "# train_df[norm_features] = scaler.transform(train_df[norm_features].values)\n",
    "# test_df[norm_features] = scaler.transform(test_df[norm_features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.loc[train[\"u_out\"] == 0]['pressure'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train.loc[train[\"u_out\"] == 0, ['id', 'breath_id', 'pressure']].reset_index(drop=True)], axis=1)\n",
    "test_df = pd.concat([test_df, test.loc[test[\"u_out\"] == 0,['id', 'breath_id']].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.894404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 190008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061893, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.130399\tvalid_1's l1: 0.128787\n",
      "[200]\ttraining's l1: 0.124764\tvalid_1's l1: 0.123085\n",
      "[300]\ttraining's l1: 0.12285\tvalid_1's l1: 0.121189\n",
      "[400]\ttraining's l1: 0.121592\tvalid_1's l1: 0.119997\n",
      "[500]\ttraining's l1: 0.1208\tvalid_1's l1: 0.119285\n",
      "[600]\ttraining's l1: 0.120121\tvalid_1's l1: 0.118747\n",
      "[700]\ttraining's l1: 0.119816\tvalid_1's l1: 0.118495\n",
      "[800]\ttraining's l1: 0.119553\tvalid_1's l1: 0.118316\n",
      "[900]\ttraining's l1: 0.119257\tvalid_1's l1: 0.11812\n",
      "[1000]\ttraining's l1: 0.118975\tvalid_1's l1: 0.118001\n",
      "[1100]\ttraining's l1: 0.118766\tvalid_1's l1: 0.117903\n",
      "[1200]\ttraining's l1: 0.1185\tvalid_1's l1: 0.117753\n",
      "[1300]\ttraining's l1: 0.118353\tvalid_1's l1: 0.117679\n",
      "[1400]\ttraining's l1: 0.118287\tvalid_1's l1: 0.117658\n",
      "[1500]\ttraining's l1: 0.118145\tvalid_1's l1: 0.117528\n",
      "[1600]\ttraining's l1: 0.118074\tvalid_1's l1: 0.117508\n",
      "[1700]\ttraining's l1: 0.118019\tvalid_1's l1: 0.117494\n",
      "[1800]\ttraining's l1: 0.117954\tvalid_1's l1: 0.117441\n",
      "[1900]\ttraining's l1: 0.117916\tvalid_1's l1: 0.117428\n",
      "[2000]\ttraining's l1: 0.117887\tvalid_1's l1: 0.117421\n",
      "[2100]\ttraining's l1: 0.117862\tvalid_1's l1: 0.11741\n",
      "[2200]\ttraining's l1: 0.117832\tvalid_1's l1: 0.117392\n",
      "[2300]\ttraining's l1: 0.117823\tvalid_1's l1: 0.117394\n",
      "[2400]\ttraining's l1: 0.117819\tvalid_1's l1: 0.117395\n",
      "Early stopping, best iteration is:\n",
      "[2208]\ttraining's l1: 0.11783\tvalid_1's l1: 0.117392\n",
      "fold = 0, score = 0.11739169804004689\n",
      "Fold-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.981763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 190008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061993, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.131563\tvalid_1's l1: 0.13269\n",
      "[200]\ttraining's l1: 0.124399\tvalid_1's l1: 0.125933\n",
      "[300]\ttraining's l1: 0.122104\tvalid_1's l1: 0.123778\n",
      "[400]\ttraining's l1: 0.12088\tvalid_1's l1: 0.122609\n",
      "[500]\ttraining's l1: 0.120318\tvalid_1's l1: 0.12218\n",
      "[600]\ttraining's l1: 0.119794\tvalid_1's l1: 0.121731\n",
      "[700]\ttraining's l1: 0.119304\tvalid_1's l1: 0.12133\n",
      "[800]\ttraining's l1: 0.118946\tvalid_1's l1: 0.121062\n",
      "[900]\ttraining's l1: 0.118768\tvalid_1's l1: 0.120924\n",
      "[1000]\ttraining's l1: 0.118459\tvalid_1's l1: 0.120748\n",
      "[1100]\ttraining's l1: 0.118259\tvalid_1's l1: 0.120644\n",
      "[1200]\ttraining's l1: 0.118117\tvalid_1's l1: 0.120572\n",
      "[1300]\ttraining's l1: 0.117983\tvalid_1's l1: 0.12052\n",
      "[1400]\ttraining's l1: 0.117847\tvalid_1's l1: 0.12046\n",
      "[1500]\ttraining's l1: 0.11769\tvalid_1's l1: 0.120378\n",
      "[1600]\ttraining's l1: 0.117576\tvalid_1's l1: 0.120338\n",
      "[1700]\ttraining's l1: 0.117413\tvalid_1's l1: 0.120279\n",
      "[1800]\ttraining's l1: 0.117297\tvalid_1's l1: 0.12026\n",
      "[1900]\ttraining's l1: 0.117238\tvalid_1's l1: 0.12026\n",
      "[2000]\ttraining's l1: 0.117209\tvalid_1's l1: 0.120257\n",
      "[2100]\ttraining's l1: 0.117201\tvalid_1's l1: 0.120254\n",
      "[2200]\ttraining's l1: 0.117129\tvalid_1's l1: 0.120254\n",
      "[2300]\ttraining's l1: 0.116977\tvalid_1's l1: 0.120238\n",
      "[2400]\ttraining's l1: 0.116833\tvalid_1's l1: 0.120218\n",
      "[2500]\ttraining's l1: 0.116731\tvalid_1's l1: 0.120199\n",
      "[2600]\ttraining's l1: 0.116634\tvalid_1's l1: 0.120164\n",
      "[2700]\ttraining's l1: 0.116494\tvalid_1's l1: 0.120143\n",
      "[2800]\ttraining's l1: 0.116428\tvalid_1's l1: 0.120124\n",
      "[2900]\ttraining's l1: 0.116311\tvalid_1's l1: 0.120106\n",
      "[3000]\ttraining's l1: 0.116234\tvalid_1's l1: 0.120091\n",
      "[3100]\ttraining's l1: 0.116109\tvalid_1's l1: 0.120099\n",
      "Early stopping, best iteration is:\n",
      "[2982]\ttraining's l1: 0.116241\tvalid_1's l1: 0.12009\n",
      "fold = 1, score = 0.12009001930435871\n",
      "Fold-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.915502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 190008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061937, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.131308\tvalid_1's l1: 0.128733\n",
      "[200]\ttraining's l1: 0.124787\tvalid_1's l1: 0.122592\n",
      "[300]\ttraining's l1: 0.123573\tvalid_1's l1: 0.121431\n",
      "[400]\ttraining's l1: 0.122215\tvalid_1's l1: 0.120095\n",
      "[500]\ttraining's l1: 0.12113\tvalid_1's l1: 0.119131\n",
      "[600]\ttraining's l1: 0.120444\tvalid_1's l1: 0.11856\n",
      "[700]\ttraining's l1: 0.119941\tvalid_1's l1: 0.11816\n",
      "[800]\ttraining's l1: 0.119675\tvalid_1's l1: 0.11795\n",
      "[900]\ttraining's l1: 0.119289\tvalid_1's l1: 0.117693\n",
      "[1000]\ttraining's l1: 0.119088\tvalid_1's l1: 0.117544\n",
      "[1100]\ttraining's l1: 0.118815\tvalid_1's l1: 0.117407\n",
      "[1200]\ttraining's l1: 0.118654\tvalid_1's l1: 0.11733\n",
      "[1300]\ttraining's l1: 0.118408\tvalid_1's l1: 0.117195\n",
      "[1400]\ttraining's l1: 0.11817\tvalid_1's l1: 0.117099\n",
      "[1500]\ttraining's l1: 0.118\tvalid_1's l1: 0.117056\n",
      "[1600]\ttraining's l1: 0.117807\tvalid_1's l1: 0.116972\n",
      "[1700]\ttraining's l1: 0.117633\tvalid_1's l1: 0.116936\n",
      "[1800]\ttraining's l1: 0.117509\tvalid_1's l1: 0.116897\n",
      "[1900]\ttraining's l1: 0.117456\tvalid_1's l1: 0.116874\n",
      "[2000]\ttraining's l1: 0.117412\tvalid_1's l1: 0.116856\n",
      "[2100]\ttraining's l1: 0.117388\tvalid_1's l1: 0.11685\n",
      "[2200]\ttraining's l1: 0.117366\tvalid_1's l1: 0.116842\n",
      "[2300]\ttraining's l1: 0.117336\tvalid_1's l1: 0.116822\n",
      "[2400]\ttraining's l1: 0.117319\tvalid_1's l1: 0.116814\n",
      "[2500]\ttraining's l1: 0.117302\tvalid_1's l1: 0.116806\n",
      "[2600]\ttraining's l1: 0.117285\tvalid_1's l1: 0.116798\n",
      "[2700]\ttraining's l1: 0.117272\tvalid_1's l1: 0.116796\n",
      "[2800]\ttraining's l1: 0.117243\tvalid_1's l1: 0.116805\n",
      "[2900]\ttraining's l1: 0.117123\tvalid_1's l1: 0.116801\n",
      "[3000]\ttraining's l1: 0.117029\tvalid_1's l1: 0.116758\n",
      "[3100]\ttraining's l1: 0.11691\tvalid_1's l1: 0.116744\n",
      "[3200]\ttraining's l1: 0.116802\tvalid_1's l1: 0.116711\n",
      "[3300]\ttraining's l1: 0.116675\tvalid_1's l1: 0.116692\n",
      "[3400]\ttraining's l1: 0.11651\tvalid_1's l1: 0.116678\n",
      "[3500]\ttraining's l1: 0.116433\tvalid_1's l1: 0.116677\n",
      "[3600]\ttraining's l1: 0.116376\tvalid_1's l1: 0.116666\n",
      "[3700]\ttraining's l1: 0.116312\tvalid_1's l1: 0.116648\n",
      "[3800]\ttraining's l1: 0.116217\tvalid_1's l1: 0.116618\n",
      "[3900]\ttraining's l1: 0.116145\tvalid_1's l1: 0.116619\n",
      "[4000]\ttraining's l1: 0.116107\tvalid_1's l1: 0.116604\n",
      "[4100]\ttraining's l1: 0.11602\tvalid_1's l1: 0.116598\n",
      "[4200]\ttraining's l1: 0.115996\tvalid_1's l1: 0.116595\n",
      "[4300]\ttraining's l1: 0.115963\tvalid_1's l1: 0.116583\n",
      "[4400]\ttraining's l1: 0.115912\tvalid_1's l1: 0.116568\n",
      "[4500]\ttraining's l1: 0.115857\tvalid_1's l1: 0.116565\n",
      "[4600]\ttraining's l1: 0.115789\tvalid_1's l1: 0.11656\n",
      "[4700]\ttraining's l1: 0.115712\tvalid_1's l1: 0.116552\n",
      "[4800]\ttraining's l1: 0.115629\tvalid_1's l1: 0.116548\n",
      "[4900]\ttraining's l1: 0.11555\tvalid_1's l1: 0.116522\n",
      "[5000]\ttraining's l1: 0.11552\tvalid_1's l1: 0.116514\n",
      "[5100]\ttraining's l1: 0.11545\tvalid_1's l1: 0.116501\n",
      "[5200]\ttraining's l1: 0.115335\tvalid_1's l1: 0.116498\n",
      "[5300]\ttraining's l1: 0.115214\tvalid_1's l1: 0.116502\n",
      "[5400]\ttraining's l1: 0.115107\tvalid_1's l1: 0.1165\n",
      "Early stopping, best iteration is:\n",
      "[5227]\ttraining's l1: 0.11531\tvalid_1's l1: 0.116495\n",
      "fold = 2, score = 0.11649457829791376\n",
      "Fold-3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.927566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 190008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061922, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.131176\tvalid_1's l1: 0.131603\n",
      "[200]\ttraining's l1: 0.124437\tvalid_1's l1: 0.125443\n",
      "[300]\ttraining's l1: 0.122239\tvalid_1's l1: 0.123304\n",
      "[400]\ttraining's l1: 0.121029\tvalid_1's l1: 0.122191\n",
      "[500]\ttraining's l1: 0.120307\tvalid_1's l1: 0.121586\n",
      "[600]\ttraining's l1: 0.119757\tvalid_1's l1: 0.121179\n",
      "[700]\ttraining's l1: 0.119373\tvalid_1's l1: 0.120879\n",
      "[800]\ttraining's l1: 0.119156\tvalid_1's l1: 0.120731\n",
      "[900]\ttraining's l1: 0.118854\tvalid_1's l1: 0.120512\n",
      "[1000]\ttraining's l1: 0.118658\tvalid_1's l1: 0.120378\n",
      "[1100]\ttraining's l1: 0.118423\tvalid_1's l1: 0.120293\n",
      "[1200]\ttraining's l1: 0.118271\tvalid_1's l1: 0.120233\n",
      "[1300]\ttraining's l1: 0.118103\tvalid_1's l1: 0.120145\n",
      "[1400]\ttraining's l1: 0.118003\tvalid_1's l1: 0.120083\n",
      "[1500]\ttraining's l1: 0.117935\tvalid_1's l1: 0.12004\n",
      "[1600]\ttraining's l1: 0.117791\tvalid_1's l1: 0.119996\n",
      "[1700]\ttraining's l1: 0.117714\tvalid_1's l1: 0.119936\n",
      "[1800]\ttraining's l1: 0.117656\tvalid_1's l1: 0.119916\n",
      "[1900]\ttraining's l1: 0.117548\tvalid_1's l1: 0.119893\n",
      "[2000]\ttraining's l1: 0.117461\tvalid_1's l1: 0.119862\n",
      "[2100]\ttraining's l1: 0.117432\tvalid_1's l1: 0.11985\n",
      "[2200]\ttraining's l1: 0.117364\tvalid_1's l1: 0.119846\n",
      "[2300]\ttraining's l1: 0.117233\tvalid_1's l1: 0.119805\n",
      "[2400]\ttraining's l1: 0.117129\tvalid_1's l1: 0.119796\n",
      "[2500]\ttraining's l1: 0.117027\tvalid_1's l1: 0.119759\n",
      "[2600]\ttraining's l1: 0.116918\tvalid_1's l1: 0.119727\n",
      "[2700]\ttraining's l1: 0.116803\tvalid_1's l1: 0.119697\n",
      "[2800]\ttraining's l1: 0.116743\tvalid_1's l1: 0.119686\n",
      "[2900]\ttraining's l1: 0.116648\tvalid_1's l1: 0.119661\n",
      "[3000]\ttraining's l1: 0.116552\tvalid_1's l1: 0.11964\n",
      "[3100]\ttraining's l1: 0.116505\tvalid_1's l1: 0.119626\n",
      "[3200]\ttraining's l1: 0.116438\tvalid_1's l1: 0.119611\n",
      "[3300]\ttraining's l1: 0.116389\tvalid_1's l1: 0.119601\n",
      "[3400]\ttraining's l1: 0.116341\tvalid_1's l1: 0.119587\n",
      "[3500]\ttraining's l1: 0.116294\tvalid_1's l1: 0.119577\n",
      "[3600]\ttraining's l1: 0.116217\tvalid_1's l1: 0.119556\n",
      "[3700]\ttraining's l1: 0.116169\tvalid_1's l1: 0.119532\n",
      "[3800]\ttraining's l1: 0.116113\tvalid_1's l1: 0.11952\n",
      "[3900]\ttraining's l1: 0.116072\tvalid_1's l1: 0.119511\n",
      "[4000]\ttraining's l1: 0.116027\tvalid_1's l1: 0.119505\n",
      "[4100]\ttraining's l1: 0.115998\tvalid_1's l1: 0.119498\n",
      "[4200]\ttraining's l1: 0.115962\tvalid_1's l1: 0.119485\n",
      "[4300]\ttraining's l1: 0.11595\tvalid_1's l1: 0.119483\n",
      "[4400]\ttraining's l1: 0.115855\tvalid_1's l1: 0.119483\n",
      "[4500]\ttraining's l1: 0.115653\tvalid_1's l1: 0.119484\n",
      "Early stopping, best iteration is:\n",
      "[4339]\ttraining's l1: 0.115936\tvalid_1's l1: 0.119478\n",
      "fold = 3, score = 0.1194775399863892\n",
      "Fold-4\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.967833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 190008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061804, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.130057\tvalid_1's l1: 0.130266\n",
      "[200]\ttraining's l1: 0.124345\tvalid_1's l1: 0.124629\n",
      "[300]\ttraining's l1: 0.122559\tvalid_1's l1: 0.122833\n",
      "[400]\ttraining's l1: 0.121361\tvalid_1's l1: 0.121672\n",
      "[500]\ttraining's l1: 0.120417\tvalid_1's l1: 0.120796\n",
      "[600]\ttraining's l1: 0.119942\tvalid_1's l1: 0.120382\n",
      "[700]\ttraining's l1: 0.119553\tvalid_1's l1: 0.120127\n",
      "[800]\ttraining's l1: 0.119217\tvalid_1's l1: 0.119923\n",
      "[900]\ttraining's l1: 0.118959\tvalid_1's l1: 0.119721\n",
      "[1000]\ttraining's l1: 0.118597\tvalid_1's l1: 0.119468\n",
      "[1100]\ttraining's l1: 0.118459\tvalid_1's l1: 0.119375\n",
      "[1200]\ttraining's l1: 0.11824\tvalid_1's l1: 0.119297\n",
      "[1300]\ttraining's l1: 0.118065\tvalid_1's l1: 0.119185\n",
      "[1400]\ttraining's l1: 0.117844\tvalid_1's l1: 0.119143\n",
      "[1500]\ttraining's l1: 0.117646\tvalid_1's l1: 0.11904\n",
      "[1600]\ttraining's l1: 0.117504\tvalid_1's l1: 0.118997\n",
      "[1700]\ttraining's l1: 0.117386\tvalid_1's l1: 0.118968\n",
      "[1800]\ttraining's l1: 0.117311\tvalid_1's l1: 0.118956\n",
      "[1900]\ttraining's l1: 0.117248\tvalid_1's l1: 0.11895\n",
      "[2000]\ttraining's l1: 0.117125\tvalid_1's l1: 0.118911\n",
      "[2100]\ttraining's l1: 0.117104\tvalid_1's l1: 0.118905\n",
      "[2200]\ttraining's l1: 0.116888\tvalid_1's l1: 0.118889\n",
      "[2300]\ttraining's l1: 0.116746\tvalid_1's l1: 0.118835\n",
      "[2400]\ttraining's l1: 0.116642\tvalid_1's l1: 0.118791\n",
      "[2500]\ttraining's l1: 0.116581\tvalid_1's l1: 0.118755\n",
      "[2600]\ttraining's l1: 0.116436\tvalid_1's l1: 0.118722\n",
      "[2700]\ttraining's l1: 0.116325\tvalid_1's l1: 0.118722\n",
      "[2800]\ttraining's l1: 0.116245\tvalid_1's l1: 0.118699\n",
      "[2900]\ttraining's l1: 0.116193\tvalid_1's l1: 0.118672\n",
      "[3000]\ttraining's l1: 0.116104\tvalid_1's l1: 0.118644\n",
      "[3100]\ttraining's l1: 0.116086\tvalid_1's l1: 0.118638\n",
      "[3200]\ttraining's l1: 0.116009\tvalid_1's l1: 0.118627\n",
      "[3300]\ttraining's l1: 0.115894\tvalid_1's l1: 0.118586\n",
      "[3400]\ttraining's l1: 0.115799\tvalid_1's l1: 0.118576\n",
      "[3500]\ttraining's l1: 0.115737\tvalid_1's l1: 0.118566\n",
      "[3600]\ttraining's l1: 0.115672\tvalid_1's l1: 0.118554\n",
      "[3700]\ttraining's l1: 0.115633\tvalid_1's l1: 0.118543\n",
      "[3800]\ttraining's l1: 0.115619\tvalid_1's l1: 0.118546\n",
      "Early stopping, best iteration is:\n",
      "[3652]\ttraining's l1: 0.115637\tvalid_1's l1: 0.118542\n",
      "fold = 4, score = 0.11854187445889511\n",
      "Fold-5\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.885078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 190008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061837, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.131821\tvalid_1's l1: 0.13317\n",
      "[200]\ttraining's l1: 0.124852\tvalid_1's l1: 0.125812\n",
      "[300]\ttraining's l1: 0.123144\tvalid_1's l1: 0.124124\n",
      "[400]\ttraining's l1: 0.121221\tvalid_1's l1: 0.122209\n",
      "[500]\ttraining's l1: 0.120327\tvalid_1's l1: 0.121344\n",
      "[600]\ttraining's l1: 0.119961\tvalid_1's l1: 0.121038\n",
      "[700]\ttraining's l1: 0.119652\tvalid_1's l1: 0.120786\n",
      "[800]\ttraining's l1: 0.119343\tvalid_1's l1: 0.120527\n",
      "[900]\ttraining's l1: 0.119105\tvalid_1's l1: 0.120341\n",
      "[1000]\ttraining's l1: 0.118831\tvalid_1's l1: 0.120128\n",
      "[1100]\ttraining's l1: 0.118583\tvalid_1's l1: 0.119973\n",
      "[1200]\ttraining's l1: 0.118431\tvalid_1's l1: 0.119922\n",
      "[1300]\ttraining's l1: 0.118296\tvalid_1's l1: 0.119845\n",
      "[1400]\ttraining's l1: 0.118091\tvalid_1's l1: 0.119677\n",
      "[1500]\ttraining's l1: 0.117926\tvalid_1's l1: 0.119572\n",
      "[1600]\ttraining's l1: 0.117787\tvalid_1's l1: 0.119499\n",
      "[1700]\ttraining's l1: 0.117633\tvalid_1's l1: 0.119438\n",
      "[1800]\ttraining's l1: 0.117508\tvalid_1's l1: 0.119392\n",
      "[1900]\ttraining's l1: 0.117373\tvalid_1's l1: 0.119374\n",
      "[2000]\ttraining's l1: 0.117201\tvalid_1's l1: 0.119323\n",
      "[2100]\ttraining's l1: 0.117024\tvalid_1's l1: 0.119299\n",
      "[2200]\ttraining's l1: 0.11699\tvalid_1's l1: 0.119291\n",
      "[2300]\ttraining's l1: 0.11696\tvalid_1's l1: 0.119276\n",
      "[2400]\ttraining's l1: 0.116938\tvalid_1's l1: 0.119268\n",
      "[2500]\ttraining's l1: 0.116918\tvalid_1's l1: 0.119261\n",
      "[2600]\ttraining's l1: 0.116905\tvalid_1's l1: 0.119258\n",
      "[2700]\ttraining's l1: 0.1169\tvalid_1's l1: 0.119255\n",
      "[2800]\ttraining's l1: 0.116886\tvalid_1's l1: 0.119254\n",
      "[2900]\ttraining's l1: 0.116865\tvalid_1's l1: 0.119253\n",
      "[3000]\ttraining's l1: 0.116724\tvalid_1's l1: 0.119234\n",
      "[3100]\ttraining's l1: 0.116569\tvalid_1's l1: 0.119231\n",
      "[3200]\ttraining's l1: 0.116433\tvalid_1's l1: 0.119211\n",
      "[3300]\ttraining's l1: 0.116353\tvalid_1's l1: 0.11919\n",
      "[3400]\ttraining's l1: 0.116237\tvalid_1's l1: 0.119176\n",
      "[3500]\ttraining's l1: 0.11615\tvalid_1's l1: 0.11914\n",
      "[3600]\ttraining's l1: 0.116103\tvalid_1's l1: 0.119133\n",
      "[3700]\ttraining's l1: 0.116039\tvalid_1's l1: 0.119097\n",
      "[3800]\ttraining's l1: 0.115972\tvalid_1's l1: 0.119072\n",
      "[3900]\ttraining's l1: 0.115919\tvalid_1's l1: 0.119061\n",
      "[4000]\ttraining's l1: 0.115898\tvalid_1's l1: 0.119047\n",
      "[4100]\ttraining's l1: 0.115859\tvalid_1's l1: 0.119029\n",
      "[4200]\ttraining's l1: 0.115797\tvalid_1's l1: 0.119032\n",
      "[4300]\ttraining's l1: 0.115743\tvalid_1's l1: 0.119026\n",
      "Early stopping, best iteration is:\n",
      "[4148]\ttraining's l1: 0.115823\tvalid_1's l1: 0.119013\n",
      "fold = 5, score = 0.11901288412105754\n",
      "Fold-6\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.902140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 190008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061818, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.131586\tvalid_1's l1: 0.130933\n",
      "[200]\ttraining's l1: 0.125412\tvalid_1's l1: 0.125317\n",
      "[300]\ttraining's l1: 0.122908\tvalid_1's l1: 0.122889\n",
      "[400]\ttraining's l1: 0.121487\tvalid_1's l1: 0.12151\n",
      "[500]\ttraining's l1: 0.120646\tvalid_1's l1: 0.12071\n",
      "[600]\ttraining's l1: 0.120043\tvalid_1's l1: 0.120236\n",
      "[700]\ttraining's l1: 0.119707\tvalid_1's l1: 0.119993\n",
      "[800]\ttraining's l1: 0.119339\tvalid_1's l1: 0.119768\n",
      "[900]\ttraining's l1: 0.119193\tvalid_1's l1: 0.119633\n",
      "[1000]\ttraining's l1: 0.118991\tvalid_1's l1: 0.119458\n",
      "[1100]\ttraining's l1: 0.118714\tvalid_1's l1: 0.119311\n",
      "[1200]\ttraining's l1: 0.118428\tvalid_1's l1: 0.119231\n",
      "[1300]\ttraining's l1: 0.118286\tvalid_1's l1: 0.11915\n",
      "[1400]\ttraining's l1: 0.118178\tvalid_1's l1: 0.119116\n",
      "[1500]\ttraining's l1: 0.11806\tvalid_1's l1: 0.119112\n",
      "[1600]\ttraining's l1: 0.117975\tvalid_1's l1: 0.119084\n",
      "[1700]\ttraining's l1: 0.117916\tvalid_1's l1: 0.119048\n",
      "[1800]\ttraining's l1: 0.117866\tvalid_1's l1: 0.119039\n",
      "[1900]\ttraining's l1: 0.11783\tvalid_1's l1: 0.119016\n",
      "[2000]\ttraining's l1: 0.117771\tvalid_1's l1: 0.118996\n",
      "[2100]\ttraining's l1: 0.117713\tvalid_1's l1: 0.118969\n",
      "[2200]\ttraining's l1: 0.117667\tvalid_1's l1: 0.11894\n",
      "[2300]\ttraining's l1: 0.11763\tvalid_1's l1: 0.11893\n",
      "[2400]\ttraining's l1: 0.117597\tvalid_1's l1: 0.11892\n",
      "[2500]\ttraining's l1: 0.117541\tvalid_1's l1: 0.118908\n",
      "[2600]\ttraining's l1: 0.117503\tvalid_1's l1: 0.118899\n",
      "[2700]\ttraining's l1: 0.117466\tvalid_1's l1: 0.118888\n",
      "[2800]\ttraining's l1: 0.117441\tvalid_1's l1: 0.118884\n",
      "[2900]\ttraining's l1: 0.11741\tvalid_1's l1: 0.118867\n",
      "[3000]\ttraining's l1: 0.117382\tvalid_1's l1: 0.11886\n",
      "[3100]\ttraining's l1: 0.117339\tvalid_1's l1: 0.118827\n",
      "[3200]\ttraining's l1: 0.117317\tvalid_1's l1: 0.11882\n",
      "[3300]\ttraining's l1: 0.117297\tvalid_1's l1: 0.118812\n",
      "[3400]\ttraining's l1: 0.117275\tvalid_1's l1: 0.118805\n",
      "[3500]\ttraining's l1: 0.117254\tvalid_1's l1: 0.118799\n",
      "[3600]\ttraining's l1: 0.117238\tvalid_1's l1: 0.118795\n",
      "[3700]\ttraining's l1: 0.117222\tvalid_1's l1: 0.118783\n",
      "[3800]\ttraining's l1: 0.117207\tvalid_1's l1: 0.118771\n",
      "[3900]\ttraining's l1: 0.117167\tvalid_1's l1: 0.118751\n",
      "[4000]\ttraining's l1: 0.117157\tvalid_1's l1: 0.118749\n",
      "[4100]\ttraining's l1: 0.117151\tvalid_1's l1: 0.118746\n",
      "[4200]\ttraining's l1: 0.117146\tvalid_1's l1: 0.118745\n",
      "[4300]\ttraining's l1: 0.117139\tvalid_1's l1: 0.118743\n",
      "[4400]\ttraining's l1: 0.117124\tvalid_1's l1: 0.118736\n",
      "[4500]\ttraining's l1: 0.117117\tvalid_1's l1: 0.118732\n",
      "[4600]\ttraining's l1: 0.117111\tvalid_1's l1: 0.118731\n",
      "[4700]\ttraining's l1: 0.117105\tvalid_1's l1: 0.118732\n",
      "[4800]\ttraining's l1: 0.117098\tvalid_1's l1: 0.118731\n",
      "[4900]\ttraining's l1: 0.117094\tvalid_1's l1: 0.118729\n",
      "[5000]\ttraining's l1: 0.117093\tvalid_1's l1: 0.118729\n",
      "[5100]\ttraining's l1: 0.117092\tvalid_1's l1: 0.118729\n",
      "[5200]\ttraining's l1: 0.117077\tvalid_1's l1: 0.118728\n",
      "[5300]\ttraining's l1: 0.117075\tvalid_1's l1: 0.118726\n",
      "[5400]\ttraining's l1: 0.117012\tvalid_1's l1: 0.118689\n",
      "[5500]\ttraining's l1: 0.116968\tvalid_1's l1: 0.118663\n",
      "[5600]\ttraining's l1: 0.116787\tvalid_1's l1: 0.118649\n",
      "[5700]\ttraining's l1: 0.116726\tvalid_1's l1: 0.118611\n",
      "[5800]\ttraining's l1: 0.116643\tvalid_1's l1: 0.118575\n",
      "[5900]\ttraining's l1: 0.116574\tvalid_1's l1: 0.118554\n",
      "[6000]\ttraining's l1: 0.116533\tvalid_1's l1: 0.118548\n",
      "[6100]\ttraining's l1: 0.116427\tvalid_1's l1: 0.118536\n",
      "[6200]\ttraining's l1: 0.116342\tvalid_1's l1: 0.118542\n",
      "Early stopping, best iteration is:\n",
      "[6059]\ttraining's l1: 0.11649\tvalid_1's l1: 0.118532\n",
      "fold = 6, score = 0.11853171326407712\n",
      "Fold-7\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.888728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 190008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061785, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.130522\tvalid_1's l1: 0.133347\n",
      "[200]\ttraining's l1: 0.125007\tvalid_1's l1: 0.127798\n",
      "[300]\ttraining's l1: 0.123063\tvalid_1's l1: 0.125916\n",
      "[400]\ttraining's l1: 0.121057\tvalid_1's l1: 0.123998\n",
      "[500]\ttraining's l1: 0.120237\tvalid_1's l1: 0.123261\n",
      "[600]\ttraining's l1: 0.119876\tvalid_1's l1: 0.122946\n",
      "[700]\ttraining's l1: 0.119491\tvalid_1's l1: 0.122687\n",
      "[800]\ttraining's l1: 0.119167\tvalid_1's l1: 0.122481\n",
      "[900]\ttraining's l1: 0.118857\tvalid_1's l1: 0.122281\n",
      "[1000]\ttraining's l1: 0.118695\tvalid_1's l1: 0.122222\n",
      "[1100]\ttraining's l1: 0.118529\tvalid_1's l1: 0.122151\n",
      "[1200]\ttraining's l1: 0.118268\tvalid_1's l1: 0.122008\n",
      "[1300]\ttraining's l1: 0.118071\tvalid_1's l1: 0.121957\n",
      "[1400]\ttraining's l1: 0.117955\tvalid_1's l1: 0.121924\n",
      "[1500]\ttraining's l1: 0.117906\tvalid_1's l1: 0.12191\n",
      "[1600]\ttraining's l1: 0.117864\tvalid_1's l1: 0.121918\n",
      "[1700]\ttraining's l1: 0.117833\tvalid_1's l1: 0.121905\n",
      "[1800]\ttraining's l1: 0.117821\tvalid_1's l1: 0.121901\n",
      "[1900]\ttraining's l1: 0.117804\tvalid_1's l1: 0.12189\n",
      "[2000]\ttraining's l1: 0.117797\tvalid_1's l1: 0.121887\n",
      "[2100]\ttraining's l1: 0.117786\tvalid_1's l1: 0.121883\n",
      "[2200]\ttraining's l1: 0.117776\tvalid_1's l1: 0.121874\n",
      "[2300]\ttraining's l1: 0.117771\tvalid_1's l1: 0.121872\n",
      "[2400]\ttraining's l1: 0.117763\tvalid_1's l1: 0.121872\n",
      "[2500]\ttraining's l1: 0.117714\tvalid_1's l1: 0.121865\n",
      "[2600]\ttraining's l1: 0.117623\tvalid_1's l1: 0.121808\n",
      "[2700]\ttraining's l1: 0.117486\tvalid_1's l1: 0.121729\n",
      "[2800]\ttraining's l1: 0.117406\tvalid_1's l1: 0.121703\n",
      "[2900]\ttraining's l1: 0.117329\tvalid_1's l1: 0.121666\n",
      "[3000]\ttraining's l1: 0.117262\tvalid_1's l1: 0.121622\n",
      "[3100]\ttraining's l1: 0.117182\tvalid_1's l1: 0.121568\n",
      "[3200]\ttraining's l1: 0.117128\tvalid_1's l1: 0.121537\n",
      "[3300]\ttraining's l1: 0.117042\tvalid_1's l1: 0.121506\n",
      "[3400]\ttraining's l1: 0.116933\tvalid_1's l1: 0.121484\n",
      "[3500]\ttraining's l1: 0.116822\tvalid_1's l1: 0.121476\n",
      "[3600]\ttraining's l1: 0.11666\tvalid_1's l1: 0.121422\n",
      "[3700]\ttraining's l1: 0.116528\tvalid_1's l1: 0.121377\n",
      "[3800]\ttraining's l1: 0.116409\tvalid_1's l1: 0.12133\n",
      "[3900]\ttraining's l1: 0.116304\tvalid_1's l1: 0.1213\n",
      "[4000]\ttraining's l1: 0.116168\tvalid_1's l1: 0.121278\n",
      "[4100]\ttraining's l1: 0.1161\tvalid_1's l1: 0.121262\n",
      "[4200]\ttraining's l1: 0.115996\tvalid_1's l1: 0.121252\n",
      "[4300]\ttraining's l1: 0.115953\tvalid_1's l1: 0.121243\n",
      "[4400]\ttraining's l1: 0.115945\tvalid_1's l1: 0.121243\n",
      "[4500]\ttraining's l1: 0.115822\tvalid_1's l1: 0.121177\n",
      "[4600]\ttraining's l1: 0.115767\tvalid_1's l1: 0.121166\n",
      "[4700]\ttraining's l1: 0.115636\tvalid_1's l1: 0.121154\n",
      "[4800]\ttraining's l1: 0.115589\tvalid_1's l1: 0.121142\n",
      "[4900]\ttraining's l1: 0.11552\tvalid_1's l1: 0.121142\n",
      "[5000]\ttraining's l1: 0.115402\tvalid_1's l1: 0.121134\n",
      "[5100]\ttraining's l1: 0.115306\tvalid_1's l1: 0.12111\n",
      "[5200]\ttraining's l1: 0.11514\tvalid_1's l1: 0.121114\n",
      "[5300]\ttraining's l1: 0.115069\tvalid_1's l1: 0.121118\n",
      "[5400]\ttraining's l1: 0.114975\tvalid_1's l1: 0.121106\n",
      "[5500]\ttraining's l1: 0.114902\tvalid_1's l1: 0.1211\n",
      "[5600]\ttraining's l1: 0.114864\tvalid_1's l1: 0.121098\n",
      "[5700]\ttraining's l1: 0.114837\tvalid_1's l1: 0.121101\n",
      "[5800]\ttraining's l1: 0.114798\tvalid_1's l1: 0.121098\n",
      "[5900]\ttraining's l1: 0.114748\tvalid_1's l1: 0.121089\n",
      "[6000]\ttraining's l1: 0.114723\tvalid_1's l1: 0.121086\n",
      "[6100]\ttraining's l1: 0.11466\tvalid_1's l1: 0.121091\n",
      "[6200]\ttraining's l1: 0.114575\tvalid_1's l1: 0.12109\n",
      "[6300]\ttraining's l1: 0.114407\tvalid_1's l1: 0.121101\n",
      "Early stopping, best iteration is:\n",
      "[6192]\ttraining's l1: 0.114605\tvalid_1's l1: 0.12108\n",
      "fold = 7, score = 0.12108006180412476\n",
      "Fold-8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.890946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 190008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061827, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 15.890698\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.131915\tvalid_1's l1: 0.133293\n",
      "[200]\ttraining's l1: 0.12383\tvalid_1's l1: 0.124682\n",
      "[300]\ttraining's l1: 0.12188\tvalid_1's l1: 0.122689\n",
      "[400]\ttraining's l1: 0.121066\tvalid_1's l1: 0.121858\n",
      "[500]\ttraining's l1: 0.120488\tvalid_1's l1: 0.121325\n",
      "[600]\ttraining's l1: 0.119946\tvalid_1's l1: 0.120817\n",
      "[700]\ttraining's l1: 0.119517\tvalid_1's l1: 0.120472\n",
      "[800]\ttraining's l1: 0.11919\tvalid_1's l1: 0.120282\n",
      "[900]\ttraining's l1: 0.118972\tvalid_1's l1: 0.120111\n",
      "[1000]\ttraining's l1: 0.118652\tvalid_1's l1: 0.119907\n",
      "[1100]\ttraining's l1: 0.118387\tvalid_1's l1: 0.119755\n",
      "[1200]\ttraining's l1: 0.118204\tvalid_1's l1: 0.119645\n",
      "[1300]\ttraining's l1: 0.118021\tvalid_1's l1: 0.119555\n",
      "[1400]\ttraining's l1: 0.117872\tvalid_1's l1: 0.119456\n",
      "[1500]\ttraining's l1: 0.11772\tvalid_1's l1: 0.119371\n",
      "[1600]\ttraining's l1: 0.117572\tvalid_1's l1: 0.119309\n",
      "[1700]\ttraining's l1: 0.117521\tvalid_1's l1: 0.119299\n",
      "[1800]\ttraining's l1: 0.117492\tvalid_1's l1: 0.119289\n",
      "[1900]\ttraining's l1: 0.11745\tvalid_1's l1: 0.119272\n",
      "[2000]\ttraining's l1: 0.117332\tvalid_1's l1: 0.119187\n",
      "[2100]\ttraining's l1: 0.117226\tvalid_1's l1: 0.119137\n",
      "[2200]\ttraining's l1: 0.117142\tvalid_1's l1: 0.119115\n",
      "[2300]\ttraining's l1: 0.116965\tvalid_1's l1: 0.119077\n",
      "[2400]\ttraining's l1: 0.116863\tvalid_1's l1: 0.119061\n",
      "[2500]\ttraining's l1: 0.116746\tvalid_1's l1: 0.11903\n",
      "[2600]\ttraining's l1: 0.116656\tvalid_1's l1: 0.118989\n",
      "[2700]\ttraining's l1: 0.116565\tvalid_1's l1: 0.118982\n",
      "[2800]\ttraining's l1: 0.116481\tvalid_1's l1: 0.118971\n",
      "[2900]\ttraining's l1: 0.116425\tvalid_1's l1: 0.118953\n",
      "[3000]\ttraining's l1: 0.116377\tvalid_1's l1: 0.118942\n",
      "[3100]\ttraining's l1: 0.11626\tvalid_1's l1: 0.118929\n",
      "[3200]\ttraining's l1: 0.116128\tvalid_1's l1: 0.118889\n",
      "[3300]\ttraining's l1: 0.116071\tvalid_1's l1: 0.118904\n",
      "[3400]\ttraining's l1: 0.116039\tvalid_1's l1: 0.1189\n",
      "Early stopping, best iteration is:\n",
      "[3200]\ttraining's l1: 0.116128\tvalid_1's l1: 0.118889\n",
      "fold = 8, score = 0.11888876252308903\n",
      "Fold-9\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.890260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 190008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061896, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.130766\tvalid_1's l1: 0.131676\n",
      "[200]\ttraining's l1: 0.123636\tvalid_1's l1: 0.123976\n",
      "[300]\ttraining's l1: 0.121777\tvalid_1's l1: 0.122142\n",
      "[400]\ttraining's l1: 0.121087\tvalid_1's l1: 0.121481\n",
      "[500]\ttraining's l1: 0.120317\tvalid_1's l1: 0.120853\n",
      "[600]\ttraining's l1: 0.11981\tvalid_1's l1: 0.120438\n",
      "[700]\ttraining's l1: 0.119339\tvalid_1's l1: 0.120095\n",
      "[800]\ttraining's l1: 0.119033\tvalid_1's l1: 0.119903\n",
      "[900]\ttraining's l1: 0.118791\tvalid_1's l1: 0.119702\n",
      "[1000]\ttraining's l1: 0.118527\tvalid_1's l1: 0.119488\n",
      "[1100]\ttraining's l1: 0.118351\tvalid_1's l1: 0.11943\n",
      "[1200]\ttraining's l1: 0.118203\tvalid_1's l1: 0.119338\n",
      "[1300]\ttraining's l1: 0.118075\tvalid_1's l1: 0.119275\n",
      "[1400]\ttraining's l1: 0.11798\tvalid_1's l1: 0.119222\n",
      "[1500]\ttraining's l1: 0.117909\tvalid_1's l1: 0.11916\n",
      "[1600]\ttraining's l1: 0.117862\tvalid_1's l1: 0.119134\n",
      "[1700]\ttraining's l1: 0.117805\tvalid_1's l1: 0.119093\n",
      "[1800]\ttraining's l1: 0.117745\tvalid_1's l1: 0.119086\n",
      "[1900]\ttraining's l1: 0.117594\tvalid_1's l1: 0.119038\n",
      "[2000]\ttraining's l1: 0.117536\tvalid_1's l1: 0.119013\n",
      "[2100]\ttraining's l1: 0.117444\tvalid_1's l1: 0.118981\n",
      "[2200]\ttraining's l1: 0.117353\tvalid_1's l1: 0.118954\n",
      "[2300]\ttraining's l1: 0.117285\tvalid_1's l1: 0.118904\n",
      "[2400]\ttraining's l1: 0.117173\tvalid_1's l1: 0.118859\n",
      "[2500]\ttraining's l1: 0.11711\tvalid_1's l1: 0.118833\n",
      "[2600]\ttraining's l1: 0.11704\tvalid_1's l1: 0.118811\n",
      "[2700]\ttraining's l1: 0.116969\tvalid_1's l1: 0.11878\n",
      "[2800]\ttraining's l1: 0.116892\tvalid_1's l1: 0.118733\n",
      "[2900]\ttraining's l1: 0.116794\tvalid_1's l1: 0.118703\n",
      "[3000]\ttraining's l1: 0.116732\tvalid_1's l1: 0.118682\n",
      "[3100]\ttraining's l1: 0.11668\tvalid_1's l1: 0.118673\n",
      "[3200]\ttraining's l1: 0.116639\tvalid_1's l1: 0.118654\n",
      "[3300]\ttraining's l1: 0.116602\tvalid_1's l1: 0.118641\n",
      "[3400]\ttraining's l1: 0.11657\tvalid_1's l1: 0.118636\n",
      "[3500]\ttraining's l1: 0.11654\tvalid_1's l1: 0.118618\n",
      "[3600]\ttraining's l1: 0.116511\tvalid_1's l1: 0.118608\n",
      "[3700]\ttraining's l1: 0.116498\tvalid_1's l1: 0.118599\n",
      "[3800]\ttraining's l1: 0.116482\tvalid_1's l1: 0.11859\n",
      "[3900]\ttraining's l1: 0.116465\tvalid_1's l1: 0.118594\n",
      "[4000]\ttraining's l1: 0.116449\tvalid_1's l1: 0.11859\n",
      "Early stopping, best iteration is:\n",
      "[3807]\ttraining's l1: 0.116481\tvalid_1's l1: 0.118589\n",
      "fold = 9, score = 0.11858903398961544\n"
     ]
    }
   ],
   "source": [
    "oof_prediction = np.zeros(len(train_df))\n",
    "test_preds_lst = []\n",
    "input_dim = len(train_value_col)\n",
    "train_df['pred'] = 0\n",
    "train_gby = train_df.groupby('breath_id')['R_C'].agg('first').reset_index()\n",
    "skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "models = []\n",
    "\n",
    "\n",
    "fold_df = pd.DataFrame()\n",
    "fold_df[\"id\"] = train[\"id\"]\n",
    "fold_df[\"fold\"] = -1\n",
    "\n",
    "for fold, (_, valid_idx) in enumerate(skf.split(train_gby, train_gby['R_C'])):        \n",
    "    valid_b_ids = train_gby.iloc[valid_idx]['breath_id'].values\n",
    "    valid_df_idx = train_df[train_df['breath_id'].isin(valid_b_ids)].index.to_list()\n",
    "    fold_df.loc[valid_df_idx, 'fold'] = fold\n",
    "\n",
    "for i, fold in enumerate(range(CFG.n_folds)):\n",
    "    if i not in CFG.folds:\n",
    "        continue\n",
    "    print(f'Fold-{fold}')\n",
    "    \n",
    "    train_idx = fold_df[fold_df[\"fold\"] != fold].index\n",
    "    valid_idx = fold_df[fold_df[\"fold\"] == fold].index\n",
    "    \n",
    "    trn_df = train_df.loc[fold_df[\"fold\"] != fold, train_value_col].reset_index(drop=True)\n",
    "    val_df = train_df.loc[fold_df[\"fold\"] == fold, train_value_col].reset_index(drop=True)\n",
    "    trn_y = train_df.loc[fold_df[\"fold\"] != fold, 'pressure'].reset_index(drop=True)\n",
    "    val_y = train_df.loc[fold_df[\"fold\"] == fold, 'pressure'].reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    lgb_train = lgb.Dataset(trn_df, trn_y)\n",
    "    lgb_valid = lgb.Dataset(val_df, val_y, reference=lgb_train)\n",
    "\n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "             'objective': 'l1',\n",
    "            'metric': 'l1',\n",
    "            'seed': CFG.seed,\n",
    "            'max_bin': 2000,\n",
    "            'num_boost_round': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'lambda_l1': 0.1,\n",
    "            'lambda_l2': 0.1,\n",
    "    }\n",
    "\n",
    "\n",
    "    model = lgb.train(params, \n",
    "                      train_set=lgb_train, \n",
    "                      valid_sets=[lgb_train, lgb_valid], early_stopping_rounds=200, verbose_eval=100)\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "    oof_prediction[valid_idx] = model.predict(val_df[train_value_col])\n",
    "    test_pred = model.predict(test_df[train_value_col])\n",
    "    test_preds_lst.append(test_pred)\n",
    "    score = np.abs(val_y.values - oof_prediction[valid_idx]).mean()\n",
    "    print(f'fold = {fold}, score = {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880989174922657"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV = np.abs(y.values - oof_prediction).mean()\n",
    "CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(OUTPUT_DIR / f\"stacking3_oof_{CFG.exp_num}\", oof_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pressures = train[\"pressure\"].unique()\n",
    "sorted_pressures = np.sort(unique_pressures)\n",
    "total_pressures_len = len(sorted_pressures)\n",
    "\n",
    "def find_nearest(prediction):\n",
    "    insert_idx = np.searchsorted(sorted_pressures, prediction)\n",
    "    if insert_idx == total_pressures_len:\n",
    "        # If the predicted value is bigger than the highest pressure in the train dataset,\n",
    "        # return the max value.\n",
    "        return sorted_pressures[-1]\n",
    "    elif insert_idx == 0:\n",
    "        # Same control but for the lower bound.\n",
    "        return sorted_pressures[0]\n",
    "    lower_val = sorted_pressures[insert_idx - 1]\n",
    "    upper_val = sorted_pressures[insert_idx]\n",
    "    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11771671037730122\n"
     ]
    }
   ],
   "source": [
    "oof = pd.DataFrame({'pred': oof_prediction})\n",
    "oof_pp = oof['pred'].map(lambda x: unique_pressures[np.abs(unique_pressures-x).argmin()])\n",
    "score = np.abs(y.values - oof_pp).mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(DATA_DIR / \"sample_submission.csv\")\n",
    "\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = np.stack(test_preds_lst).mean(0)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking3_submission_mean_{CFG.exp_num}.csv\", index=None)\n",
    "\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = np.median(np.stack(test_preds_lst), axis=0)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking3_submission_median_{CFG.exp_num}.csv\", index=None)\n",
    "\n",
    "# Post Processing: https://www.kaggle.com/snnclsr/a-dummy-approach-to-improve-your-score-postprocess\n",
    "\n",
    "\n",
    "sub_df = pd.read_csv(OUTPUT_DIR / f\"stacking3_submission_mean_{CFG.exp_num}.csv\")\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = sub_df[\"pressure\"].apply(find_nearest)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking3_submission_mean_pp_{CFG.exp_num}.csv\", index=None)\n",
    "\n",
    "sub_df = pd.read_csv(OUTPUT_DIR / f\"stacking3_submission_median_{CFG.exp_num}.csv\")\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = sub_df[\"pressure\"].apply(find_nearest)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking3_submission_median_pp_{CFG.exp_num}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5cb25c469b873a0e0eec115bfbbdb6f77ff8970c2724434dd7f3f7fbd6e0533"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
