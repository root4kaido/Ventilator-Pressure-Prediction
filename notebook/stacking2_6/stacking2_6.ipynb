{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    exp_num = 6\n",
    "    n_folds = 10\n",
    "    folds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    seed = 777\n",
    "    local = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/ventilator-pressure-prediction\")\n",
    "OUTPUT_DIR = Path('./output/')\n",
    "OOF_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_oofs_stacking\")\n",
    "SUB_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_subs_stacking\")\n",
    "PICKLE_DIR = Path(\"/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_stacking_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../src/')\n",
    "import utils as utils\n",
    "from utils import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_paths = sorted(list(OOF_DIR.rglob('*.npy'))+list(OOF_DIR.rglob('*.csv')))\n",
    "sub_paths = sorted(list(SUB_DIR.rglob('*.npy'))+list(SUB_DIR.rglob('*.csv')))\n",
    "\n",
    "len(oof_paths), len(sub_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLE_DIR / \"train_only_1st_stacking.pickle\", mode=\"rb\") as f:\n",
    "    oofs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs = oofs.iloc[:, 8:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>pred_10</th>\n",
       "      <th>pred_11</th>\n",
       "      <th>pred_12</th>\n",
       "      <th>pred_13</th>\n",
       "      <th>pred_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.833371</td>\n",
       "      <td>5.787222</td>\n",
       "      <td>6.023309</td>\n",
       "      <td>5.693756</td>\n",
       "      <td>5.820899</td>\n",
       "      <td>5.523668</td>\n",
       "      <td>5.898385</td>\n",
       "      <td>5.878293</td>\n",
       "      <td>5.883394</td>\n",
       "      <td>5.864807</td>\n",
       "      <td>5.941694</td>\n",
       "      <td>5.814224</td>\n",
       "      <td>5.805068</td>\n",
       "      <td>5.862573</td>\n",
       "      <td>5.773038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.938485</td>\n",
       "      <td>5.887587</td>\n",
       "      <td>5.845187</td>\n",
       "      <td>5.917422</td>\n",
       "      <td>5.824658</td>\n",
       "      <td>5.929617</td>\n",
       "      <td>5.857195</td>\n",
       "      <td>5.873602</td>\n",
       "      <td>5.898860</td>\n",
       "      <td>5.866838</td>\n",
       "      <td>5.846353</td>\n",
       "      <td>5.847313</td>\n",
       "      <td>5.846550</td>\n",
       "      <td>5.848502</td>\n",
       "      <td>5.877314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.245914</td>\n",
       "      <td>8.147405</td>\n",
       "      <td>7.962515</td>\n",
       "      <td>7.924459</td>\n",
       "      <td>8.030790</td>\n",
       "      <td>8.095352</td>\n",
       "      <td>7.991342</td>\n",
       "      <td>8.220143</td>\n",
       "      <td>8.093781</td>\n",
       "      <td>8.102347</td>\n",
       "      <td>8.084612</td>\n",
       "      <td>8.069213</td>\n",
       "      <td>7.975787</td>\n",
       "      <td>7.955888</td>\n",
       "      <td>8.036733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.079426</td>\n",
       "      <td>12.057881</td>\n",
       "      <td>11.971588</td>\n",
       "      <td>12.247079</td>\n",
       "      <td>11.877783</td>\n",
       "      <td>12.134422</td>\n",
       "      <td>12.059141</td>\n",
       "      <td>12.239809</td>\n",
       "      <td>12.114367</td>\n",
       "      <td>12.041298</td>\n",
       "      <td>12.239206</td>\n",
       "      <td>12.118088</td>\n",
       "      <td>12.002528</td>\n",
       "      <td>12.016686</td>\n",
       "      <td>11.990269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.523297</td>\n",
       "      <td>12.538396</td>\n",
       "      <td>12.531747</td>\n",
       "      <td>12.404102</td>\n",
       "      <td>12.507798</td>\n",
       "      <td>12.600920</td>\n",
       "      <td>12.567769</td>\n",
       "      <td>12.644754</td>\n",
       "      <td>12.594013</td>\n",
       "      <td>12.576857</td>\n",
       "      <td>12.477226</td>\n",
       "      <td>12.604493</td>\n",
       "      <td>12.502975</td>\n",
       "      <td>12.537569</td>\n",
       "      <td>12.526273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290963</th>\n",
       "      <td>29.465751</td>\n",
       "      <td>29.468914</td>\n",
       "      <td>29.481145</td>\n",
       "      <td>29.442779</td>\n",
       "      <td>29.476760</td>\n",
       "      <td>29.459700</td>\n",
       "      <td>29.461234</td>\n",
       "      <td>29.455700</td>\n",
       "      <td>29.447010</td>\n",
       "      <td>29.446421</td>\n",
       "      <td>29.463127</td>\n",
       "      <td>29.460402</td>\n",
       "      <td>29.423048</td>\n",
       "      <td>29.461472</td>\n",
       "      <td>29.469219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290964</th>\n",
       "      <td>29.107071</td>\n",
       "      <td>29.119773</td>\n",
       "      <td>29.114014</td>\n",
       "      <td>29.128193</td>\n",
       "      <td>29.140826</td>\n",
       "      <td>29.138840</td>\n",
       "      <td>29.117303</td>\n",
       "      <td>29.121960</td>\n",
       "      <td>29.119019</td>\n",
       "      <td>29.114550</td>\n",
       "      <td>29.111472</td>\n",
       "      <td>29.111569</td>\n",
       "      <td>29.086384</td>\n",
       "      <td>29.109639</td>\n",
       "      <td>29.110482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290965</th>\n",
       "      <td>29.874415</td>\n",
       "      <td>29.878339</td>\n",
       "      <td>29.910456</td>\n",
       "      <td>29.884028</td>\n",
       "      <td>29.887930</td>\n",
       "      <td>29.883578</td>\n",
       "      <td>29.886303</td>\n",
       "      <td>29.888802</td>\n",
       "      <td>29.877069</td>\n",
       "      <td>29.880650</td>\n",
       "      <td>29.896856</td>\n",
       "      <td>29.892732</td>\n",
       "      <td>29.874448</td>\n",
       "      <td>29.880339</td>\n",
       "      <td>29.886278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290966</th>\n",
       "      <td>29.389308</td>\n",
       "      <td>29.391641</td>\n",
       "      <td>29.388630</td>\n",
       "      <td>29.388361</td>\n",
       "      <td>29.380993</td>\n",
       "      <td>29.397045</td>\n",
       "      <td>29.375070</td>\n",
       "      <td>29.397812</td>\n",
       "      <td>29.391010</td>\n",
       "      <td>29.390039</td>\n",
       "      <td>29.391071</td>\n",
       "      <td>29.388413</td>\n",
       "      <td>29.382864</td>\n",
       "      <td>29.373224</td>\n",
       "      <td>29.380328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290967</th>\n",
       "      <td>30.028628</td>\n",
       "      <td>30.069012</td>\n",
       "      <td>30.075131</td>\n",
       "      <td>30.070247</td>\n",
       "      <td>30.065571</td>\n",
       "      <td>30.056584</td>\n",
       "      <td>30.107550</td>\n",
       "      <td>30.082020</td>\n",
       "      <td>30.070402</td>\n",
       "      <td>30.072382</td>\n",
       "      <td>30.052643</td>\n",
       "      <td>30.087266</td>\n",
       "      <td>30.072513</td>\n",
       "      <td>30.066792</td>\n",
       "      <td>30.028275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2290968 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred_0     pred_1     pred_2     pred_3     pred_4     pred_5  \\\n",
       "0         5.833371   5.787222   6.023309   5.693756   5.820899   5.523668   \n",
       "1         5.938485   5.887587   5.845187   5.917422   5.824658   5.929617   \n",
       "2         8.245914   8.147405   7.962515   7.924459   8.030790   8.095352   \n",
       "3        12.079426  12.057881  11.971588  12.247079  11.877783  12.134422   \n",
       "4        12.523297  12.538396  12.531747  12.404102  12.507798  12.600920   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "2290963  29.465751  29.468914  29.481145  29.442779  29.476760  29.459700   \n",
       "2290964  29.107071  29.119773  29.114014  29.128193  29.140826  29.138840   \n",
       "2290965  29.874415  29.878339  29.910456  29.884028  29.887930  29.883578   \n",
       "2290966  29.389308  29.391641  29.388630  29.388361  29.380993  29.397045   \n",
       "2290967  30.028628  30.069012  30.075131  30.070247  30.065571  30.056584   \n",
       "\n",
       "            pred_6     pred_7     pred_8     pred_9    pred_10    pred_11  \\\n",
       "0         5.898385   5.878293   5.883394   5.864807   5.941694   5.814224   \n",
       "1         5.857195   5.873602   5.898860   5.866838   5.846353   5.847313   \n",
       "2         7.991342   8.220143   8.093781   8.102347   8.084612   8.069213   \n",
       "3        12.059141  12.239809  12.114367  12.041298  12.239206  12.118088   \n",
       "4        12.567769  12.644754  12.594013  12.576857  12.477226  12.604493   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "2290963  29.461234  29.455700  29.447010  29.446421  29.463127  29.460402   \n",
       "2290964  29.117303  29.121960  29.119019  29.114550  29.111472  29.111569   \n",
       "2290965  29.886303  29.888802  29.877069  29.880650  29.896856  29.892732   \n",
       "2290966  29.375070  29.397812  29.391010  29.390039  29.391071  29.388413   \n",
       "2290967  30.107550  30.082020  30.070402  30.072382  30.052643  30.087266   \n",
       "\n",
       "           pred_12    pred_13    pred_14  \n",
       "0         5.805068   5.862573   5.773038  \n",
       "1         5.846550   5.848502   5.877314  \n",
       "2         7.975787   7.955888   8.036733  \n",
       "3        12.002528  12.016686  11.990269  \n",
       "4        12.502975  12.537569  12.526273  \n",
       "...            ...        ...        ...  \n",
       "2290963  29.423048  29.461472  29.469219  \n",
       "2290964  29.086384  29.109639  29.110482  \n",
       "2290965  29.874448  29.880339  29.886278  \n",
       "2290966  29.382864  29.373224  29.380328  \n",
       "2290967  30.072513  30.066792  30.028275  \n",
       "\n",
       "[2290968 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oofs.columns = [f\"pred_{i}\" for i in range(len(oofs.columns))]\n",
    "oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLE_DIR / \"test_only_1st_stacking.pickle\", mode=\"rb\") as f:\n",
    "    subs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = subs.iloc[:, 7:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>pred_10</th>\n",
       "      <th>pred_11</th>\n",
       "      <th>pred_12</th>\n",
       "      <th>pred_13</th>\n",
       "      <th>pred_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.274139</td>\n",
       "      <td>6.234902</td>\n",
       "      <td>6.248912</td>\n",
       "      <td>6.264675</td>\n",
       "      <td>6.255715</td>\n",
       "      <td>6.270192</td>\n",
       "      <td>6.254150</td>\n",
       "      <td>6.245424</td>\n",
       "      <td>6.247398</td>\n",
       "      <td>6.248691</td>\n",
       "      <td>6.234512</td>\n",
       "      <td>6.244083</td>\n",
       "      <td>6.239510</td>\n",
       "      <td>6.234668</td>\n",
       "      <td>6.242348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.000910</td>\n",
       "      <td>5.972803</td>\n",
       "      <td>5.974298</td>\n",
       "      <td>5.978864</td>\n",
       "      <td>5.977430</td>\n",
       "      <td>5.970970</td>\n",
       "      <td>5.981585</td>\n",
       "      <td>5.977894</td>\n",
       "      <td>5.978619</td>\n",
       "      <td>5.979913</td>\n",
       "      <td>5.982571</td>\n",
       "      <td>5.995547</td>\n",
       "      <td>5.973396</td>\n",
       "      <td>5.970536</td>\n",
       "      <td>5.979932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.145276</td>\n",
       "      <td>7.127580</td>\n",
       "      <td>7.114281</td>\n",
       "      <td>7.185232</td>\n",
       "      <td>7.164241</td>\n",
       "      <td>7.154575</td>\n",
       "      <td>7.165225</td>\n",
       "      <td>7.141719</td>\n",
       "      <td>7.146804</td>\n",
       "      <td>7.142194</td>\n",
       "      <td>7.149453</td>\n",
       "      <td>7.138753</td>\n",
       "      <td>7.121976</td>\n",
       "      <td>7.120587</td>\n",
       "      <td>7.118664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.765169</td>\n",
       "      <td>7.751527</td>\n",
       "      <td>7.740086</td>\n",
       "      <td>7.747494</td>\n",
       "      <td>7.752016</td>\n",
       "      <td>7.730515</td>\n",
       "      <td>7.737912</td>\n",
       "      <td>7.702444</td>\n",
       "      <td>7.704516</td>\n",
       "      <td>7.705604</td>\n",
       "      <td>7.772260</td>\n",
       "      <td>7.740436</td>\n",
       "      <td>7.688272</td>\n",
       "      <td>7.684845</td>\n",
       "      <td>7.707492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.219263</td>\n",
       "      <td>9.211786</td>\n",
       "      <td>9.215903</td>\n",
       "      <td>9.238264</td>\n",
       "      <td>9.225886</td>\n",
       "      <td>9.231619</td>\n",
       "      <td>9.219219</td>\n",
       "      <td>9.219450</td>\n",
       "      <td>9.212603</td>\n",
       "      <td>9.214954</td>\n",
       "      <td>9.230925</td>\n",
       "      <td>9.249313</td>\n",
       "      <td>9.231130</td>\n",
       "      <td>9.221489</td>\n",
       "      <td>9.240027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023995</th>\n",
       "      <td>13.629684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.043241</td>\n",
       "      <td>13.823712</td>\n",
       "      <td>13.164266</td>\n",
       "      <td>14.155994</td>\n",
       "      <td>13.728745</td>\n",
       "      <td>14.426674</td>\n",
       "      <td>28.574068</td>\n",
       "      <td>14.213044</td>\n",
       "      <td>14.063761</td>\n",
       "      <td>13.676671</td>\n",
       "      <td>14.365964</td>\n",
       "      <td>14.153107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023996</th>\n",
       "      <td>13.785939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.845679</td>\n",
       "      <td>13.816230</td>\n",
       "      <td>13.322442</td>\n",
       "      <td>14.111152</td>\n",
       "      <td>14.042326</td>\n",
       "      <td>14.669333</td>\n",
       "      <td>29.799187</td>\n",
       "      <td>14.399313</td>\n",
       "      <td>13.898353</td>\n",
       "      <td>14.014549</td>\n",
       "      <td>14.781502</td>\n",
       "      <td>14.449735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023997</th>\n",
       "      <td>14.146443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.994447</td>\n",
       "      <td>13.984568</td>\n",
       "      <td>13.530339</td>\n",
       "      <td>14.174723</td>\n",
       "      <td>14.331810</td>\n",
       "      <td>15.028529</td>\n",
       "      <td>30.255470</td>\n",
       "      <td>14.419702</td>\n",
       "      <td>14.630459</td>\n",
       "      <td>14.213983</td>\n",
       "      <td>14.877322</td>\n",
       "      <td>14.795870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023998</th>\n",
       "      <td>14.354524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.225302</td>\n",
       "      <td>14.286920</td>\n",
       "      <td>13.157774</td>\n",
       "      <td>14.750629</td>\n",
       "      <td>14.073773</td>\n",
       "      <td>14.739818</td>\n",
       "      <td>30.044895</td>\n",
       "      <td>14.306656</td>\n",
       "      <td>14.117593</td>\n",
       "      <td>14.409499</td>\n",
       "      <td>15.085758</td>\n",
       "      <td>14.273345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023999</th>\n",
       "      <td>14.032889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.391728</td>\n",
       "      <td>13.497197</td>\n",
       "      <td>12.981979</td>\n",
       "      <td>14.135050</td>\n",
       "      <td>8.081411</td>\n",
       "      <td>8.534279</td>\n",
       "      <td>13.451024</td>\n",
       "      <td>14.110665</td>\n",
       "      <td>14.731728</td>\n",
       "      <td>14.567464</td>\n",
       "      <td>15.171421</td>\n",
       "      <td>14.395846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4024000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred_0    pred_1    pred_2     pred_3     pred_4     pred_5  \\\n",
       "0         6.274139  6.234902  6.248912   6.264675   6.255715   6.270192   \n",
       "1         6.000910  5.972803  5.974298   5.978864   5.977430   5.970970   \n",
       "2         7.145276  7.127580  7.114281   7.185232   7.164241   7.154575   \n",
       "3         7.765169  7.751527  7.740086   7.747494   7.752016   7.730515   \n",
       "4         9.219263  9.211786  9.215903   9.238264   9.225886   9.231619   \n",
       "...            ...       ...       ...        ...        ...        ...   \n",
       "4023995  13.629684  0.000000  0.000000  14.043241  13.823712  13.164266   \n",
       "4023996  13.785939  0.000000  0.000000  13.845679  13.816230  13.322442   \n",
       "4023997  14.146443  0.000000  0.000000  13.994447  13.984568  13.530339   \n",
       "4023998  14.354524  0.000000  0.000000  14.225302  14.286920  13.157774   \n",
       "4023999  14.032889  0.000000  0.000000  13.391728  13.497197  12.981979   \n",
       "\n",
       "            pred_6     pred_7     pred_8     pred_9    pred_10    pred_11  \\\n",
       "0         6.254150   6.245424   6.247398   6.248691   6.234512   6.244083   \n",
       "1         5.981585   5.977894   5.978619   5.979913   5.982571   5.995547   \n",
       "2         7.165225   7.141719   7.146804   7.142194   7.149453   7.138753   \n",
       "3         7.737912   7.702444   7.704516   7.705604   7.772260   7.740436   \n",
       "4         9.219219   9.219450   9.212603   9.214954   9.230925   9.249313   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "4023995  14.155994  13.728745  14.426674  28.574068  14.213044  14.063761   \n",
       "4023996  14.111152  14.042326  14.669333  29.799187  14.399313  13.898353   \n",
       "4023997  14.174723  14.331810  15.028529  30.255470  14.419702  14.630459   \n",
       "4023998  14.750629  14.073773  14.739818  30.044895  14.306656  14.117593   \n",
       "4023999  14.135050   8.081411   8.534279  13.451024  14.110665  14.731728   \n",
       "\n",
       "           pred_12    pred_13    pred_14  \n",
       "0         6.239510   6.234668   6.242348  \n",
       "1         5.973396   5.970536   5.979932  \n",
       "2         7.121976   7.120587   7.118664  \n",
       "3         7.688272   7.684845   7.707492  \n",
       "4         9.231130   9.221489   9.240027  \n",
       "...            ...        ...        ...  \n",
       "4023995  13.676671  14.365964  14.153107  \n",
       "4023996  14.014549  14.781502  14.449735  \n",
       "4023997  14.213983  14.877322  14.795870  \n",
       "4023998  14.409499  15.085758  14.273345  \n",
       "4023999  14.567464  15.171421  14.395846  \n",
       "\n",
       "[4024000 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs.columns = [f\"pred_{i}\" for i in range(len(subs.columns))]\n",
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_paths = [Path('/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_stacking_pickle/oof_lb1147.npy')]\n",
    "sub_paths = [Path('/home/knikaido/work/Ventilator-Pressure-Prediction/data/team_stacking_pickle/sub_stacking_cv0.11594.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_team_preds(paths):\n",
    "    oofs = []\n",
    "    for path in paths:\n",
    "        path = str(path)\n",
    "        if '.csv' in path:\n",
    "            try:\n",
    "                oof_ = pd.read_csv(path, usecols=['pressure']).values.reshape(-1)\n",
    "\n",
    "            except:\n",
    "                oof_ = pd.read_csv(path, usecols=['pred']).values.reshape(-1)\n",
    "                print(type(oof_))\n",
    "        else:\n",
    "            try:\n",
    "                oof_ = np.load(path)\n",
    "            except:\n",
    "                oof_ = np.load(path).reshape(-1)\n",
    "#         print(f'loaded {path}')\n",
    "\n",
    "        oofs.append(oof_)\n",
    "    print('preparation done!')\n",
    "    oofs = np.array(oofs)\n",
    "    return oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparation done!\n",
      "preparation done!\n"
     ]
    }
   ],
   "source": [
    "oof_ = read_team_preds(oof_paths)\n",
    "sub_ = read_team_preds(sub_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs['pred_15'] = oof_[0]\n",
    "subs['pred_15'] = sub_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_features(input_df, dataType = 'train'):\n",
    "    colum = ['time_step', 'u_in', 'R', 'C']\n",
    "\n",
    "    return input_df[colum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_features(input_df, dataType = 'train'):\n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    colum = ['R_C']\n",
    "    rc_map = {'5_10': 0, '5_20': 1, '5_50': 2, '20_10': 3, '20_20': 4, '20_50': 5, '50_10': 6, '50_20': 7, '50_50': 8}\n",
    "    \n",
    "    output_df['R_C'] = [f'{r}_{c}' for r, c in zip(output_df['R'], output_df['C'])]\n",
    "    output_df['R_C'] = output_df['R_C'].map(rc_map)\n",
    "\n",
    "    return output_df[colum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_calc_features(input_df, dataType = 'train'):\n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    output_df['time_delta'] = output_df.groupby('breath_id')['time_step'].diff().fillna(0)\n",
    "    output_df['delta'] = output_df['time_delta'] * output_df['u_in']\n",
    "    output_df['area'] = output_df.groupby('breath_id')['delta'].cumsum()\n",
    "\n",
    "    output_df['cross']= output_df['u_in']*output_df['u_out']\n",
    "    output_df['cross2']= output_df['time_step']*output_df['u_out']\n",
    "    \n",
    "    output_df['u_in_cumsum'] = (output_df['u_in']).groupby(output_df['breath_id']).cumsum()\n",
    "    output_df['one'] = 1\n",
    "    output_df['count'] = (output_df['one']).groupby(output_df['breath_id']).cumsum()\n",
    "    output_df['u_in_cummean'] =output_df['u_in_cumsum'] / output_df['count']\n",
    "    \n",
    "    output_df['u_in_sqrt'] = output_df['u_in'].apply(lambda x: np.sqrt(x))\n",
    "    output_df['u_in_sqrt_cumsum'] = output_df.groupby('breath_id')['u_in_sqrt'].cumsum()\n",
    "    \n",
    "    output_df = output_df.drop(['count','one'], axis=1)\n",
    "    \n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'u_in': [np.max, np.mean],\n",
    "    }\n",
    "    \n",
    "    def get_agg_window(start_time=0, end_time=3.0, add_suffix = False):\n",
    "        \n",
    "        df_tgt = output_df[(output_df['time_step'] >= start_time) & (output_df['time_step'] <= end_time)]\n",
    "        df_feature = df_tgt.groupby(['breath_id']).agg(create_feature_dict)\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        \n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(start_time) + '_' + str(end_time))\n",
    "            \n",
    "        return df_feature\n",
    "    \n",
    "    df_agg_feature = get_agg_window().reset_index()\n",
    "    \n",
    "#     df_tmp = get_agg_window(start_time = 2, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(start_time = 1, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(end_time = 1, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "#     df_tmp = get_agg_window(end_time = 2, add_suffix = True).reset_index()\n",
    "#     df_agg_feature = df_agg_feature.merge(df_tmp, how = 'left', on = 'breath_id')\n",
    "\n",
    "    output_df = pd.merge(output_df, df_agg_feature, how='left', on='breath_id')\n",
    "    \n",
    "    output_df['u_in_diffmax'] = output_df['u_in_amax'] - output_df['u_in']\n",
    "    output_df['u_in_diffmean'] = output_df['u_in_mean'] - output_df['u_in']\n",
    "    \n",
    "#     output_df = output_df.drop(['u_in_amax','u_in_mean'], axis=1)\n",
    "    \n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_half_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    output_df['tmp'] = output_df['u_out']*(-1)+1 # inversion of u_out\n",
    "    output_df['u_in_half'] = output_df['tmp'] * output_df['u_in']\n",
    "    \n",
    "#     u_in_half_max_dict = train.groupby('breath_id')['u_in_half'].max().to_dict()\n",
    "#     train['u_in_half_max'] = train['breath_id'].map(u_in_half_max_dict)\n",
    "#     u_in_half_min_dict = train.groupby('breath_id')['u_in_half'].min().to_dict()\n",
    "#     train['u_in_half_min'] = train['breath_id'].map(u_in_half_min_dict)\n",
    "    u_in_half_mean_dict = output_df.groupby('breath_id')['u_in_half'].mean().to_dict()\n",
    "    output_df['u_in_half_mean'] = output_df['breath_id'].map(u_in_half_mean_dict)\n",
    "#     u_in_half_std_dict = train.groupby('breath_id')['u_in_half'].std().to_dict()\n",
    "#     train['u_in_half_std'] = train['breath_id'].map(u_in_half_std_dict)\n",
    "\n",
    "    del output_df['u_in_half'], output_df['tmp']\n",
    "    return output_df.iloc[:, c_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass_filter(series, b, a):\n",
    "    return signal.filtfilt(b, a, series)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    fp = 5 # 通過域端周波数[Hz]\n",
    "    fs = 10 # 阻止域端周波数[Hz]\n",
    "    gpass = 3 # 通過域端最大損失[dB]\n",
    "    gstop = 40 # 阻止域端最小損失[dB]\n",
    "    samplerate = 100\n",
    "\n",
    "    fn = samplerate / 2   #ナイキスト周波数\n",
    "    wp = fp / fn  #ナイキスト周波数で通過域端周波数を正規化\n",
    "    ws = fs / fn  #ナイキスト周波数で阻止域端周波数を正規化\n",
    "    N, Wn = signal.buttord(wp, ws, gpass, gstop)  #オーダーとバターワースの正規化周波数を計算\n",
    "    b, a = signal.butter(N, Wn, \"low\")            #フィルタ伝達関数の分子と分母を計算\n",
    "    \n",
    "    def get_agg_window(start_time=0, end_time=3.0, add_suffix = False):\n",
    "        \n",
    "        df_tgt = output_df[(output_df['time_step'] >= start_time) & (output_df['time_step'] <= end_time)]\n",
    "        df_feature = df_tgt.groupby(['breath_id'])['u_in'].apply(lowpass_filter, b=b, a=a)\n",
    "        df_feature.name = 'u_in_filter'\n",
    "                    \n",
    "        return df_feature\n",
    "    \n",
    "    df_agg_feature = get_agg_window().reset_index()\n",
    "    df_agg_feature = df_agg_feature.explode(\"u_in_filter\").reset_index(drop=True)\n",
    "    df_agg_feature['u_in_filter'] = df_agg_feature['u_in_filter'].astype(float)\n",
    "        \n",
    "    df_agg_feature['u_in_filter_cumsum'] = df_agg_feature.groupby('breath_id')['u_in_filter'].cumsum()\n",
    "\n",
    "    return df_agg_feature.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vib_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    output_df['u_out_diff'] = output_df['u_out'].diff()\n",
    "    output_df['u_out_diff'].fillna(0, inplace=True)\n",
    "    output_df['u_out_diff'].replace(-1, 0, inplace=True)\n",
    "    uout1_df = output_df[output_df['u_out_diff']==1]\n",
    "    \n",
    "    first_df = output_df.loc[0::80,:]\n",
    "    first_0_dict = dict(zip(first_df['id'], [0]*len(uout1_df)))\n",
    "\n",
    "    output_df['u_in_diff'] = output_df['u_in'].diff()\n",
    "    output_df['diff_sign'] = np.sign(output_df['u_in_diff'])\n",
    "    output_df['sign_diff'] = output_df['diff_sign'].diff()\n",
    "    output_df['tmp'] = output_df['id'].map(first_0_dict) # put 0, the 80row cycle\n",
    "    output_df.iloc[0::80, output_df.columns.get_loc('sign_diff')] = output_df.iloc[0::80, output_df.columns.get_loc('tmp')]\n",
    "\n",
    "    # Count the number of inversions, so take the absolute value and sum\n",
    "    output_df['sign_diff'] = abs(output_df['sign_diff']) \n",
    "    sign_diff_dict = output_df.groupby('breath_id')['sign_diff'].sum().to_dict()\n",
    "    output_df['diff_vib'] = output_df['breath_id'].map(sign_diff_dict)\n",
    "    \n",
    "    return output_df['sign_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(out_df, input_df, dataType = 'train'):\n",
    "\n",
    "    USE_LAG = [-2, -1, 1, 2, 3, 4]\n",
    "    lag_map = {-2: 1, -1: 2, 1: 3, 2: 4, 3: 5, 4: 6}\n",
    "\n",
    "    out_df['breath_id'] = input_df['breath_id']\n",
    "    \n",
    "    for lag in USE_LAG:\n",
    "        out_df[f'breath_id_lag{lag_map[lag]}']=out_df['breath_id'].shift(lag).fillna(0)\n",
    "        out_df[f'breath_id_lag{lag_map[lag]}same']=np.select([out_df[f'breath_id_lag{lag_map[lag]}']==out_df['breath_id']], [1], 0)\n",
    "\n",
    "        # u_in_filter\n",
    "        out_df[f'u_in_filter_lag_{lag_map[lag]}'] = out_df['u_in_filter'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "        out_df[f'u_in_filter_diff_{lag_map[lag]}'] = out_df['u_in_filter'] - out_df[f'u_in_filter_lag_{lag_map[lag]}']\n",
    "        # u_in_sqrt\n",
    "        out_df[f'u_in_sqrt_lag_{lag_map[lag]}'] = out_df['u_in_sqrt'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "        out_df[f'u_in_sqrt_diff_{lag_map[lag]}'] = out_df['u_in_sqrt'] - out_df[f'u_in_sqrt_lag_{lag_map[lag]}']\n",
    "\n",
    "        # u_in \n",
    "        out_df[f'u_in_lag_{lag_map[lag]}'] = out_df['u_in'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "        out_df[f'u_in_diff_{lag_map[lag]}'] = out_df['u_in'] - out_df[f'u_in_lag_{lag_map[lag]}']\n",
    "        # u_out\n",
    "        out_df[f'u_out_lag_{lag_map[lag]}'] = out_df['u_out'].shift(lag).fillna(0) * out_df[f'breath_id_lag{lag_map[lag]}same']\n",
    "\n",
    "        # breath_time\n",
    "    out_df[f'time_step_lag_{1}'] = out_df['time_step'].shift(1).fillna(0) * out_df[f'breath_id_lag{1}same']\n",
    "    out_df[f'time_step_diff_{1}'] = out_df['time_step'] - out_df[f'time_step_lag_{1}']\n",
    "        \n",
    "    drop_columns = ['breath_id', 'time_step_lag_1']\n",
    "    drop_columns += [f'breath_id_lag{lag_map[i]}' for i in USE_LAG]\n",
    "    drop_columns += [f'breath_id_lag{lag_map[i]}same' for i in USE_LAG]\n",
    "    out_df = out_df.drop(drop_columns, axis=1)\n",
    "    out_df = out_df.fillna(0)\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    output_df = copy.deepcopy(input_df)\n",
    "    c_num = input_df.shape[1]\n",
    "    \n",
    "    for i in range(len(pred_cols)):\n",
    "        output_df[f\"pred_{i}\"] = 0.\n",
    "        output_df.loc[oof[\"u_out\"] == 0, f\"pred_{i}\"] = _oof[f\"oof{i}\"].values\n",
    "    \n",
    "\n",
    "    \n",
    "    return output_df['sign_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_feature(input_df, dataType = 'train'):\n",
    "    \"\"\"input_df を特徴量行列に変換した新しいデータフレームを返す.\n",
    "    \"\"\"\n",
    "\n",
    "    processors = [\n",
    "        get_raw_features,\n",
    "        get_simple_calc_features,\n",
    "        get_agg_features,\n",
    "        get_vib_features,\n",
    "#         get_half_features,\n",
    "        get_category_features,\n",
    "        get_filter_features,\n",
    "    ]\n",
    "\n",
    "    out_df = pd.DataFrame()\n",
    "\n",
    "    for func in tqdm(processors, total=len(processors)):\n",
    "        with Timer(prefix='' + func.__name__ + ' '):\n",
    "            _df = func(input_df, dataType)\n",
    "\n",
    "        # 長さが等しいことをチェック (ずれている場合, func の実装がおかしい)\n",
    "        assert len(_df) == len(input_df), func.__name__\n",
    "        out_df = pd.concat([out_df, _df], axis=1)\n",
    "#     out_df = utils.reduce_mem_usage(out_df)\n",
    "#     out_df = add_time_features(out_df, input_df)\n",
    "    out_df_cols = sorted(list(out_df))\n",
    "    out_df = out_df[out_df_cols]\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_raw_features  0.031[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:15<00:31,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_simple_calc_features  15.640[s]\n",
      "get_agg_features  1.027[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:17<00:15,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_vib_features  0.495[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:17<00:07,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_category_features  2.270[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:20<00:03,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_filter_features  10.889[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:31<00:00,  5.32s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_raw_features  0.018[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:10<00:21,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_simple_calc_features  10.567[s]\n",
      "get_agg_features  0.612[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:11<00:10,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_vib_features  0.314[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:12<00:04,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_category_features  1.486[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:13<00:02,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_filter_features  7.250[s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:21<00:00,  3.55s/it]\n"
     ]
    }
   ],
   "source": [
    "train_df = to_feature(train, dataType = 'train')\n",
    "test_df = to_feature(test, dataType = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = [f\"pred_{i}\" for i in range(len(oofs.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_oof_features(input_df, dataType = 'train'):\n",
    "    \n",
    "    if dataType == 'train':\n",
    "        for i in range(len(pred_cols)):\n",
    "            input_df[f\"pred_{i}\"] = 0.\n",
    "            input_df.loc[train[\"u_out\"] == 0, f\"pred_{i}\"] = oofs[f\"pred_{i}\"].values\n",
    "        input_df['breath_id'] = train['breath_id']\n",
    "        input_df = train_df.loc[train[\"u_out\"] == 0].reset_index(drop=True)\n",
    "    else:\n",
    "        for i in range(len(pred_cols)):\n",
    "            input_df[f\"pred_{i}\"] = 0.\n",
    "            input_df.loc[:, f\"pred_{i}\"] = subs[f\"pred_{i}\"].values\n",
    "        input_df['breath_id'] = test['breath_id']\n",
    "        input_df = input_df.loc[test[\"u_out\"] == 0].reset_index(drop=True)\n",
    "      \n",
    "    # v2\n",
    "    input_df[\"pred_mean\"] = np.mean(input_df[pred_cols].values, axis=1)\n",
    "    input_df[\"pred_median\"] = np.median(input_df[pred_cols].values, axis=1)\n",
    "\n",
    "    input_df[\"pred_std\"] = input_df[pred_cols].std(axis=1)\n",
    "    input_df[\"pred_max\"] = input_df[pred_cols].values.max(axis=1)\n",
    "    input_df[\"pred_min\"] = input_df[pred_cols].values.min(axis=1)\n",
    "    input_df[\"pred_max-min\"] = input_df[\"pred_max\"] - input_df[\"pred_min\"]\n",
    "    input_df[\"pred_max-median\"] = input_df[\"pred_max\"] - input_df[\"pred_median\"]\n",
    "    input_df[\"pred_max-mean\"] = input_df[\"pred_max\"] - input_df[\"pred_mean\"]\n",
    "    input_df[\"pred_median-min\"] = input_df[\"pred_median\"] - input_df[\"pred_min\"]\n",
    "    input_df[\"pred_mean-min\"] = input_df[\"pred_mean\"] - input_df[\"pred_min\"]\n",
    "    input_df[\"pred_mean-median\"] = input_df[\"pred_mean\"] - input_df[\"pred_median\"]\n",
    "    input_df[\"pred_kurt\"] = input_df[pred_cols].kurt(axis=1)\n",
    "    for col_ in pred_cols:\n",
    "        input_df[f\"{col_}_past_1\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(1)\n",
    "        input_df[f\"{col_}_past_2\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(2)\n",
    "        input_df[f\"{col_}_past_3\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(3)\n",
    "        input_df[f\"{col_}_past_4\"] = input_df.groupby(\"breath_id\")[f\"{col_}\"].shift(4)\n",
    "\n",
    "        input_df[f\"{col_}_diff_1\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_1\"]\n",
    "        input_df[f\"{col_}_diff_2\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_2\"]\n",
    "        input_df[f\"{col_}_diff_3\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_3\"]\n",
    "        input_df[f\"{col_}_diff_4\"] = input_df[f\"{col_}\"] - input_df[f\"{col_}_past_4\"]\n",
    "\n",
    "    input_df[\"u_in_past_1\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(1)\n",
    "    input_df[\"u_in_past_2\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(2)\n",
    "    input_df[\"u_in_past_3\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(3)\n",
    "    input_df[\"u_in_past_4\"] = input_df.groupby(\"breath_id\")[\"u_in\"].shift(4)\n",
    "\n",
    "    input_df[\"u_in_diff_1\"] = input_df[\"u_in\"] - input_df[\"u_in_past_1\"]\n",
    "    input_df[\"u_in_diff_2\"] = input_df[\"u_in\"] - input_df[\"u_in_past_2\"]\n",
    "    input_df[\"u_in_diff_3\"] = input_df[\"u_in\"] - input_df[\"u_in_past_3\"]\n",
    "    input_df[\"u_in_diff_4\"] = input_df[\"u_in\"] - input_df[\"u_in_past_4\"]\n",
    "\n",
    "    input_df[\"u_in_cumsum\"] = input_df.groupby(\"breath_id\")[\"u_in\"].cumsum()\n",
    "\n",
    "    del input_df['breath_id']\n",
    "    \n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_oof_features(train_df, dataType = 'train')\n",
    "test_df = add_oof_features(test_df, dataType = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>R</th>\n",
       "      <th>R_C</th>\n",
       "      <th>area</th>\n",
       "      <th>cross</th>\n",
       "      <th>cross2</th>\n",
       "      <th>delta</th>\n",
       "      <th>sign_diff</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>time_step</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_15_diff_3</th>\n",
       "      <th>pred_15_diff_4</th>\n",
       "      <th>u_in_past_1</th>\n",
       "      <th>u_in_past_2</th>\n",
       "      <th>u_in_past_3</th>\n",
       "      <th>u_in_past_4</th>\n",
       "      <th>u_in_diff_1</th>\n",
       "      <th>u_in_diff_2</th>\n",
       "      <th>u_in_diff_3</th>\n",
       "      <th>u_in_diff_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.618632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.299707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1.380843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033862</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.126236</td>\n",
       "      <td>22.425944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2.156978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034028</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>...</td>\n",
       "      <td>6.248865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.299544</td>\n",
       "      <td>4.425781</td>\n",
       "      <td>22.725488</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>3.024485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034213</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>...</td>\n",
       "      <td>6.655945</td>\n",
       "      <td>6.728749</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>2.547028</td>\n",
       "      <td>2.846573</td>\n",
       "      <td>6.972809</td>\n",
       "      <td>25.272516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290963</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>7.762919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062477</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.033421</td>\n",
       "      <td>0.834147</td>\n",
       "      <td>...</td>\n",
       "      <td>1.673309</td>\n",
       "      <td>1.052967</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>2.438287</td>\n",
       "      <td>3.783043</td>\n",
       "      <td>3.209590</td>\n",
       "      <td>-0.780965</td>\n",
       "      <td>-0.568920</td>\n",
       "      <td>-1.913676</td>\n",
       "      <td>-1.340223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290964</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>7.834934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.033427</td>\n",
       "      <td>0.867574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079825</td>\n",
       "      <td>1.331771</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>2.438287</td>\n",
       "      <td>3.783043</td>\n",
       "      <td>0.285047</td>\n",
       "      <td>-0.495918</td>\n",
       "      <td>-0.283873</td>\n",
       "      <td>-1.628629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290965</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>7.878428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043494</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.033343</td>\n",
       "      <td>0.900917</td>\n",
       "      <td>...</td>\n",
       "      <td>1.112608</td>\n",
       "      <td>0.842314</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>2.438287</td>\n",
       "      <td>-0.849980</td>\n",
       "      <td>-0.564933</td>\n",
       "      <td>-1.345899</td>\n",
       "      <td>-1.133853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290966</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>7.936323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.033391</td>\n",
       "      <td>0.934309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070026</td>\n",
       "      <td>0.621632</td>\n",
       "      <td>1.304434</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>2.650333</td>\n",
       "      <td>0.429396</td>\n",
       "      <td>-0.420585</td>\n",
       "      <td>-0.135538</td>\n",
       "      <td>-0.916503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290967</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>7.968377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032054</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.033434</td>\n",
       "      <td>0.967743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951469</td>\n",
       "      <td>0.609930</td>\n",
       "      <td>1.733830</td>\n",
       "      <td>1.304434</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>-0.775103</td>\n",
       "      <td>-0.345708</td>\n",
       "      <td>-1.195688</td>\n",
       "      <td>-0.910641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2290968 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C   R  R_C      area  cross  cross2     delta  sign_diff  \\\n",
       "0        50  20    5  0.000000    0.0     0.0  0.000000        0.0   \n",
       "1        50  20    5  0.618632    0.0     0.0  0.618632        NaN   \n",
       "2        50  20    5  1.380843    0.0     0.0  0.762212        0.0   \n",
       "3        50  20    5  2.156978    0.0     0.0  0.776134        0.0   \n",
       "4        50  20    5  3.024485    0.0     0.0  0.867507        0.0   \n",
       "...      ..  ..  ...       ...    ...     ...       ...        ...   \n",
       "2290963  10  50    6  7.762919    0.0     0.0  0.062477        2.0   \n",
       "2290964  10  50    6  7.834934    0.0     0.0  0.072015        2.0   \n",
       "2290965  10  50    6  7.878428    0.0     0.0  0.043494        2.0   \n",
       "2290966  10  50    6  7.936323    0.0     0.0  0.057895        2.0   \n",
       "2290967  10  50    6  7.968377    0.0     0.0  0.032054        2.0   \n",
       "\n",
       "         time_delta  time_step  ...  pred_15_diff_3  pred_15_diff_4  \\\n",
       "0          0.000000   0.000000  ...             NaN             NaN   \n",
       "1          0.033652   0.033652  ...             NaN             NaN   \n",
       "2          0.033862   0.067514  ...             NaN             NaN   \n",
       "3          0.034028   0.101542  ...        6.248865             NaN   \n",
       "4          0.034213   0.135756  ...        6.655945        6.728749   \n",
       "...             ...        ...  ...             ...             ...   \n",
       "2290963    0.033421   0.834147  ...        1.673309        1.052967   \n",
       "2290964    0.033427   0.867574  ...        0.079825        1.331771   \n",
       "2290965    0.033343   0.900917  ...        1.112608        0.842314   \n",
       "2290966    0.033391   0.934309  ...       -0.070026        0.621632   \n",
       "2290967    0.033434   0.967743  ...        0.951469        0.609930   \n",
       "\n",
       "         u_in_past_1  u_in_past_2  u_in_past_3  u_in_past_4  u_in_diff_1  \\\n",
       "0                NaN          NaN          NaN          NaN          NaN   \n",
       "1           0.083334          NaN          NaN          NaN    18.299707   \n",
       "2          18.383041     0.083334          NaN          NaN     4.126236   \n",
       "3          22.509278    18.383041     0.083334          NaN     0.299544   \n",
       "4          22.808822    22.509278    18.383041     0.083334     2.547028   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "2290963     2.650333     2.438287     3.783043     3.209590    -0.780965   \n",
       "2290964     1.869367     2.650333     2.438287     3.783043     0.285047   \n",
       "2290965     2.154414     1.869367     2.650333     2.438287    -0.849980   \n",
       "2290966     1.304434     2.154414     1.869367     2.650333     0.429396   \n",
       "2290967     1.733830     1.304434     2.154414     1.869367    -0.775103   \n",
       "\n",
       "         u_in_diff_2  u_in_diff_3  u_in_diff_4  \n",
       "0                NaN          NaN          NaN  \n",
       "1                NaN          NaN          NaN  \n",
       "2          22.425944          NaN          NaN  \n",
       "3           4.425781    22.725488          NaN  \n",
       "4           2.846573     6.972809    25.272516  \n",
       "...              ...          ...          ...  \n",
       "2290963    -0.568920    -1.913676    -1.340223  \n",
       "2290964    -0.495918    -0.283873    -1.628629  \n",
       "2290965    -0.564933    -1.345899    -1.133853  \n",
       "2290966    -0.420585    -0.135538    -0.916503  \n",
       "2290967    -0.345708    -1.195688    -0.910641  \n",
       "\n",
       "[2290968 rows x 185 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>R</th>\n",
       "      <th>R_C</th>\n",
       "      <th>area</th>\n",
       "      <th>cross</th>\n",
       "      <th>cross2</th>\n",
       "      <th>delta</th>\n",
       "      <th>sign_diff</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>time_step</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_15_diff_3</th>\n",
       "      <th>pred_15_diff_4</th>\n",
       "      <th>u_in_past_1</th>\n",
       "      <th>u_in_past_2</th>\n",
       "      <th>u_in_past_3</th>\n",
       "      <th>u_in_past_4</th>\n",
       "      <th>u_in_diff_1</th>\n",
       "      <th>u_in_diff_2</th>\n",
       "      <th>u_in_diff_3</th>\n",
       "      <th>u_in_diff_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.239758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.136630</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.385252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>...</td>\n",
       "      <td>1.476345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.578935</td>\n",
       "      <td>13.715564</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.224695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.839442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>...</td>\n",
       "      <td>3.233899</td>\n",
       "      <td>2.952690</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.090346</td>\n",
       "      <td>11.669281</td>\n",
       "      <td>18.805911</td>\n",
       "      <td>26.320956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527560</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1.969112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033553</td>\n",
       "      <td>0.842145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527561</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1.969112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033503</td>\n",
       "      <td>0.875648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070302</td>\n",
       "      <td>-0.070302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527562</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1.973183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033537</td>\n",
       "      <td>0.909185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140604</td>\n",
       "      <td>-0.140604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.121375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527563</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1.973183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.033962</td>\n",
       "      <td>0.943148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070302</td>\n",
       "      <td>-0.070302</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527564</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1.973183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033667</td>\n",
       "      <td>0.976815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.070302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.121375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527565 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C   R  R_C      area  cross  cross2     delta  sign_diff  \\\n",
       "0        20   5    1  0.000000    0.0     0.0  0.000000        0.0   \n",
       "1        20   5    1  0.239758    0.0     0.0  0.239758        NaN   \n",
       "2        20   5    1  0.707491    0.0     0.0  0.467733        0.0   \n",
       "3        20   5    1  1.385252    0.0     0.0  0.677761        0.0   \n",
       "4        20   5    1  2.224695    0.0     0.0  0.839442        0.0   \n",
       "...      ..  ..  ...       ...    ...     ...       ...        ...   \n",
       "1527560  10  20    3  1.969112    0.0     0.0  0.000000        0.0   \n",
       "1527561  10  20    3  1.969112    0.0     0.0  0.000000        0.0   \n",
       "1527562  10  20    3  1.973183    0.0     0.0  0.004071        1.0   \n",
       "1527563  10  20    3  1.973183    0.0     0.0  0.000000        2.0   \n",
       "1527564  10  20    3  1.973183    0.0     0.0  0.000000        1.0   \n",
       "\n",
       "         time_delta  time_step  ...  pred_15_diff_3  pred_15_diff_4  \\\n",
       "0          0.000000   0.000000  ...             NaN             NaN   \n",
       "1          0.031904   0.031904  ...             NaN             NaN   \n",
       "2          0.031924   0.063827  ...             NaN             NaN   \n",
       "3          0.031924   0.095751  ...        1.476345             NaN   \n",
       "4          0.031893   0.127644  ...        3.233899        2.952690   \n",
       "...             ...        ...  ...             ...             ...   \n",
       "1527560    0.033553   0.842145  ...        0.000000        0.070302   \n",
       "1527561    0.033503   0.875648  ...       -0.070302       -0.070302   \n",
       "1527562    0.033537   0.909185  ...       -0.140604       -0.140604   \n",
       "1527563    0.033962   0.943148  ...       -0.070302       -0.070302   \n",
       "1527564    0.033667   0.976815  ...        0.000000       -0.070302   \n",
       "\n",
       "         u_in_past_1  u_in_past_2  u_in_past_3  u_in_past_4  u_in_diff_1  \\\n",
       "0                NaN          NaN          NaN          NaN          NaN   \n",
       "1           0.000000          NaN          NaN          NaN     7.515046   \n",
       "2           7.515046     0.000000          NaN          NaN     7.136630   \n",
       "3          14.651675     7.515046     0.000000          NaN     6.578935   \n",
       "4          21.230610    14.651675     7.515046          0.0     5.090346   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "1527560     0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "1527561     0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "1527562     0.000000     0.000000     0.000000          0.0     0.121375   \n",
       "1527563     0.121375     0.000000     0.000000          0.0    -0.121375   \n",
       "1527564     0.000000     0.121375     0.000000          0.0     0.000000   \n",
       "\n",
       "         u_in_diff_2  u_in_diff_3  u_in_diff_4  \n",
       "0                NaN          NaN          NaN  \n",
       "1                NaN          NaN          NaN  \n",
       "2          14.651675          NaN          NaN  \n",
       "3          13.715564    21.230610          NaN  \n",
       "4          11.669281    18.805911    26.320956  \n",
       "...              ...          ...          ...  \n",
       "1527560     0.000000     0.000000     0.000000  \n",
       "1527561     0.000000     0.000000     0.000000  \n",
       "1527562     0.121375     0.121375     0.121375  \n",
       "1527563     0.000000     0.000000     0.000000  \n",
       "1527564    -0.121375     0.000000     0.000000  \n",
       "\n",
       "[1527565 rows x 185 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train_df), display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_category_col = ['R_C']\n",
    "train_value_col = [i for i in train_df.columns.to_list() if i not in train_category_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_features = train_value_col\n",
    "# train_df = train_df.fillna(0)\n",
    "# test_df = test_df.fillna(0)\n",
    "# scaler = RobustScaler()\n",
    "# scaler.fit(train_df[norm_features])\n",
    "# train_df[norm_features] = scaler.transform(train_df[norm_features].values)\n",
    "# test_df[norm_features] = scaler.transform(test_df[norm_features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.loc[train[\"u_out\"] == 0]['pressure'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train.loc[train[\"u_out\"] == 0, ['id', 'breath_id', 'pressure']].reset_index(drop=True)], axis=1)\n",
    "test_df = pd.concat([test_df, test.loc[test[\"u_out\"] == 0,['id', 'breath_id']].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.056333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 358011\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061893, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.133398\tvalid_1's l1: 0.13227\n",
      "[200]\ttraining's l1: 0.125604\tvalid_1's l1: 0.124415\n",
      "[300]\ttraining's l1: 0.122893\tvalid_1's l1: 0.121816\n",
      "[400]\ttraining's l1: 0.121799\tvalid_1's l1: 0.120997\n",
      "[500]\ttraining's l1: 0.12052\tvalid_1's l1: 0.120283\n",
      "[600]\ttraining's l1: 0.119691\tvalid_1's l1: 0.119627\n",
      "[700]\ttraining's l1: 0.119183\tvalid_1's l1: 0.119386\n",
      "[800]\ttraining's l1: 0.118797\tvalid_1's l1: 0.119102\n",
      "[900]\ttraining's l1: 0.118428\tvalid_1's l1: 0.118911\n",
      "[1000]\ttraining's l1: 0.118091\tvalid_1's l1: 0.118772\n",
      "[1100]\ttraining's l1: 0.117622\tvalid_1's l1: 0.118728\n",
      "[1200]\ttraining's l1: 0.117466\tvalid_1's l1: 0.118704\n",
      "[1300]\ttraining's l1: 0.117341\tvalid_1's l1: 0.118708\n",
      "[1400]\ttraining's l1: 0.117188\tvalid_1's l1: 0.118661\n",
      "[1500]\ttraining's l1: 0.117078\tvalid_1's l1: 0.118618\n",
      "[1600]\ttraining's l1: 0.116919\tvalid_1's l1: 0.118582\n",
      "[1700]\ttraining's l1: 0.116755\tvalid_1's l1: 0.118556\n",
      "[1800]\ttraining's l1: 0.11669\tvalid_1's l1: 0.11855\n",
      "[1900]\ttraining's l1: 0.116614\tvalid_1's l1: 0.118516\n",
      "[2000]\ttraining's l1: 0.11653\tvalid_1's l1: 0.11851\n",
      "[2100]\ttraining's l1: 0.116429\tvalid_1's l1: 0.118487\n",
      "[2200]\ttraining's l1: 0.116358\tvalid_1's l1: 0.118472\n",
      "[2300]\ttraining's l1: 0.116283\tvalid_1's l1: 0.118456\n",
      "[2400]\ttraining's l1: 0.116179\tvalid_1's l1: 0.118386\n",
      "[2500]\ttraining's l1: 0.116107\tvalid_1's l1: 0.118373\n",
      "[2600]\ttraining's l1: 0.11603\tvalid_1's l1: 0.118357\n",
      "[2700]\ttraining's l1: 0.115961\tvalid_1's l1: 0.118308\n",
      "[2800]\ttraining's l1: 0.115886\tvalid_1's l1: 0.118274\n",
      "[2900]\ttraining's l1: 0.115833\tvalid_1's l1: 0.118278\n",
      "[3000]\ttraining's l1: 0.115763\tvalid_1's l1: 0.118244\n",
      "[3100]\ttraining's l1: 0.115696\tvalid_1's l1: 0.118246\n",
      "[3200]\ttraining's l1: 0.115625\tvalid_1's l1: 0.118219\n",
      "[3300]\ttraining's l1: 0.115553\tvalid_1's l1: 0.118201\n",
      "[3400]\ttraining's l1: 0.115523\tvalid_1's l1: 0.118196\n",
      "[3500]\ttraining's l1: 0.115498\tvalid_1's l1: 0.118193\n",
      "[3600]\ttraining's l1: 0.115474\tvalid_1's l1: 0.118194\n",
      "Early stopping, best iteration is:\n",
      "[3462]\ttraining's l1: 0.115508\tvalid_1's l1: 0.118189\n",
      "fold = 0, score = 0.11818915489775957\n",
      "Fold-1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.100753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 358011\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061993, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.132368\tvalid_1's l1: 0.133309\n",
      "[200]\ttraining's l1: 0.125164\tvalid_1's l1: 0.126641\n",
      "[300]\ttraining's l1: 0.12241\tvalid_1's l1: 0.124231\n",
      "[400]\ttraining's l1: 0.121098\tvalid_1's l1: 0.123266\n",
      "[500]\ttraining's l1: 0.120014\tvalid_1's l1: 0.122552\n",
      "[600]\ttraining's l1: 0.119212\tvalid_1's l1: 0.122245\n",
      "[700]\ttraining's l1: 0.118767\tvalid_1's l1: 0.122013\n",
      "[800]\ttraining's l1: 0.118427\tvalid_1's l1: 0.121797\n",
      "[900]\ttraining's l1: 0.118053\tvalid_1's l1: 0.121754\n",
      "[1000]\ttraining's l1: 0.117707\tvalid_1's l1: 0.121624\n",
      "[1100]\ttraining's l1: 0.117397\tvalid_1's l1: 0.121537\n",
      "[1200]\ttraining's l1: 0.117175\tvalid_1's l1: 0.121462\n",
      "[1300]\ttraining's l1: 0.11692\tvalid_1's l1: 0.121433\n",
      "[1400]\ttraining's l1: 0.116666\tvalid_1's l1: 0.121475\n",
      "Early stopping, best iteration is:\n",
      "[1280]\ttraining's l1: 0.116966\tvalid_1's l1: 0.12141\n",
      "fold = 1, score = 0.12140959743811415\n",
      "Fold-2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.059353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 358011\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061937, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.13191\tvalid_1's l1: 0.129065\n",
      "[200]\ttraining's l1: 0.12546\tvalid_1's l1: 0.123109\n",
      "[300]\ttraining's l1: 0.122672\tvalid_1's l1: 0.120898\n",
      "[400]\ttraining's l1: 0.121685\tvalid_1's l1: 0.120179\n",
      "[500]\ttraining's l1: 0.120763\tvalid_1's l1: 0.119515\n",
      "[600]\ttraining's l1: 0.120061\tvalid_1's l1: 0.119214\n",
      "[700]\ttraining's l1: 0.119466\tvalid_1's l1: 0.119002\n",
      "[800]\ttraining's l1: 0.119196\tvalid_1's l1: 0.118853\n",
      "[900]\ttraining's l1: 0.11886\tvalid_1's l1: 0.118752\n",
      "[1000]\ttraining's l1: 0.11858\tvalid_1's l1: 0.118652\n",
      "[1100]\ttraining's l1: 0.118348\tvalid_1's l1: 0.118527\n",
      "[1200]\ttraining's l1: 0.11815\tvalid_1's l1: 0.118461\n",
      "[1300]\ttraining's l1: 0.117906\tvalid_1's l1: 0.118442\n",
      "[1400]\ttraining's l1: 0.117732\tvalid_1's l1: 0.118411\n",
      "[1500]\ttraining's l1: 0.117614\tvalid_1's l1: 0.118351\n",
      "[1600]\ttraining's l1: 0.117515\tvalid_1's l1: 0.118305\n",
      "[1700]\ttraining's l1: 0.117414\tvalid_1's l1: 0.118266\n",
      "[1800]\ttraining's l1: 0.117317\tvalid_1's l1: 0.118224\n",
      "[1900]\ttraining's l1: 0.117219\tvalid_1's l1: 0.118183\n",
      "[2000]\ttraining's l1: 0.117156\tvalid_1's l1: 0.118164\n",
      "[2100]\ttraining's l1: 0.117104\tvalid_1's l1: 0.118148\n",
      "[2200]\ttraining's l1: 0.117079\tvalid_1's l1: 0.118143\n",
      "[2300]\ttraining's l1: 0.117043\tvalid_1's l1: 0.118141\n",
      "[2400]\ttraining's l1: 0.116778\tvalid_1's l1: 0.118081\n",
      "[2500]\ttraining's l1: 0.116632\tvalid_1's l1: 0.118033\n",
      "[2600]\ttraining's l1: 0.116472\tvalid_1's l1: 0.118059\n",
      "[2700]\ttraining's l1: 0.116274\tvalid_1's l1: 0.118014\n",
      "[2800]\ttraining's l1: 0.116045\tvalid_1's l1: 0.117996\n",
      "[2900]\ttraining's l1: 0.115895\tvalid_1's l1: 0.117965\n",
      "[3000]\ttraining's l1: 0.115802\tvalid_1's l1: 0.117941\n",
      "[3100]\ttraining's l1: 0.115617\tvalid_1's l1: 0.117929\n",
      "[3200]\ttraining's l1: 0.115522\tvalid_1's l1: 0.117921\n",
      "[3300]\ttraining's l1: 0.115375\tvalid_1's l1: 0.117871\n",
      "[3400]\ttraining's l1: 0.115218\tvalid_1's l1: 0.117871\n",
      "[3500]\ttraining's l1: 0.115082\tvalid_1's l1: 0.117866\n",
      "[3600]\ttraining's l1: 0.114883\tvalid_1's l1: 0.117848\n",
      "[3700]\ttraining's l1: 0.114761\tvalid_1's l1: 0.117858\n",
      "[3800]\ttraining's l1: 0.114733\tvalid_1's l1: 0.117857\n",
      "Early stopping, best iteration is:\n",
      "[3600]\ttraining's l1: 0.114883\tvalid_1's l1: 0.117848\n",
      "fold = 2, score = 0.11784830251714147\n",
      "Fold-3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.080243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 358011\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061922, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.132441\tvalid_1's l1: 0.133152\n",
      "[200]\ttraining's l1: 0.125536\tvalid_1's l1: 0.126783\n",
      "[300]\ttraining's l1: 0.122826\tvalid_1's l1: 0.124208\n",
      "[400]\ttraining's l1: 0.121417\tvalid_1's l1: 0.123064\n",
      "[500]\ttraining's l1: 0.120373\tvalid_1's l1: 0.122344\n",
      "[600]\ttraining's l1: 0.119327\tvalid_1's l1: 0.1218\n",
      "[700]\ttraining's l1: 0.118909\tvalid_1's l1: 0.121604\n",
      "[800]\ttraining's l1: 0.118511\tvalid_1's l1: 0.121482\n",
      "[900]\ttraining's l1: 0.118171\tvalid_1's l1: 0.121397\n",
      "[1000]\ttraining's l1: 0.117871\tvalid_1's l1: 0.121324\n",
      "[1100]\ttraining's l1: 0.117654\tvalid_1's l1: 0.121255\n",
      "[1200]\ttraining's l1: 0.117457\tvalid_1's l1: 0.121236\n",
      "[1300]\ttraining's l1: 0.117165\tvalid_1's l1: 0.121113\n",
      "[1400]\ttraining's l1: 0.116982\tvalid_1's l1: 0.12105\n",
      "[1500]\ttraining's l1: 0.116764\tvalid_1's l1: 0.121046\n",
      "[1600]\ttraining's l1: 0.116678\tvalid_1's l1: 0.120986\n",
      "[1700]\ttraining's l1: 0.116593\tvalid_1's l1: 0.120945\n",
      "[1800]\ttraining's l1: 0.116452\tvalid_1's l1: 0.120888\n",
      "[1900]\ttraining's l1: 0.116274\tvalid_1's l1: 0.120798\n",
      "[2000]\ttraining's l1: 0.116189\tvalid_1's l1: 0.120757\n",
      "[2100]\ttraining's l1: 0.11603\tvalid_1's l1: 0.1207\n",
      "[2200]\ttraining's l1: 0.116007\tvalid_1's l1: 0.120695\n",
      "[2300]\ttraining's l1: 0.115975\tvalid_1's l1: 0.12071\n",
      "[2400]\ttraining's l1: 0.115946\tvalid_1's l1: 0.120706\n",
      "Early stopping, best iteration is:\n",
      "[2216]\ttraining's l1: 0.116006\tvalid_1's l1: 0.120695\n",
      "fold = 3, score = 0.12069453361454717\n",
      "Fold-4\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.991003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 358011\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061804, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.132521\tvalid_1's l1: 0.132646\n",
      "[200]\ttraining's l1: 0.125247\tvalid_1's l1: 0.125481\n",
      "[300]\ttraining's l1: 0.123077\tvalid_1's l1: 0.12356\n",
      "[400]\ttraining's l1: 0.121635\tvalid_1's l1: 0.122167\n",
      "[500]\ttraining's l1: 0.120632\tvalid_1's l1: 0.121372\n",
      "[600]\ttraining's l1: 0.119954\tvalid_1's l1: 0.12106\n",
      "[700]\ttraining's l1: 0.119461\tvalid_1's l1: 0.120769\n",
      "[800]\ttraining's l1: 0.118894\tvalid_1's l1: 0.120506\n",
      "[900]\ttraining's l1: 0.118376\tvalid_1's l1: 0.120276\n",
      "[1000]\ttraining's l1: 0.117946\tvalid_1's l1: 0.120135\n",
      "[1100]\ttraining's l1: 0.117388\tvalid_1's l1: 0.120085\n",
      "[1200]\ttraining's l1: 0.117195\tvalid_1's l1: 0.120011\n",
      "[1300]\ttraining's l1: 0.116961\tvalid_1's l1: 0.119976\n",
      "[1400]\ttraining's l1: 0.11665\tvalid_1's l1: 0.119884\n",
      "[1500]\ttraining's l1: 0.116434\tvalid_1's l1: 0.119833\n",
      "[1600]\ttraining's l1: 0.116289\tvalid_1's l1: 0.119805\n",
      "[1700]\ttraining's l1: 0.116132\tvalid_1's l1: 0.119736\n",
      "[1800]\ttraining's l1: 0.115871\tvalid_1's l1: 0.119654\n",
      "[1900]\ttraining's l1: 0.115681\tvalid_1's l1: 0.119625\n",
      "[2000]\ttraining's l1: 0.115539\tvalid_1's l1: 0.11957\n",
      "[2100]\ttraining's l1: 0.115362\tvalid_1's l1: 0.119549\n",
      "[2200]\ttraining's l1: 0.11523\tvalid_1's l1: 0.119559\n",
      "Early stopping, best iteration is:\n",
      "[2088]\ttraining's l1: 0.115391\tvalid_1's l1: 0.119538\n",
      "fold = 4, score = 0.11953846111044857\n",
      "Fold-5\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.011417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 358011\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061837, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.13177\tvalid_1's l1: 0.133481\n",
      "[200]\ttraining's l1: 0.125295\tvalid_1's l1: 0.126649\n",
      "[300]\ttraining's l1: 0.122709\tvalid_1's l1: 0.124151\n",
      "[400]\ttraining's l1: 0.121144\tvalid_1's l1: 0.123117\n",
      "[500]\ttraining's l1: 0.120066\tvalid_1's l1: 0.122329\n",
      "[600]\ttraining's l1: 0.119352\tvalid_1's l1: 0.121966\n",
      "[700]\ttraining's l1: 0.118869\tvalid_1's l1: 0.121724\n",
      "[800]\ttraining's l1: 0.118489\tvalid_1's l1: 0.121511\n",
      "[900]\ttraining's l1: 0.118185\tvalid_1's l1: 0.121405\n",
      "[1000]\ttraining's l1: 0.117905\tvalid_1's l1: 0.121236\n",
      "[1100]\ttraining's l1: 0.117637\tvalid_1's l1: 0.121119\n",
      "[1200]\ttraining's l1: 0.117335\tvalid_1's l1: 0.120976\n",
      "[1300]\ttraining's l1: 0.117105\tvalid_1's l1: 0.120906\n",
      "[1400]\ttraining's l1: 0.116917\tvalid_1's l1: 0.120813\n",
      "[1500]\ttraining's l1: 0.116699\tvalid_1's l1: 0.120775\n",
      "[1600]\ttraining's l1: 0.116455\tvalid_1's l1: 0.120729\n",
      "[1700]\ttraining's l1: 0.116296\tvalid_1's l1: 0.120679\n",
      "[1800]\ttraining's l1: 0.116097\tvalid_1's l1: 0.120687\n",
      "[1900]\ttraining's l1: 0.115924\tvalid_1's l1: 0.120684\n",
      "[2000]\ttraining's l1: 0.115713\tvalid_1's l1: 0.120661\n",
      "[2100]\ttraining's l1: 0.115526\tvalid_1's l1: 0.120652\n",
      "[2200]\ttraining's l1: 0.115365\tvalid_1's l1: 0.12065\n",
      "[2300]\ttraining's l1: 0.115188\tvalid_1's l1: 0.120651\n",
      "Early stopping, best iteration is:\n",
      "[2159]\ttraining's l1: 0.115426\tvalid_1's l1: 0.120629\n",
      "fold = 5, score = 0.12062886200832071\n",
      "Fold-6\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.023697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 358011\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061818, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.132175\tvalid_1's l1: 0.131099\n",
      "[200]\ttraining's l1: 0.125163\tvalid_1's l1: 0.125034\n",
      "[300]\ttraining's l1: 0.122544\tvalid_1's l1: 0.122759\n",
      "[400]\ttraining's l1: 0.120889\tvalid_1's l1: 0.121693\n",
      "[500]\ttraining's l1: 0.120112\tvalid_1's l1: 0.121075\n",
      "[600]\ttraining's l1: 0.119679\tvalid_1's l1: 0.120851\n",
      "[700]\ttraining's l1: 0.119147\tvalid_1's l1: 0.120632\n",
      "[800]\ttraining's l1: 0.118527\tvalid_1's l1: 0.120342\n",
      "[900]\ttraining's l1: 0.118092\tvalid_1's l1: 0.120218\n",
      "[1000]\ttraining's l1: 0.117736\tvalid_1's l1: 0.120103\n",
      "[1100]\ttraining's l1: 0.117329\tvalid_1's l1: 0.119868\n",
      "[1200]\ttraining's l1: 0.11708\tvalid_1's l1: 0.119796\n",
      "[1300]\ttraining's l1: 0.116878\tvalid_1's l1: 0.119732\n",
      "[1400]\ttraining's l1: 0.116773\tvalid_1's l1: 0.119696\n",
      "[1500]\ttraining's l1: 0.116661\tvalid_1's l1: 0.11966\n",
      "[1600]\ttraining's l1: 0.116566\tvalid_1's l1: 0.119625\n",
      "[1700]\ttraining's l1: 0.116517\tvalid_1's l1: 0.119614\n",
      "[1800]\ttraining's l1: 0.116467\tvalid_1's l1: 0.119605\n",
      "[1900]\ttraining's l1: 0.116416\tvalid_1's l1: 0.119587\n",
      "[2000]\ttraining's l1: 0.116366\tvalid_1's l1: 0.119582\n",
      "[2100]\ttraining's l1: 0.116206\tvalid_1's l1: 0.119565\n",
      "[2200]\ttraining's l1: 0.115967\tvalid_1's l1: 0.11955\n",
      "[2300]\ttraining's l1: 0.115872\tvalid_1's l1: 0.119553\n",
      "Early stopping, best iteration is:\n",
      "[2147]\ttraining's l1: 0.116055\tvalid_1's l1: 0.119539\n",
      "fold = 6, score = 0.11953861078185424\n",
      "Fold-7\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.004008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 358011\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061785, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.132174\tvalid_1's l1: 0.135146\n",
      "[200]\ttraining's l1: 0.126263\tvalid_1's l1: 0.129186\n",
      "[300]\ttraining's l1: 0.123205\tvalid_1's l1: 0.126276\n",
      "[400]\ttraining's l1: 0.121153\tvalid_1's l1: 0.124387\n",
      "[500]\ttraining's l1: 0.1201\tvalid_1's l1: 0.123672\n",
      "[600]\ttraining's l1: 0.11932\tvalid_1's l1: 0.123111\n",
      "[700]\ttraining's l1: 0.118794\tvalid_1's l1: 0.122888\n",
      "[800]\ttraining's l1: 0.118313\tvalid_1's l1: 0.122753\n",
      "[900]\ttraining's l1: 0.11781\tvalid_1's l1: 0.122612\n",
      "[1000]\ttraining's l1: 0.117455\tvalid_1's l1: 0.122577\n",
      "[1100]\ttraining's l1: 0.117179\tvalid_1's l1: 0.122463\n",
      "[1200]\ttraining's l1: 0.116929\tvalid_1's l1: 0.122441\n",
      "[1300]\ttraining's l1: 0.116768\tvalid_1's l1: 0.122401\n",
      "[1400]\ttraining's l1: 0.116639\tvalid_1's l1: 0.122384\n",
      "[1500]\ttraining's l1: 0.116478\tvalid_1's l1: 0.122324\n",
      "[1600]\ttraining's l1: 0.116405\tvalid_1's l1: 0.122298\n",
      "[1700]\ttraining's l1: 0.116297\tvalid_1's l1: 0.122274\n",
      "[1800]\ttraining's l1: 0.116233\tvalid_1's l1: 0.122245\n",
      "[1900]\ttraining's l1: 0.116201\tvalid_1's l1: 0.12224\n",
      "[2000]\ttraining's l1: 0.11615\tvalid_1's l1: 0.122231\n",
      "[2100]\ttraining's l1: 0.116107\tvalid_1's l1: 0.122209\n",
      "[2200]\ttraining's l1: 0.116082\tvalid_1's l1: 0.122202\n",
      "[2300]\ttraining's l1: 0.116059\tvalid_1's l1: 0.122205\n",
      "[2400]\ttraining's l1: 0.116045\tvalid_1's l1: 0.122194\n",
      "[2500]\ttraining's l1: 0.116038\tvalid_1's l1: 0.122194\n",
      "Early stopping, best iteration is:\n",
      "[2328]\ttraining's l1: 0.116051\tvalid_1's l1: 0.122191\n",
      "fold = 7, score = 0.12219063790727061\n",
      "Fold-8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.004047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 358011\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061827, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 15.890698\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.13131\tvalid_1's l1: 0.132795\n",
      "[200]\ttraining's l1: 0.125403\tvalid_1's l1: 0.126287\n",
      "[300]\ttraining's l1: 0.12297\tvalid_1's l1: 0.123985\n",
      "[400]\ttraining's l1: 0.121721\tvalid_1's l1: 0.123012\n",
      "[500]\ttraining's l1: 0.120839\tvalid_1's l1: 0.122346\n",
      "[600]\ttraining's l1: 0.120186\tvalid_1's l1: 0.121933\n",
      "[700]\ttraining's l1: 0.119579\tvalid_1's l1: 0.121542\n",
      "[800]\ttraining's l1: 0.119117\tvalid_1's l1: 0.121351\n",
      "[900]\ttraining's l1: 0.118746\tvalid_1's l1: 0.121252\n",
      "[1000]\ttraining's l1: 0.118398\tvalid_1's l1: 0.121108\n",
      "[1100]\ttraining's l1: 0.118069\tvalid_1's l1: 0.120976\n",
      "[1200]\ttraining's l1: 0.11756\tvalid_1's l1: 0.120839\n",
      "[1300]\ttraining's l1: 0.117267\tvalid_1's l1: 0.120772\n",
      "[1400]\ttraining's l1: 0.11703\tvalid_1's l1: 0.120643\n",
      "[1500]\ttraining's l1: 0.116812\tvalid_1's l1: 0.120555\n",
      "[1600]\ttraining's l1: 0.116567\tvalid_1's l1: 0.120484\n",
      "[1700]\ttraining's l1: 0.116305\tvalid_1's l1: 0.120501\n",
      "[1800]\ttraining's l1: 0.116145\tvalid_1's l1: 0.12044\n",
      "[1900]\ttraining's l1: 0.115975\tvalid_1's l1: 0.120394\n",
      "[2000]\ttraining's l1: 0.115868\tvalid_1's l1: 0.120385\n",
      "[2100]\ttraining's l1: 0.115726\tvalid_1's l1: 0.120348\n",
      "[2200]\ttraining's l1: 0.115554\tvalid_1's l1: 0.120337\n",
      "[2300]\ttraining's l1: 0.115401\tvalid_1's l1: 0.1203\n",
      "[2400]\ttraining's l1: 0.115303\tvalid_1's l1: 0.120277\n",
      "[2500]\ttraining's l1: 0.115183\tvalid_1's l1: 0.120252\n",
      "[2600]\ttraining's l1: 0.115027\tvalid_1's l1: 0.120236\n",
      "[2700]\ttraining's l1: 0.11491\tvalid_1's l1: 0.120231\n",
      "[2800]\ttraining's l1: 0.114726\tvalid_1's l1: 0.120229\n",
      "[2900]\ttraining's l1: 0.114613\tvalid_1's l1: 0.120234\n",
      "Early stopping, best iteration is:\n",
      "[2777]\ttraining's l1: 0.114763\tvalid_1's l1: 0.120213\n",
      "fold = 8, score = 0.12021283212775635\n",
      "Fold-9\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.009886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 358011\n",
      "[LightGBM] [Info] Number of data points in the train set: 2061896, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 15.820396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's l1: 0.131719\tvalid_1's l1: 0.132755\n",
      "[200]\ttraining's l1: 0.125441\tvalid_1's l1: 0.125827\n",
      "[300]\ttraining's l1: 0.122769\tvalid_1's l1: 0.123486\n",
      "[400]\ttraining's l1: 0.121199\tvalid_1's l1: 0.122224\n",
      "[500]\ttraining's l1: 0.120355\tvalid_1's l1: 0.121627\n",
      "[600]\ttraining's l1: 0.119622\tvalid_1's l1: 0.121179\n",
      "[700]\ttraining's l1: 0.11902\tvalid_1's l1: 0.120854\n",
      "[800]\ttraining's l1: 0.118665\tvalid_1's l1: 0.120683\n",
      "[900]\ttraining's l1: 0.118467\tvalid_1's l1: 0.120536\n",
      "[1000]\ttraining's l1: 0.118283\tvalid_1's l1: 0.120439\n",
      "[1100]\ttraining's l1: 0.117936\tvalid_1's l1: 0.120307\n",
      "[1200]\ttraining's l1: 0.117707\tvalid_1's l1: 0.120244\n",
      "[1300]\ttraining's l1: 0.117532\tvalid_1's l1: 0.120235\n",
      "[1400]\ttraining's l1: 0.117176\tvalid_1's l1: 0.120224\n",
      "[1500]\ttraining's l1: 0.116889\tvalid_1's l1: 0.120203\n",
      "[1600]\ttraining's l1: 0.116728\tvalid_1's l1: 0.120173\n",
      "[1700]\ttraining's l1: 0.116608\tvalid_1's l1: 0.120137\n",
      "[1800]\ttraining's l1: 0.116538\tvalid_1's l1: 0.12011\n",
      "[1900]\ttraining's l1: 0.116449\tvalid_1's l1: 0.120096\n",
      "[2000]\ttraining's l1: 0.116254\tvalid_1's l1: 0.12008\n",
      "[2100]\ttraining's l1: 0.116147\tvalid_1's l1: 0.120051\n",
      "[2200]\ttraining's l1: 0.116027\tvalid_1's l1: 0.120048\n",
      "[2300]\ttraining's l1: 0.115966\tvalid_1's l1: 0.120048\n",
      "[2400]\ttraining's l1: 0.115871\tvalid_1's l1: 0.120027\n",
      "[2500]\ttraining's l1: 0.115715\tvalid_1's l1: 0.119973\n",
      "[2600]\ttraining's l1: 0.115588\tvalid_1's l1: 0.119956\n",
      "[2700]\ttraining's l1: 0.115393\tvalid_1's l1: 0.119956\n",
      "[2800]\ttraining's l1: 0.115322\tvalid_1's l1: 0.119964\n",
      "Early stopping, best iteration is:\n",
      "[2621]\ttraining's l1: 0.115535\tvalid_1's l1: 0.119942\n",
      "fold = 9, score = 0.1199415684363835\n"
     ]
    }
   ],
   "source": [
    "oof_prediction = np.zeros(len(train_df))\n",
    "test_preds_lst = []\n",
    "input_dim = len(train_value_col)\n",
    "train_df['pred'] = 0\n",
    "train_gby = train_df.groupby('breath_id')['R_C'].agg('first').reset_index()\n",
    "skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "models = []\n",
    "\n",
    "\n",
    "fold_df = pd.DataFrame()\n",
    "fold_df[\"id\"] = train[\"id\"]\n",
    "fold_df[\"fold\"] = -1\n",
    "\n",
    "for fold, (_, valid_idx) in enumerate(skf.split(train_gby, train_gby['R_C'])):        \n",
    "    valid_b_ids = train_gby.iloc[valid_idx]['breath_id'].values\n",
    "    valid_df_idx = train_df[train_df['breath_id'].isin(valid_b_ids)].index.to_list()\n",
    "    fold_df.loc[valid_df_idx, 'fold'] = fold\n",
    "\n",
    "for i, fold in enumerate(range(CFG.n_folds)):\n",
    "    if i not in CFG.folds:\n",
    "        continue\n",
    "    print(f'Fold-{fold}')\n",
    "    \n",
    "    train_idx = fold_df[fold_df[\"fold\"] != fold].index\n",
    "    valid_idx = fold_df[fold_df[\"fold\"] == fold].index\n",
    "    \n",
    "    trn_df = train_df.loc[fold_df[\"fold\"] != fold, train_value_col].reset_index(drop=True)\n",
    "    val_df = train_df.loc[fold_df[\"fold\"] == fold, train_value_col].reset_index(drop=True)\n",
    "    trn_y = train_df.loc[fold_df[\"fold\"] != fold, 'pressure'].reset_index(drop=True)\n",
    "    val_y = train_df.loc[fold_df[\"fold\"] == fold, 'pressure'].reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    lgb_train = lgb.Dataset(trn_df, trn_y)\n",
    "    lgb_valid = lgb.Dataset(val_df, val_y, reference=lgb_train)\n",
    "\n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "             'objective': 'l1',\n",
    "            'metric': 'l1',\n",
    "            'seed': CFG.seed,\n",
    "            'max_bin': 2000,\n",
    "            'num_boost_round': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'lambda_l1': 0.1,\n",
    "            'lambda_l2': 0.1,\n",
    "    }\n",
    "\n",
    "\n",
    "    model = lgb.train(params, \n",
    "                      train_set=lgb_train, \n",
    "                      valid_sets=[lgb_train, lgb_valid], early_stopping_rounds=200, verbose_eval=100)\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "    oof_prediction[valid_idx] = model.predict(val_df[train_value_col])\n",
    "    test_pred = model.predict(test_df[train_value_col])\n",
    "    test_preds_lst.append(test_pred)\n",
    "    score = np.abs(val_y.values - oof_prediction[valid_idx]).mean()\n",
    "    print(f'fold = {fold}, score = {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12001931707209802"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV = np.abs(y.values - oof_prediction).mean()\n",
    "CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(OUTPUT_DIR / f\"stacking2_oof_{CFG.exp_num}\", oof_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pressures = train[\"pressure\"].unique()\n",
    "sorted_pressures = np.sort(unique_pressures)\n",
    "total_pressures_len = len(sorted_pressures)\n",
    "\n",
    "def find_nearest(prediction):\n",
    "    insert_idx = np.searchsorted(sorted_pressures, prediction)\n",
    "    if insert_idx == total_pressures_len:\n",
    "        # If the predicted value is bigger than the highest pressure in the train dataset,\n",
    "        # return the max value.\n",
    "        return sorted_pressures[-1]\n",
    "    elif insert_idx == 0:\n",
    "        # Same control but for the lower bound.\n",
    "        return sorted_pressures[0]\n",
    "    lower_val = sorted_pressures[insert_idx - 1]\n",
    "    upper_val = sorted_pressures[insert_idx]\n",
    "    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11843895149779683\n"
     ]
    }
   ],
   "source": [
    "oof = pd.DataFrame({'pred': oof_prediction})\n",
    "oof_pp = oof['pred'].map(lambda x: unique_pressures[np.abs(unique_pressures-x).argmin()])\n",
    "score = np.abs(y.values - oof_pp).mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(DATA_DIR / \"sample_submission.csv\")\n",
    "\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = np.stack(test_preds_lst).mean(0)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking2_submission_mean_{CFG.exp_num}.csv\", index=None)\n",
    "\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = np.median(np.stack(test_preds_lst), axis=0)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking2_submission_median_{CFG.exp_num}.csv\", index=None)\n",
    "\n",
    "# Post Processing: https://www.kaggle.com/snnclsr/a-dummy-approach-to-improve-your-score-postprocess\n",
    "\n",
    "\n",
    "sub_df = pd.read_csv(OUTPUT_DIR / f\"stacking2_submission_mean_{CFG.exp_num}.csv\")\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = sub_df[\"pressure\"].apply(find_nearest)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking2_submission_mean_pp_{CFG.exp_num}.csv\", index=None)\n",
    "\n",
    "sub_df = pd.read_csv(OUTPUT_DIR / f\"stacking2_submission_median_{CFG.exp_num}.csv\")\n",
    "sub_df.loc[test['u_out']==0, 'pressure'] = sub_df[\"pressure\"].apply(find_nearest)\n",
    "sub_df.to_csv(OUTPUT_DIR / f\"stacking2_submission_median_pp_{CFG.exp_num}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5cb25c469b873a0e0eec115bfbbdb6f77ff8970c2724434dd7f3f7fbd6e0533"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
